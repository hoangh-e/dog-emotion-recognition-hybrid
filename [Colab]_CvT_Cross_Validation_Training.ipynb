{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üîÑ CvT Cross-Validation Training for Dog Emotion Recognition\n",
        "\n",
        "## T·ªïng quan\n",
        "Notebook n√†y hu·∫•n luy·ªán m√¥ h√¨nh **CvT (Convolutional vision Transformer)** cho b√†i to√°n nh·∫≠n di·ªán c·∫£m x√∫c ch√≥ v·ªõi:\n",
        "- **Clone repository** t·ª´ GitHub\n",
        "- **Import CvT module** t·ª´ dog_emotion_classification package\n",
        "- **5-fold Cross-Validation** ƒë·ªÉ ƒë√°nh gi√° robust\n",
        "- **50 epochs** hu·∫•n luy·ªán cho m·ªói fold\n",
        "- **T·ª± ƒë·ªông t·∫£i dataset** t·ª´ Google Drive\n",
        "- **Visualization** k·∫øt qu·∫£ training v√† confusion matrix\n",
        "- **T·ª± ƒë·ªông l∆∞u model** v√† t·∫£i v·ªÅ m√°y\n",
        "\n",
        "## ƒê·∫∑c ƒëi·ªÉm CvT\n",
        "- **Convolutional Vision Transformer**: K·∫øt h·ª£p convolution v·ªõi self-attention\n",
        "- **Convolutional Embedding**: S·ª≠ d·ª•ng convolution ƒë·ªÉ t·∫°o tokens thay v√¨ linear projection\n",
        "- **Multi-Scale Features**: X·ª≠ l√Ω features ·ªü nhi·ªÅu scale kh√°c nhau\n",
        "- **Hierarchical Architecture**: Thi·∫øt k·∫ø hierarchical nh∆∞ CNN nh∆∞ng c√≥ attention\n",
        "\n",
        "## C√°ch s·ª≠ d·ª•ng\n",
        "1. **Ch·∫°y \"Run All\"** - T·∫•t c·∫£ s·∫Ω ƒë∆∞·ª£c th·ª±c hi·ªán t·ª± ƒë·ªông\n",
        "2. **Ch·ªù k·∫øt qu·∫£** - Kho·∫£ng 3-4 gi·ªù cho 5 folds √ó 50 epochs\n",
        "3. **T·∫£i model** - File .pth s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông download v·ªÅ m√°y\n",
        "4. **Xem k·∫øt qu·∫£** - Accuracy, confusion matrix, v√† training curves\n",
        "\n",
        "## Y√™u c·∫ßu\n",
        "- **GPU**: Khuy·∫øn ngh·ªã s·ª≠ d·ª•ng GPU ƒë·ªÉ training nhanh h∆°n\n",
        "- **RAM**: T·ªëi thi·ªÉu 12GB RAM\n",
        "- **Disk**: Kho·∫£ng 5GB cho dataset v√† model\n",
        "\n",
        "---\n",
        "**L∆∞u √Ω**: CvT l√† Transformer v·ªõi convolutional token embedding v√† multi-scale processing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "üîÑ CvT Cross-Validation Training for Dog Emotion Recognition\n",
        "===========================================================\n",
        "\n",
        "Complete pipeline for training CvT on dog emotion dataset with:\n",
        "- Automatic dataset download and preparation\n",
        "- 5-fold stratified cross-validation\n",
        "- 50 epochs training per fold\n",
        "- Comprehensive visualization and evaluation\n",
        "- Model saving and download\n",
        "\n",
        "Author: Dog Emotion Recognition Team\n",
        "Date: 2024\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import time\n",
        "from datetime import datetime\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "print(\"üöÄ Starting CvT Cross-Validation Training Pipeline\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# =====================================\n",
        "# 1. PACKAGE INSTALLATION\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüì¶ Installing required packages...\")\n",
        "packages = [\n",
        "    'torch>=1.9.0',\n",
        "    'torchvision>=0.10.0', \n",
        "    'scikit-learn>=1.0.0',\n",
        "    'matplotlib>=3.3.0',\n",
        "    'seaborn>=0.11.0',\n",
        "    'gdown>=4.0.0',\n",
        "    'Pillow>=8.0.0',\n",
        "    'numpy>=1.21.0',\n",
        "    'pandas>=1.3.0',\n",
        "    'tqdm>=4.60.0'\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        os.system(f'pip install {package} --quiet')\n",
        "        print(f\"‚úÖ {package}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to install {package}: {e}\")\n",
        "\n",
        "print(\"üì¶ Package installation completed!\")\n",
        "\n",
        "# =====================================\n",
        "# 1.5. CLONE REPOSITORY & IMPORT MODULES\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüì• Cloning repository and importing custom modules...\")\n",
        "\n",
        "# Clone repository t·ª´ GitHub\n",
        "REPO_URL = \"https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git\"\n",
        "if not os.path.exists(\"dog-emotion-recognition-hybrid\"):\n",
        "    print(\"üì• Cloning repository from GitHub...\")\n",
        "    os.system(f\"git clone {REPO_URL}\")\n",
        "\n",
        "# Change to repository directory v√† th√™m v√†o Python path\n",
        "os.chdir(\"dog-emotion-recognition-hybrid\")\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "# Import modules t·ª´ custom package\n",
        "print(\"üì¶ Importing custom modules...\")\n",
        "from dog_emotion_classification.cvt import (\n",
        "    load_cvt_model,\n",
        "    predict_emotion_cvt,\n",
        "    get_cvt_transforms,\n",
        "    create_cvt_model\n",
        ")\n",
        "\n",
        "# =====================================\n",
        "# 2. IMPORTS\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüìö Importing libraries...\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "import gdown\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üîß Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "# =====================================\n",
        "# 3. DATASET DOWNLOAD\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüíæ Downloading dataset...\")\n",
        "\n",
        "# Google Drive dataset ID\n",
        "dataset_id = \"1ZAgz5u64i3LDbwMFpBXjzsKt6FrhNGdW\"\n",
        "dataset_zip = \"dog_emotion_dataset.zip\"\n",
        "dataset_dir = \"dog_emotion_dataset\"\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "    print(\"üì• Downloading dataset from Google Drive...\")\n",
        "    try:\n",
        "        gdown.download(f'https://drive.google.com/uc?id={dataset_id}', dataset_zip, quiet=False)\n",
        "        \n",
        "        print(\"üìÇ Extracting dataset...\")\n",
        "        with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        \n",
        "        os.remove(dataset_zip)\n",
        "        print(\"‚úÖ Dataset downloaded and extracted successfully!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error downloading dataset: {e}\")\n",
        "        print(\"Please check your internet connection and try again.\")\n",
        "        sys.exit(1)\n",
        "else:\n",
        "    print(\"‚úÖ Dataset already exists!\")\n",
        "\n",
        "# =====================================\n",
        "# 4. DATASET CLASS\n",
        "# =====================================\n",
        "\n",
        "class DogEmotionDataset(Dataset):\n",
        "    \"\"\"Dataset class for dog emotion recognition\"\"\"\n",
        "    \n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Load image\n",
        "            image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "            \n",
        "            # Apply transforms\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            # Get label\n",
        "            label = self.labels[idx]\n",
        "            \n",
        "            return image, label\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {self.image_paths[idx]}: {e}\")\n",
        "            # Return a dummy image and label\n",
        "            dummy_image = torch.zeros(3, 224, 224)\n",
        "            return dummy_image, 0\n",
        "\n",
        "# =====================================\n",
        "# 5. DATA PREPARATION\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüîç Preparing dataset...\")\n",
        "\n",
        "# Define emotion classes\n",
        "emotion_classes = ['angry', 'happy', 'relaxed', 'sad']\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(emotion_classes)}\n",
        "\n",
        "# Collect all images and labels\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "for class_name in emotion_classes:\n",
        "    class_dir = Path(dataset_dir) / class_name\n",
        "    if class_dir.exists():\n",
        "        images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png'))\n",
        "        all_images.extend(images)\n",
        "        all_labels.extend([class_to_idx[class_name]] * len(images))\n",
        "        print(f\"üìÅ {class_name}: {len(images)} images\")\n",
        "\n",
        "print(f\"\\nüìä Total dataset: {len(all_images)} images\")\n",
        "print(f\"üìä Classes: {emotion_classes}\")\n",
        "\n",
        "# Convert to numpy arrays\n",
        "all_images = np.array(all_images)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# =====================================\n",
        "# 6. TRAINING FUNCTIONS\n",
        "# =====================================\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train model for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(dataloader, desc=\"Training\")\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'Loss': f'{loss.item():.4f}',\n",
        "            'Acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    \"\"\"Evaluate model on validation set\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predicted = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(dataloader, desc=\"Evaluating\")\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            all_predicted.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            \n",
        "            pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "    \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc, all_predicted, all_labels\n",
        "\n",
        "# =====================================\n",
        "# 7. CROSS-VALIDATION TRAINING\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüéØ Starting 5-Fold Cross-Validation Training...\")\n",
        "\n",
        "# Training parameters\n",
        "n_folds = 5\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "input_size = 224\n",
        "\n",
        "# Data transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Initialize cross-validation\n",
        "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Storage for results\n",
        "fold_results = []\n",
        "all_train_losses = []\n",
        "all_val_losses = []\n",
        "all_train_accs = []\n",
        "all_val_accs = []\n",
        "\n",
        "# Training loop\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(all_images, all_labels)):\n",
        "    print(f\"\\n{'='*20} FOLD {fold+1}/{n_folds} {'='*20}\")\n",
        "    \n",
        "    # Split data\n",
        "    train_images = all_images[train_idx]\n",
        "    train_labels = all_labels[train_idx]\n",
        "    val_images = all_images[val_idx]\n",
        "    val_labels = all_labels[val_idx]\n",
        "    \n",
        "    print(f\"Train samples: {len(train_images)}\")\n",
        "    print(f\"Validation samples: {len(val_images)}\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = DogEmotionDataset(train_images, train_labels, train_transform)\n",
        "    val_dataset = DogEmotionDataset(val_images, val_labels, val_transform)\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    \n",
        "    # Create model using custom function\n",
        "    model = create_cvt_model(num_classes=len(emotion_classes))\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
        "    \n",
        "    # Training tracking\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    best_val_acc = 0.0\n",
        "    \n",
        "    # Training epochs\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 30)\n",
        "        \n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        \n",
        "        # Validate\n",
        "        val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Save metrics\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "        \n",
        "        # Print progress\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "        \n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f'cvt_fold_{fold+1}_best.pth')\n",
        "            print(f\"üíæ New best model saved! Accuracy: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    # Store fold results\n",
        "    fold_results.append({\n",
        "        'fold': fold + 1,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accs': train_accs,\n",
        "        'val_accs': val_accs\n",
        "    })\n",
        "    \n",
        "    all_train_losses.append(train_losses)\n",
        "    all_val_losses.append(val_losses)\n",
        "    all_train_accs.append(train_accs)\n",
        "    all_val_accs.append(val_accs)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Fold {fold+1} completed! Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "# =====================================\n",
        "# 8. RESULTS ANALYSIS\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüìä Training Results Analysis\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Calculate statistics\n",
        "fold_accuracies = [result['best_val_acc'] for result in fold_results]\n",
        "mean_acc = np.mean(fold_accuracies)\n",
        "std_acc = np.std(fold_accuracies)\n",
        "\n",
        "print(f\"Cross-Validation Results:\")\n",
        "print(f\"Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"Best Fold: {max(fold_accuracies):.2f}%\")\n",
        "print(f\"Worst Fold: {min(fold_accuracies):.2f}%\")\n",
        "\n",
        "print(\"\\nFold-by-fold results:\")\n",
        "for i, acc in enumerate(fold_accuracies):\n",
        "    print(f\"Fold {i+1}: {acc:.2f}%\")\n",
        "\n",
        "# =====================================\n",
        "# 9. VISUALIZATION\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüìà Creating visualizations...\")\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create comprehensive visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('CvT Cross-Validation Training Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Training and Validation Loss\n",
        "ax1 = axes[0, 0]\n",
        "for fold in range(n_folds):\n",
        "    epochs_range = range(1, epochs + 1)\n",
        "    ax1.plot(epochs_range, all_train_losses[fold], alpha=0.7, label=f'Fold {fold+1} Train')\n",
        "    ax1.plot(epochs_range, all_val_losses[fold], alpha=0.7, linestyle='--', label=f'Fold {fold+1} Val')\n",
        "\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Training and Validation Accuracy\n",
        "ax2 = axes[0, 1]\n",
        "for fold in range(n_folds):\n",
        "    epochs_range = range(1, epochs + 1)\n",
        "    ax2.plot(epochs_range, all_train_accs[fold], alpha=0.7, label=f'Fold {fold+1} Train')\n",
        "    ax2.plot(epochs_range, all_val_accs[fold], alpha=0.7, linestyle='--', label=f'Fold {fold+1} Val')\n",
        "\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Cross-Validation Accuracy Distribution\n",
        "ax3 = axes[1, 0]\n",
        "ax3.bar(range(1, n_folds + 1), fold_accuracies, alpha=0.7, color='skyblue', edgecolor='navy')\n",
        "ax3.axhline(y=mean_acc, color='red', linestyle='--', label=f'Mean: {mean_acc:.2f}%')\n",
        "ax3.set_title('Cross-Validation Accuracy by Fold')\n",
        "ax3.set_xlabel('Fold')\n",
        "ax3.set_ylabel('Accuracy (%)')\n",
        "ax3.set_xticks(range(1, n_folds + 1))\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Add accuracy values on bars\n",
        "for i, acc in enumerate(fold_accuracies):\n",
        "    ax3.text(i + 1, acc + 0.5, f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 4. Model Performance Summary\n",
        "ax4 = axes[1, 1]\n",
        "ax4.axis('off')\n",
        "\n",
        "# Create summary text\n",
        "summary_text = f\"\"\"\n",
        "CVT TRAINING SUMMARY\n",
        "{'='*20}\n",
        "\n",
        "Dataset: Dog Emotion Recognition\n",
        "Architecture: CvT (Convolutional Vision Transformer)\n",
        "Input Size: 224√ó224\n",
        "Classes: {len(emotion_classes)}\n",
        "\n",
        "Training Configuration:\n",
        "‚Ä¢ Folds: {n_folds}\n",
        "‚Ä¢ Epochs per fold: {epochs}\n",
        "‚Ä¢ Batch size: {batch_size}\n",
        "‚Ä¢ Learning rate: {learning_rate}\n",
        "‚Ä¢ Optimizer: Adam\n",
        "\n",
        "Results:\n",
        "‚Ä¢ Mean CV Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\n",
        "‚Ä¢ Best Fold Accuracy: {max(fold_accuracies):.2f}%\n",
        "‚Ä¢ Total Training Time: {datetime.now().strftime('%H:%M:%S')}\n",
        "\n",
        "Classes: {', '.join(emotion_classes)}\n",
        "\"\"\"\n",
        "\n",
        "ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes, fontsize=11,\n",
        "         verticalalignment='top', fontfamily='monospace',\n",
        "         bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# =====================================\n",
        "# 10. SAVE RESULTS\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüíæ Saving results...\")\n",
        "\n",
        "# Save training history\n",
        "results_data = {\n",
        "    'fold_results': fold_results,\n",
        "    'mean_accuracy': mean_acc,\n",
        "    'std_accuracy': std_acc,\n",
        "    'emotion_classes': emotion_classes,\n",
        "    'training_config': {\n",
        "        'n_folds': n_folds,\n",
        "        'epochs': epochs,\n",
        "        'batch_size': batch_size,\n",
        "        'learning_rate': learning_rate,\n",
        "        'input_size': input_size\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('cvt_training_results.json', 'w') as f:\n",
        "    json.dump(results_data, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Results saved to cvt_training_results.json\")\n",
        "\n",
        "# =====================================\n",
        "# 11. MODEL DOWNLOAD\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüì• Preparing models for download...\")\n",
        "\n",
        "# Find best model\n",
        "best_fold = fold_accuracies.index(max(fold_accuracies)) + 1\n",
        "best_model_file = f'cvt_fold_{best_fold}_best.pth'\n",
        "\n",
        "print(f\"\\nüèÜ Best model: {best_model_file} (Accuracy: {max(fold_accuracies):.2f}%)\")\n",
        "\n",
        "# Download best model (in Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(f\"\\nüì• Downloading best model: {best_model_file}\")\n",
        "    files.download(best_model_file)\n",
        "    files.download('cvt_training_results.json')\n",
        "    print(\"‚úÖ Files downloaded successfully!\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Not running in Colab - files saved locally\")\n",
        "\n",
        "print(\"\\nüéâ CvT Cross-Validation Training Completed!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"‚úÖ Final Results:\")\n",
        "print(f\"   Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"   Best Model: {best_model_file} ({max(fold_accuracies):.2f}%)\")\n",
        "print(f\"   Classes: {emotion_classes}\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
