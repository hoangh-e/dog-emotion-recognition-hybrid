{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üêï Dog Emotion Classification - ResNet Pretrained Training\n",
        "\n",
        "Notebook n√†y s·∫Ω:\n",
        "1. **Clone repository** t·ª´ GitHub v√† c√†i ƒë·∫∑t dependencies\n",
        "2. **Import ResNet module** t·ª´ `dog_emotion_classification.resnet`\n",
        "3. **Download dataset** dog emotion classification  \n",
        "4. **Train ResNet50 pretrained** (30 epochs, save best t·ª´ epoch 10, m·ªói 5 epochs)\n",
        "5. **Train ResNet101 pretrained** v·ªõi c√πng configuration\n",
        "6. **Evaluate v√† compare** c·∫£ hai models\n",
        "\n",
        "---\n",
        "**Author**: Dog Emotion Research Team  \n",
        "**Date**: 2025  \n",
        "**Runtime**: Google Colab (GPU T4/V100 recommended)  \n",
        "**Training**: ResNet50 ‚Üí ResNet101 v·ªõi ImageNet pretrained weights  \n",
        "**Repository**: https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git  \n",
        "**Module**: `dog_emotion_classification.resnet`\n",
        "**Configuration**: Auto-detect 3-class ho·∫∑c 4-class t·ª´ dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß STEP 1: Clone Repository v√† Setup Environment\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone repository t·ª´ GitHub v·ªõi branch specification\n",
        "REPO_URL = \"https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git\"\n",
        "BRANCH_NAME = \"main\"  # Specify branch explicitly\n",
        "REPO_NAME = \"dog-emotion-recognition-hybrid\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    print(f\"üì• Cloning repository from {REPO_URL} (branch: {BRANCH_NAME})\")\n",
        "    !git clone -b {BRANCH_NAME} {REPO_URL}\n",
        "    print(\"‚úÖ Repository cloned successfully!\")\n",
        "else:\n",
        "    print(f\"‚úÖ Repository already exists: {REPO_NAME}\")\n",
        "\n",
        "# Change to repository directory\n",
        "os.chdir(REPO_NAME)\n",
        "print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Add to Python path ƒë·ªÉ import modules\n",
        "if os.getcwd() not in sys.path:\n",
        "    sys.path.insert(0, os.getcwd())\n",
        "    print(\"‚úÖ Added repository to Python path\")\n",
        "\n",
        "# Install required packages\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install opencv-python-headless pillow pandas tqdm gdown albumentations matplotlib seaborn\n",
        "!pip install scikit-learn timm ultralytics\n",
        "\n",
        "# üéØ Import ResNet t·ª´ custom module\n",
        "try:\n",
        "    from dog_emotion_classification.resnet import (\n",
        "        load_resnet_model, \n",
        "        predict_emotion_resnet,\n",
        "        get_resnet_transforms,\n",
        "        create_resnet_model,\n",
        "        load_resnet50_model,\n",
        "        load_resnet101_model,\n",
        "        predict_emotion_resnet50,\n",
        "        predict_emotion_resnet101\n",
        "    )\n",
        "\n",
        "    # Import utility functions for 3-class conversion\n",
        "    from dog_emotion_classification.utils import (\n",
        "        convert_dataframe_4class_to_3class,\n",
        "        get_3class_emotion_classes,\n",
        "        EMOTION_CLASSES_3CLASS\n",
        "    )\n",
        "    from dog_emotion_classification import EMOTION_CLASSES as PACKAGE_EMOTION_CLASSES\n",
        "\n",
        "    print(\"‚úÖ Imported 3-class utility functions\")\n",
        "    print(f\"üìä Target emotion classes: {EMOTION_CLASSES_3CLASS}\")\n",
        "    print(f\"üì¶ Package emotion classes: {PACKAGE_EMOTION_CLASSES}\")\n",
        "    print(\"‚úÖ Successfully imported ResNet module from dog_emotion_classification.resnet\")\n",
        "    print(\"üìã Available functions:\")\n",
        "    print(\"   - load_resnet_model()\")\n",
        "    print(\"   - predict_emotion_resnet()\")\n",
        "    print(\"   - get_resnet_transforms()\")\n",
        "    print(\"   - create_resnet_model()\")\n",
        "    print(\"   - load_resnet50_model(), load_resnet101_model()\")\n",
        "    print(\"   - predict_emotion_resnet50(), predict_emotion_resnet101()\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import ResNet module: {e}\")\n",
        "    print(\"Please ensure you're in the repository directory and the module exists.\")\n",
        "    raise\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîß Step 2: Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check GPU and setup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
        "print(f\"üöÄ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéØ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Using CPU - training will be slower\")\n",
        "    device = torch.device('cpu')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìä Step 3: Download & Prepare Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and extract dataset\n",
        "import zipfile\n",
        "\n",
        "DATASET_ID = \"1ZAgz5u64i3LDbwMFpBXjzsKt6FrhNGdW\"\n",
        "DATASET_ZIP = \"cropped_dataset_4k_face.zip\"\n",
        "\n",
        "print(\"üì• Downloading dog emotion dataset...\")\n",
        "if not os.path.exists(DATASET_ZIP):\n",
        "    !gdown {DATASET_ID} -O {DATASET_ZIP}\n",
        "    print(f\"‚úÖ Dataset downloaded: {DATASET_ZIP}\")\n",
        "else:\n",
        "    print(f\"‚úÖ Dataset already exists: {DATASET_ZIP}\")\n",
        "\n",
        "# Extract dataset\n",
        "if not os.path.exists(\"cropped_dataset_4k_face\"):\n",
        "    print(\"üìÇ Extracting dataset...\")\n",
        "    with zipfile.ZipFile(DATASET_ZIP, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "    print(\"‚úÖ Dataset extracted successfully\")\n",
        "\n",
        "# Dataset paths\n",
        "data_root = os.path.join(\"cropped_dataset_4k_face\", \"Dog Emotion\")\n",
        "labels_csv = os.path.join(data_root, \"labels.csv\")\n",
        "\n",
        "print(f\"\\nüìÇ Dataset structure:\")\n",
        "emotions = [d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))]\n",
        "print(f\"   Emotion classes: {emotions}\")\n",
        "\n",
        "for emotion in emotions:\n",
        "    emotion_path = os.path.join(data_root, emotion)\n",
        "    if os.path.isdir(emotion_path):\n",
        "        count = len([f for f in os.listdir(emotion_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        print(f\"     {emotion}: {count} images\")\n",
        "\n",
        "print(f\"   Labels CSV: {'‚úÖ' if os.path.exists(labels_csv) else '‚ùå'} {labels_csv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Dataset class\n",
        "class DogEmotionDataset(Dataset):\n",
        "    def __init__(self, root, labels_csv, transform=None):\n",
        "        self.root = root\n",
        "        df = pd.read_csv(labels_csv)\n",
        "        self.items = df[['filename', 'label']].values\n",
        "        unique_labels = sorted(df['label'].unique())\n",
        "        self.label2index = {name: i for i, name in enumerate(unique_labels)}\n",
        "        self.index2label = {i: name for name, i in self.label2index.items()}\n",
        "        self.transform = transform\n",
        "        print(f\"üìä Dataset: {len(self.items)} samples\")\n",
        "        print(f\"üè∑Ô∏è  Classes: {list(self.label2index.keys())}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fn, label_str = self.items[idx]\n",
        "        label_idx = self.label2index[label_str]\n",
        "        img_path = os.path.join(self.root, label_str, fn)\n",
        "        \n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            return img, label_idx\n",
        "        except Exception as e:\n",
        "            # Fallback for corrupted images\n",
        "            img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            return img, label_idx\n",
        "\n",
        "# Create transforms for ResNet (224x224 ImageNet standard)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Check if we should use 3-class or 4-class configuration\n",
        "print(\"\\nüîç Checking dataset configuration...\")\n",
        "\n",
        "# Create initial dataset to check original classes\n",
        "print(\"\\nüìä Loading original dataset...\")\n",
        "original_dataset = DogEmotionDataset(data_root, labels_csv, None)\n",
        "original_classes = list(original_dataset.label2index.keys())\n",
        "print(f\"   Original classes: {original_classes}\")\n",
        "print(f\"   Original samples: {len(original_dataset)}\")\n",
        "\n",
        "# Determine if we need 3-class conversion\n",
        "if 'sad' in original_classes and len(original_classes) == 4:\n",
        "    print(\"\\nüîß Converting to 3-class configuration...\")\n",
        "    \n",
        "    # Read labels CSV and filter out 'sad' class\n",
        "    labels_df = pd.read_csv(labels_csv)\n",
        "    print(f\"   Original DataFrame: {len(labels_df)} samples\")\n",
        "    \n",
        "    # Convert to 3-class by removing 'sad' samples\n",
        "    filtered_df = convert_dataframe_4class_to_3class(labels_df, 'label')\n",
        "    \n",
        "    # Save filtered labels CSV\n",
        "    filtered_labels_csv = os.path.join(data_root, \"labels_3class.csv\")\n",
        "    filtered_df.to_csv(filtered_labels_csv, index=False)\n",
        "    print(f\"   Saved filtered labels to: {filtered_labels_csv}\")\n",
        "    \n",
        "    # Create 3-class dataset\n",
        "    dataset = DogEmotionDataset(data_root, filtered_labels_csv, train_transform)\n",
        "    print(\"‚úÖ Using 3-class configuration\")\n",
        "else:\n",
        "    # Use original dataset (could be 3-class or 4-class)\n",
        "    dataset = DogEmotionDataset(data_root, labels_csv, train_transform)\n",
        "    print(f\"‚úÖ Using original {len(original_classes)}-class configuration\")\n",
        "\n",
        "NUM_CLASSES = len(dataset.label2index)\n",
        "EMOTION_CLASSES = list(dataset.label2index.keys())\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset ready:\")\n",
        "print(f\"   Total samples: {len(dataset)}\")\n",
        "print(f\"   Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"   Emotion classes: {EMOTION_CLASSES}\")\n",
        "\n",
        "# Update configuration\n",
        "print(f\"\\nüîß Training configuration:\")\n",
        "print(f\"   Classes: {NUM_CLASSES}\")\n",
        "print(f\"   Emotion mapping: {dataset.label2index}\")\n",
        "print(f\"   ResNet will be created with num_classes={NUM_CLASSES}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üèóÔ∏è Step 4: Define Training Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training function with custom checkpointing\n",
        "def train_resnet_model(model_name, num_epochs=30, batch_size=16, learning_rate=1e-4):\n",
        "    \"\"\"\n",
        "    Train ResNet model with specific checkpointing strategy:\n",
        "    - Save best model t·ª´ epoch 10\n",
        "    - Save m·ªói 5 epochs t·ª´ epoch 10 (10, 15, 20, 25, 30)\n",
        "    \"\"\"\n",
        "    print(f\"\\nüöÄ Training {model_name} for {num_epochs} epochs\")\n",
        "    print(\"=\"*60)\n",
        "    \n",
        "    # Create model using the custom resnet module with correct num_classes\n",
        "    if model_name == 'resnet50':\n",
        "        model = create_resnet_model(architecture='resnet50', num_classes=NUM_CLASSES, pretrained=True)\n",
        "        print(f\"üèóÔ∏è  Created ResNet50 with ImageNet pretrained weights using custom module\")\n",
        "    elif model_name == 'resnet101':\n",
        "        model = create_resnet_model(architecture='resnet101', num_classes=NUM_CLASSES, pretrained=True)\n",
        "        print(f\"üèóÔ∏è  Created ResNet101 with ImageNet pretrained weights using custom module\")\n",
        "    else:\n",
        "        raise ValueError(f\"Unsupported model: {model_name}\")\n",
        "    \n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Print model info\n",
        "    total_params = sum(p.numel() for p in model.parameters())\n",
        "    trainable_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(f\"üìä Model stats:\")\n",
        "    print(f\"   Architecture: {model_name}\")\n",
        "    print(f\"   Number of classes: {NUM_CLASSES}\")\n",
        "    print(f\"   Emotion classes: {EMOTION_CLASSES}\")\n",
        "    print(f\"   Total parameters: {total_params:,}\")\n",
        "    print(f\"   Trainable parameters: {trainable_params:,}\")\n",
        "    print(f\"   Model size: {total_params * 4 / (1024**2):.1f} MB\")\n",
        "    \n",
        "    # Create data loader\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, \n",
        "                             num_workers=2, pin_memory=True)\n",
        "    \n",
        "    # Training setup\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    \n",
        "    # Training tracking\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    best_acc = 0.0\n",
        "    best_models = {}  # Store multiple best models\n",
        "    \n",
        "    # Create checkpoint directory\n",
        "    checkpoint_dir = f\"checkpoints_{model_name}\"\n",
        "    os.makedirs(checkpoint_dir, exist_ok=True)\n",
        "    \n",
        "    print(f\"üéØ Training configuration:\")\n",
        "    print(f\"   Batch size: {batch_size}\")\n",
        "    print(f\"   Learning rate: {learning_rate}\")\n",
        "    print(f\"   Optimizer: Adam with weight decay 1e-4\")\n",
        "    print(f\"   Scheduler: StepLR(step_size=10, gamma=0.1)\")\n",
        "    print(f\"   Checkpoint dir: {checkpoint_dir}\")\n",
        "    print(f\"   Device: {device}\")\n",
        "    print(f\"   Total batches per epoch: {len(train_loader)}\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        correct = 0\n",
        "        total = 0\n",
        "        \n",
        "        # Training loop with progress bar\n",
        "        pbar = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        for batch_idx, (images, labels) in enumerate(pbar):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            # Statistics\n",
        "            running_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            \n",
        "            # Update progress bar\n",
        "            pbar.set_postfix({\n",
        "                'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
        "                'Acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "        \n",
        "        # Calculate epoch metrics\n",
        "        epoch_loss = running_loss / len(train_loader)\n",
        "        epoch_acc = correct / total\n",
        "        train_losses.append(epoch_loss)\n",
        "        train_accuracies.append(epoch_acc)\n",
        "        \n",
        "        # Learning rate step\n",
        "        scheduler.step()\n",
        "        current_lr = scheduler.get_last_lr()[0]\n",
        "        \n",
        "        # Print epoch summary\n",
        "        elapsed = time.time() - start_time\n",
        "        eta = elapsed * (num_epochs - (epoch + 1)) / (epoch + 1) if epoch > 0 else 0\n",
        "        print(f\"Epoch {epoch+1:2d}/{num_epochs} | \"\n",
        "              f\"Loss: {epoch_loss:.4f} | \"\n",
        "              f\"Acc: {epoch_acc:.4f} ({epoch_acc*100:.2f}%) | \"\n",
        "              f\"LR: {current_lr:.2e} | \"\n",
        "              f\"Time: {elapsed/60:.1f}m | ETA: {eta/60:.1f}m\")\n",
        "        \n",
        "        # Checkpointing strategy\n",
        "        if epoch + 1 >= 10:  # Start saving from epoch 10\n",
        "            if epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                # Save best model\n",
        "                best_path = os.path.join(checkpoint_dir, f\"best_model.pth\")\n",
        "                torch.save({\n",
        "                    'epoch': epoch + 1,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict': scheduler.state_dict(),\n",
        "                    'loss': epoch_loss,\n",
        "                    'accuracy': epoch_acc,\n",
        "                    'model_name': model_name,\n",
        "                    'num_classes': NUM_CLASSES,\n",
        "                    'emotion_classes': EMOTION_CLASSES\n",
        "                }, best_path)\n",
        "                print(f\"‚úÖ New best model saved: {best_path} (Acc: {epoch_acc:.4f})\")\n",
        "            \n",
        "            # Save every 5 epochs from epoch 10\n",
        "            if (epoch + 1) % 5 == 0:\n",
        "                checkpoint_path = os.path.join(checkpoint_dir, f\"model_epoch_{epoch+1}.pth\")\n",
        "                torch.save({\n",
        "                    'epoch': epoch + 1,\n",
        "                    'model_state_dict': model.state_dict(),\n",
        "                    'optimizer_state_dict': optimizer.state_dict(),\n",
        "                    'scheduler_state_dict': scheduler.state_dict(),\n",
        "                    'loss': epoch_loss,\n",
        "                    'accuracy': epoch_acc,\n",
        "                    'model_name': model_name,\n",
        "                    'num_classes': NUM_CLASSES,\n",
        "                    'emotion_classes': EMOTION_CLASSES\n",
        "                }, checkpoint_path)\n",
        "                best_models[f\"epoch_{epoch+1}\"] = {\n",
        "                    'path': checkpoint_path,\n",
        "                    'accuracy': epoch_acc,\n",
        "                    'loss': epoch_loss\n",
        "                }\n",
        "                print(f\"üì¶ Checkpoint saved: {checkpoint_path}\")\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\nüéâ Training completed!\")\n",
        "    print(f\"   Total time: {total_time/60:.1f} minutes\")\n",
        "    print(f\"   Best accuracy: {best_acc:.4f} ({best_acc*100:.2f}%)\")\n",
        "    print(f\"   Final accuracy: {train_accuracies[-1]:.4f}\")\n",
        "    print(f\"   Saved models: {len(best_models) + 1}\")  # +1 for best model\n",
        "    \n",
        "    return {\n",
        "        'model': model,\n",
        "        'train_losses': train_losses,\n",
        "        'train_accuracies': train_accuracies,\n",
        "        'best_acc': best_acc,\n",
        "        'best_models': best_models,\n",
        "        'checkpoint_dir': checkpoint_dir,\n",
        "        'total_time': total_time,\n",
        "        'num_classes': NUM_CLASSES,\n",
        "        'emotion_classes': EMOTION_CLASSES\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ Step 5: Train ResNet50\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ResNet50 with pretrained weights\n",
        "print(\"üî• Starting ResNet50 Training\")\n",
        "print(\"üéØ Strategy: 30 epochs, save best t·ª´ epoch 10, save m·ªói 5 epochs t·ª´ epoch 10\")\n",
        "print(f\"üè∑Ô∏è  Training on {NUM_CLASSES} classes: {EMOTION_CLASSES}\")\n",
        "\n",
        "resnet50_results = train_resnet_model(\n",
        "    model_name='resnet50',\n",
        "    num_epochs=30,\n",
        "    batch_size=16,\n",
        "    learning_rate=1e-4\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ ResNet50 training completed!\")\n",
        "print(f\"üéØ Best accuracy: {resnet50_results['best_acc']:.4f} ({resnet50_results['best_acc']*100:.2f}%)\")\n",
        "print(f\"‚è±Ô∏è  Total training time: {resnet50_results['total_time']/60:.1f} minutes\")\n",
        "print(f\"üìÅ Checkpoints saved in: {resnet50_results['checkpoint_dir']}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ Step 6: Train ResNet101\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train ResNet101 with pretrained weights\n",
        "print(\"\\nüî• Starting ResNet101 Training\")\n",
        "print(\"üéØ Strategy: 30 epochs, save best t·ª´ epoch 10, save m·ªói 5 epochs t·ª´ epoch 10\")\n",
        "print(f\"üè∑Ô∏è  Training on {NUM_CLASSES} classes: {EMOTION_CLASSES}\")\n",
        "\n",
        "resnet101_results = train_resnet_model(\n",
        "    model_name='resnet101',\n",
        "    num_epochs=30,\n",
        "    batch_size=16,\n",
        "    learning_rate=1e-4\n",
        ")\n",
        "\n",
        "print(f\"\\n‚úÖ ResNet101 training completed!\")\n",
        "print(f\"üéØ Best accuracy: {resnet101_results['best_acc']:.4f} ({resnet101_results['best_acc']*100:.2f}%)\")\n",
        "print(f\"‚è±Ô∏è  Total training time: {resnet101_results['total_time']/60:.1f} minutes\")\n",
        "print(f\"üìÅ Checkpoints saved in: {resnet101_results['checkpoint_dir']}\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìä Step 7: Visualize Training Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot training curves comparison\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(15, 5))\n",
        "\n",
        "# Plot 1: Training Loss\n",
        "plt.subplot(1, 3, 1)\n",
        "epochs = range(1, len(resnet50_results['train_losses']) + 1)\n",
        "plt.plot(epochs, resnet50_results['train_losses'], 'b-', label='ResNet50', linewidth=2)\n",
        "plt.plot(epochs, resnet101_results['train_losses'], 'r-', label='ResNet101', linewidth=2)\n",
        "plt.title('üî• Training Loss Comparison', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 2: Training Accuracy\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(epochs, [acc*100 for acc in resnet50_results['train_accuracies']], 'b-', label='ResNet50', linewidth=2)\n",
        "plt.plot(epochs, [acc*100 for acc in resnet101_results['train_accuracies']], 'r-', label='ResNet101', linewidth=2)\n",
        "plt.title('üéØ Training Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Plot 3: Best Accuracy Comparison\n",
        "plt.subplot(1, 3, 3)\n",
        "models = ['ResNet50', 'ResNet101']\n",
        "accuracies = [resnet50_results['best_acc']*100, resnet101_results['best_acc']*100]\n",
        "colors = ['#3498db', '#e74c3c']\n",
        "bars = plt.bar(models, accuracies, color=colors, alpha=0.8)\n",
        "plt.title('üèÜ Best Accuracy Comparison', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, accuracies):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "             f'{acc:.2f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed comparison\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üèÜ FINAL TRAINING RESULTS COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "print(f\"üìä Dataset: {NUM_CLASSES} classes ({EMOTION_CLASSES})\")\n",
        "print(f\"üñºÔ∏è  Total samples: {len(dataset)}\")\n",
        "print(f\"‚öôÔ∏è  Training: 30 epochs, batch_size=16, lr=1e-4\")\n",
        "print()\n",
        "print(\"üîµ ResNet50 Results:\")\n",
        "print(f\"   Best Accuracy: {resnet50_results['best_acc']:.4f} ({resnet50_results['best_acc']*100:.2f}%)\")\n",
        "print(f\"   Final Accuracy: {resnet50_results['train_accuracies'][-1]:.4f} ({resnet50_results['train_accuracies'][-1]*100:.2f}%)\")\n",
        "print(f\"   Training Time: {resnet50_results['total_time']/60:.1f} minutes\")\n",
        "print(f\"   Checkpoints: {len(resnet50_results['best_models']) + 1} models saved\")\n",
        "print()\n",
        "print(\"üî¥ ResNet101 Results:\")\n",
        "print(f\"   Best Accuracy: {resnet101_results['best_acc']:.4f} ({resnet101_results['best_acc']*100:.2f}%)\")\n",
        "print(f\"   Final Accuracy: {resnet101_results['train_accuracies'][-1]:.4f} ({resnet101_results['train_accuracies'][-1]*100:.2f}%)\")\n",
        "print(f\"   Training Time: {resnet101_results['total_time']/60:.1f} minutes\")\n",
        "print(f\"   Checkpoints: {len(resnet101_results['best_models']) + 1} models saved\")\n",
        "print()\n",
        "print(\"üìà Performance Analysis:\")\n",
        "acc_diff = resnet101_results['best_acc'] - resnet50_results['best_acc']\n",
        "time_diff = resnet101_results['total_time'] - resnet50_results['total_time']\n",
        "print(f\"   Accuracy Difference: {acc_diff:+.4f} ({acc_diff*100:+.2f}%)\")\n",
        "print(f\"   Training Time Difference: {time_diff/60:+.1f} minutes\")\n",
        "if acc_diff > 0:\n",
        "    print(f\"   üèÜ ResNet101 performed better by {acc_diff*100:.2f}%\")\n",
        "elif acc_diff < 0:\n",
        "    print(f\"   üèÜ ResNet50 performed better by {abs(acc_diff)*100:.2f}%\")\n",
        "else:\n",
        "    print(f\"   ü§ù Both models achieved the same accuracy\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üß™ Step 8: Model Evaluation Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Evaluation functions\n",
        "def evaluate_model(model, test_loader, emotion_classes):\n",
        "    \"\"\"Evaluate model on test set\"\"\"\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = outputs.max(1)\n",
        "            \n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            \n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    \n",
        "    accuracy = correct / total\n",
        "    return accuracy, all_predictions, all_labels\n",
        "\n",
        "def load_best_model(checkpoint_path, model_name, num_classes):\n",
        "    \"\"\"Load the best saved model\"\"\"\n",
        "    if model_name == 'resnet50':\n",
        "        model = create_resnet_model(architecture='resnet50', num_classes=num_classes, pretrained=False)\n",
        "    elif model_name == 'resnet101':\n",
        "        model = create_resnet_model(architecture='resnet101', num_classes=num_classes, pretrained=False)\n",
        "    \n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model = model.to(device)\n",
        "    \n",
        "    print(f\"‚úÖ Loaded {model_name} from {checkpoint_path}\")\n",
        "    print(f\"   Epoch: {checkpoint['epoch']}\")\n",
        "    print(f\"   Training Accuracy: {checkpoint['accuracy']:.4f} ({checkpoint['accuracy']*100:.2f}%)\")\n",
        "    print(f\"   Training Loss: {checkpoint['loss']:.4f}\")\n",
        "    \n",
        "    return model\n",
        "\n",
        "# Create test dataset for evaluation\n",
        "test_dataset = DogEmotionDataset(data_root, \n",
        "                                filtered_labels_csv if 'filtered_labels_csv' in locals() else labels_csv, \n",
        "                                val_transform)\n",
        "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=2)\n",
        "\n",
        "print(f\"üìä Test dataset ready: {len(test_dataset)} samples\")\n",
        "print(f\"üî¨ Test loader: {len(test_loader)} batches\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéØ Step 9: Evaluate Best Models\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and evaluate best ResNet50 model\n",
        "print(\"üîµ Evaluating Best ResNet50 Model\")\n",
        "print(\"=\"*50)\n",
        "best_resnet50_path = os.path.join(resnet50_results['checkpoint_dir'], \"best_model.pth\")\n",
        "best_resnet50 = load_best_model(best_resnet50_path, 'resnet50', NUM_CLASSES)\n",
        "resnet50_test_acc, resnet50_preds, resnet50_labels = evaluate_model(best_resnet50, test_loader, EMOTION_CLASSES)\n",
        "\n",
        "print(f\"\\nüéØ ResNet50 Test Results:\")\n",
        "print(f\"   Test Accuracy: {resnet50_test_acc:.4f} ({resnet50_test_acc*100:.2f}%)\")\n",
        "print(f\"   Training Best: {resnet50_results['best_acc']:.4f} ({resnet50_results['best_acc']*100:.2f}%)\")\n",
        "print(f\"   Difference: {(resnet50_test_acc - resnet50_results['best_acc'])*100:+.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "\n",
        "# Load and evaluate best ResNet101 model\n",
        "print(\"üî¥ Evaluating Best ResNet101 Model\")\n",
        "print(\"=\"*50)\n",
        "best_resnet101_path = os.path.join(resnet101_results['checkpoint_dir'], \"best_model.pth\")\n",
        "best_resnet101 = load_best_model(best_resnet101_path, 'resnet101', NUM_CLASSES)\n",
        "resnet101_test_acc, resnet101_preds, resnet101_labels = evaluate_model(best_resnet101, test_loader, EMOTION_CLASSES)\n",
        "\n",
        "print(f\"\\nüéØ ResNet101 Test Results:\")\n",
        "print(f\"   Test Accuracy: {resnet101_test_acc:.4f} ({resnet101_test_acc*100:.2f}%)\")\n",
        "print(f\"   Training Best: {resnet101_results['best_acc']:.4f} ({resnet101_results['best_acc']*100:.2f}%)\")\n",
        "print(f\"   Difference: {(resnet101_test_acc - resnet101_results['best_acc'])*100:+.2f}%\")"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìà Step 10: Final Analysis & Classification Report\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Detailed classification report\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "# Classification reports\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üìä DETAILED CLASSIFICATION REPORTS\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "print(\"\\nüîµ ResNet50 Classification Report:\")\n",
        "print(\"-\" * 60)\n",
        "print(classification_report(resnet50_labels, resnet50_preds, target_names=EMOTION_CLASSES, digits=4))\n",
        "\n",
        "print(\"\\nüî¥ ResNet101 Classification Report:\")\n",
        "print(\"-\" * 60)\n",
        "print(classification_report(resnet101_labels, resnet101_preds, target_names=EMOTION_CLASSES, digits=4))\n",
        "\n",
        "# Confusion matrices\n",
        "plt.figure(figsize=(15, 6))\n",
        "\n",
        "# ResNet50 confusion matrix\n",
        "plt.subplot(1, 2, 1)\n",
        "cm_resnet50 = confusion_matrix(resnet50_labels, resnet50_preds)\n",
        "sns.heatmap(cm_resnet50, annot=True, fmt='d', cmap='Blues', \n",
        "           xticklabels=EMOTION_CLASSES, yticklabels=EMOTION_CLASSES)\n",
        "plt.title('üîµ ResNet50 Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "# ResNet101 confusion matrix\n",
        "plt.subplot(1, 2, 2)\n",
        "cm_resnet101 = confusion_matrix(resnet101_labels, resnet101_preds)\n",
        "sns.heatmap(cm_resnet101, annot=True, fmt='d', cmap='Reds',\n",
        "           xticklabels=EMOTION_CLASSES, yticklabels=EMOTION_CLASSES)\n",
        "plt.title('üî¥ ResNet101 Confusion Matrix', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Final summary\n",
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"üèÜ FINAL MODEL COMPARISON SUMMARY\")\n",
        "print(\"=\"*80)\n",
        "print(f\"üìä Dataset: {NUM_CLASSES}-class Dog Emotion Classification\")\n",
        "print(f\"üè∑Ô∏è  Classes: {EMOTION_CLASSES}\")\n",
        "print(f\"üñºÔ∏è  Total samples: {len(dataset)} (training) + {len(test_dataset)} (test)\")\n",
        "print(f\"‚öôÔ∏è  Configuration: 30 epochs, ImageNet pretrained, Adam optimizer\")\n",
        "print()\n",
        "print(\"üìà Training Performance:\")\n",
        "print(f\"   ResNet50  - Best: {resnet50_results['best_acc']*100:.2f}% | Time: {resnet50_results['total_time']/60:.1f}m\")\n",
        "print(f\"   ResNet101 - Best: {resnet101_results['best_acc']*100:.2f}% | Time: {resnet101_results['total_time']/60:.1f}m\")\n",
        "print()\n",
        "print(\"üéØ Test Performance:\")\n",
        "print(f\"   ResNet50  - Test: {resnet50_test_acc*100:.2f}%\")\n",
        "print(f\"   ResNet101 - Test: {resnet101_test_acc*100:.2f}%\")\n",
        "print()\n",
        "print(\"üèÜ Winner:\")\n",
        "if resnet101_test_acc > resnet50_test_acc:\n",
        "    winner = \"ResNet101\"\n",
        "    diff = (resnet101_test_acc - resnet50_test_acc) * 100\n",
        "    print(f\"   ü•á ResNet101 wins by {diff:.2f}% on test set\")\n",
        "elif resnet50_test_acc > resnet101_test_acc:\n",
        "    winner = \"ResNet50\"\n",
        "    diff = (resnet50_test_acc - resnet101_test_acc) * 100\n",
        "    print(f\"   ü•á ResNet50 wins by {diff:.2f}% on test set\")\n",
        "else:\n",
        "    winner = \"Tie\"\n",
        "    print(f\"   ü§ù Both models achieved the same test accuracy\")\n",
        "\n",
        "print()\n",
        "print(\"üíæ Saved Models:\")\n",
        "print(f\"   ResNet50:  {resnet50_results['checkpoint_dir']}/best_model.pth\")\n",
        "print(f\"   ResNet101: {resnet101_results['checkpoint_dir']}/best_model.pth\")\n",
        "print(\"\\n‚úÖ Training and evaluation completed successfully!\")\n",
        "print(\"=\"*80)"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ Step 11: Model Usage Examples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example usage of trained models\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"üß™ MODEL USAGE EXAMPLES\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "# Function to predict single image\n",
        "def predict_single_image(model, image_path, emotion_classes, transform):\n",
        "    \"\"\"Predict emotion for a single image\"\"\"\n",
        "    try:\n",
        "        # Load and preprocess image\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        \n",
        "        # Predict\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            probabilities = torch.nn.functional.softmax(outputs, dim=1)\n",
        "            confidence, predicted = torch.max(probabilities, 1)\n",
        "            \n",
        "        predicted_emotion = emotion_classes[predicted.item()]\n",
        "        confidence_score = confidence.item()\n",
        "        \n",
        "        return predicted_emotion, confidence_score, probabilities.cpu().numpy()[0]\n",
        "    except Exception as e:\n",
        "        print(f\"Error predicting image {image_path}: {e}\")\n",
        "        return None, 0, None\n",
        "\n",
        "# Show how to use the custom module functions\n",
        "print(\"\\nüìù Using Custom Module Functions:\")\n",
        "print(\"\\n# Load ResNet50 model from checkpoint\")\n",
        "print(f\"resnet50_model = load_resnet50_model('{best_resnet50_path}')\")\n",
        "print(\"\\n# Load ResNet101 model from checkpoint\")\n",
        "print(f\"resnet101_model = load_resnet101_model('{best_resnet101_path}')\")\n",
        "print(\"\\n# Predict with ResNet50\")\n",
        "print(\"emotion, confidence = predict_emotion_resnet50(image_path, resnet50_model)\")\n",
        "print(\"\\n# Predict with ResNet101\")\n",
        "print(\"emotion, confidence = predict_emotion_resnet101(image_path, resnet101_model)\")\n",
        "\n",
        "print(\"\\nüéØ Model Performance Summary:\")\n",
        "print(f\"   Best ResNet50:  {resnet50_test_acc*100:.2f}% test accuracy\")\n",
        "print(f\"   Best ResNet101: {resnet101_test_acc*100:.2f}% test accuracy\")\n",
        "print(f\"   Classes: {EMOTION_CLASSES}\")\n",
        "print(f\"   Input size: 224x224 RGB\")\n",
        "print(f\"   Preprocessing: ImageNet normalization\")\n",
        "\n",
        "print(\"\\n‚úÖ Models are ready for inference!\")\n",
        "print(\"   Use the checkpoint files for deployment or further fine-tuning.\")\n",
        "print(\"   Both models use ImageNet pretrained weights and are optimized for dog emotion recognition.\")\n",
        "print(\"=\"*60)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}