{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ğŸ• Dog Emotion Classification - Pure50 Training on Colab\n",
        "\n",
        "Notebook nÃ y sáº½:\n",
        "1. **CÃ i Ä‘áº·t dependencies** vÃ  clone repository\n",
        "2. **Test package** `dog_emotion_classification` vá»›i Pure modules\n",
        "3. **Train Pure50** model cho dog emotion classification\n",
        "4. **Evaluate vÃ  test** model Ä‘Ã£ trained\n",
        "\n",
        "---\n",
        "**Author**: Dog Emotion Research Team  \n",
        "**Date**: 2025  \n",
        "**Runtime**: Google Colab (GPU recommended)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“‹ Step 1: Setup Environment & Dependencies\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install opencv-python-headless pillow pandas tqdm gdown albumentations matplotlib seaborn\n",
        "\n",
        "# Check GPU availability\n",
        "import torch\n",
        "print(f\"ğŸ”¥ PyTorch version: {torch.__version__}\")\n",
        "print(f\"ğŸš€ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"ğŸ¯ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"ğŸ’¾ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "else:\n",
        "    print(\"âš ï¸ Using CPU - training will be slower\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Clone repository with the Pure package\n",
        "import os\n",
        "\n",
        "REPO_URL = \"https://github.com/your_username/dog-emotion-recognition-hybrid.git\"  # Replace with actual repo\n",
        "REPO_NAME = \"dog-emotion-recognition-hybrid\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    print(f\"ğŸ“¥ Cloning repository from {REPO_URL}\")\n",
        "    !git clone {REPO_URL}\n",
        "else:\n",
        "    print(f\"âœ… Repository already exists: {REPO_NAME}\")\n",
        "\n",
        "# Change to repository directory\n",
        "os.chdir(REPO_NAME)\n",
        "print(f\"ğŸ“ Current directory: {os.getcwd()}\")\n",
        "print(f\"ğŸ“‚ Repository contents:\")\n",
        "!ls -la\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ§ª Step 2: Test Pure Package\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test package imports\n",
        "print(\"ğŸ” Testing package imports...\")\n",
        "\n",
        "try:\n",
        "    from dog_emotion_classification.pure import (\n",
        "        Pure18, Pure34, Pure50, Pure101, Pure152, \n",
        "        get_pure_model, PureTrainer, get_pure_transforms,\n",
        "        predict_emotion_pure, load_pure_model, download_model\n",
        "    )\n",
        "    print(\"âœ… Pure module imported successfully!\")\n",
        "    \n",
        "    # Test legacy module too\n",
        "    from dog_emotion_classification.pure34 import PURe34, predict_emotion_pure34\n",
        "    print(\"âœ… Legacy Pure34 module imported successfully!\")\n",
        "    \n",
        "except ImportError as e:\n",
        "    print(f\"âŒ Import error: {e}\")\n",
        "    print(\"ğŸ”§ Trying to add current directory to path...\")\n",
        "    import sys\n",
        "    sys.path.append('/content/dog-emotion-recognition-hybrid')\n",
        "    \n",
        "    # Retry imports\n",
        "    from dog_emotion_classification.pure import (\n",
        "        Pure18, Pure34, Pure50, Pure101, Pure152, \n",
        "        get_pure_model, PureTrainer, get_pure_transforms,\n",
        "        predict_emotion_pure, load_pure_model, download_model\n",
        "    )\n",
        "    print(\"âœ… Pure module imported after path fix!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test model creation for different architectures\n",
        "print(\"ğŸ—ï¸ Testing Pure model creation...\")\n",
        "\n",
        "architectures = ['pure18', 'pure34', 'pure50', 'pure101', 'pure152']\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "print(f\"ğŸ“Š Model Architecture Comparison:\")\n",
        "print(\"=\"*60)\n",
        "print(f\"{'Architecture':<12} {'Parameters':<12} {'Memory (MB)':<12} {'Status'}\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for arch in architectures:\n",
        "    try:\n",
        "        model = get_pure_model(arch, num_classes=4, input_size=512)\n",
        "        params = sum(p.numel() for p in model.parameters())\n",
        "        \n",
        "        # Estimate memory usage\n",
        "        model_size = sum(p.numel() * p.element_size() for p in model.parameters()) / (1024**2)\n",
        "        \n",
        "        print(f\"{arch.upper():<12} {params/1e6:.1f}M{'':<7} {model_size:.1f}MB{'':<7} âœ…\")\n",
        "        \n",
        "        # Test forward pass with dummy data\n",
        "        dummy_input = torch.randn(1, 3, 512, 512)\n",
        "        with torch.no_grad():\n",
        "            output = model(dummy_input)\n",
        "            assert output.shape == (1, 4), f\"Expected (1, 4), got {output.shape}\"\n",
        "        \n",
        "        del model  # Free memory\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"{arch.upper():<12} {'Error':<12} {'N/A':<12} âŒ {str(e)[:30]}...\")\n",
        "\n",
        "print(\"=\"*60)\n",
        "print(\"âœ… Model creation tests completed!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“Š Step 3: Download & Prepare Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download dataset\n",
        "import zipfile\n",
        "\n",
        "DATASET_ID = \"1ZAgz5u64i3LDbwMFpBXjzsKt6FrhNGdW\"  # Cropped dog emotion dataset\n",
        "DATASET_ZIP = \"cropped_dataset_4k_face.zip\"\n",
        ""cropped_dataset_4k_face" = \"data\"\n",
        "\n",
        "print(\"ğŸ“¥ Downloading dog emotion dataset...\")\n",
        "\n",
        "# Download using gdown\n",
        "if not os.path.exists(DATASET_ZIP):\n",
        "    !gdown {DATASET_ID} -O {DATASET_ZIP}\n",
        "    print(f\"âœ… Dataset downloaded: {DATASET_ZIP}\")\n",
        "else:\n",
        "    print(f\"âœ… Dataset already exists: {DATASET_ZIP}\")\n",
        "\n",
        "# Extract dataset\n",
        "if not os.path.exists("cropped_dataset_4k_face"):\n",
        "    print(\"ğŸ“‚ Extracting dataset...\")\n",
        "    with zipfile.ZipFile(DATASET_ZIP, 'r') as zip_ref:\n",
        "        zip_ref.extractall(".")\n",
        "    print(\"âœ… Dataset extracted successfully\")\n",
        "else:\n",
        "    print(f\"âœ… Dataset already extracted: {"cropped_dataset_4k_face"}\")\n",
        "\n",
        "# Check dataset structure\n",
        "data_root = os.path.join("cropped_dataset_4k_face", \"cropped_dataset_4k_face\", \"Dog Emotion\")\n",
        "labels_csv = os.path.join(data_root, \"labels.csv\")\n",
        "\n",
        "print(f\"\\nğŸ“‚ Dataset structure:\")\n",
        "if os.path.exists(data_root):\n",
        "    print(f\"   Data root: {data_root}\")\n",
        "    emotions = [d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))]\n",
        "    print(f\"   Emotion classes: {emotions}\")\n",
        "    \n",
        "    for emotion in emotions:\n",
        "        emotion_path = os.path.join(data_root, emotion)\n",
        "        if os.path.isdir(emotion_path):\n",
        "            count = len([f for f in os.listdir(emotion_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "            print(f\"     {emotion}: {count} images\")\n",
        "            \n",
        "    if os.path.exists(labels_csv):\n",
        "        print(f\"   Labels CSV: âœ… {labels_csv}\")\n",
        "    else:\n",
        "        print(f\"   Labels CSV: âŒ Not found\")\n",
        "else:\n",
        "    print(f\"âŒ Data root not found: {data_root}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸš€ Step 4: Train Pure50 Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create dataset and Pure50 model for training\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "\n",
        "class DogEmotionDataset(Dataset):\n",
        "    def __init__(self, root, labels_csv, transform=None):\n",
        "        self.root = root\n",
        "        df = pd.read_csv(labels_csv)\n",
        "        self.items = df[['filename', 'label']].values\n",
        "        unique_labels = sorted(df['label'].unique())\n",
        "        self.label2index = {name: i for i, name in enumerate(unique_labels)}\n",
        "        self.transform = transform\n",
        "        print(f\"ğŸ“Š Dataset: {len(self.items)} samples, Classes: {list(self.label2index.keys())}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fn, label_str = self.items[idx]\n",
        "        label_idx = self.label2index[label_str]\n",
        "        img_path = os.path.join(self.root, label_str, fn)\n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            return img, label_idx\n",
        "        except:\n",
        "            # Fallback for corrupted images\n",
        "            img = self.transform(Image.new('RGB', (512, 512), (0, 0, 0))) if self.transform else torch.zeros(3, 512, 512)\n",
        "            return img, label_idx\n",
        "\n",
        "# Create dataset and model\n",
        "print(\"ğŸ”„ Setting up training...\")\n",
        "train_transform = get_pure_transforms(input_size=512, is_training=True)\n",
        "dataset = DogEmotionDataset(data_root, labels_csv, train_transform)\n",
        "train_loader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "NUM_CLASSES = len(dataset.label2index)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "model = get_pure_model('pure50', num_classes=NUM_CLASSES, input_size=512)\n",
        "\n",
        "print(f\"âœ… Setup completed:\")\n",
        "print(f\"   Model: Pure50, Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"   Dataset: {len(dataset)} samples, {len(train_loader)} batches\")\n",
        "print(f\"   Device: {device}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train Pure50 model using PureTrainer\n",
        "print(\"ğŸš€ Starting Pure50 training...\")\n",
        "\n",
        "# Training configuration\n",
        "EPOCHS = 20  # Reduced for Colab demo\n",
        "CHECKPOINT_DIR = \"checkpoints\"\n",
        "\n",
        "# Create and setup trainer\n",
        "trainer = PureTrainer(model=model, device=device, checkpoint_dir=CHECKPOINT_DIR)\n",
        "trainer.setup_training(learning_rate=1e-4, weight_decay=1e-4, step_size=7, gamma=0.1)\n",
        "\n",
        "print(f\"ğŸ‹ï¸ Training configuration:\")\n",
        "print(f\"   Epochs: {EPOCHS}\")\n",
        "print(f\"   Learning rate: 1e-4\")\n",
        "print(f\"   Device: {device}\")\n",
        "print(f\"   Checkpoint dir: {CHECKPOINT_DIR}\")\n",
        "\n",
        "# Start training\n",
        "import time\n",
        "start_time = time.time()\n",
        "\n",
        "try:\n",
        "    trainer.train(\n",
        "        train_loader=train_loader,\n",
        "        val_loader=None,  # No validation split for this demo\n",
        "        epochs=EPOCHS,\n",
        "        save_best=True,\n",
        "        save_interval=5\n",
        "    )\n",
        "    \n",
        "    total_time = time.time() - start_time\n",
        "    print(f\"\\nğŸ‰ Training completed!\")\n",
        "    print(f\"   Total time: {total_time/60:.1f} minutes\")\n",
        "    print(f\"   Best accuracy: {trainer.best_acc:.4f}\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"\\nâŒ Training failed: {e}\")\n",
        "    print(f\"   Current best accuracy: {trainer.best_acc:.4f}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ“Š Step 5: Test & Evaluate Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Test trained Pure50 model\n",
        "print(\"ğŸ§ª Testing trained Pure50 model...\")\n",
        "\n",
        "# Load best model\n",
        "best_checkpoint = os.path.join(CHECKPOINT_DIR, \"best_model.pth\")\n",
        "try:\n",
        "    trained_model, test_transform = load_pure_model(\n",
        "        model_path=best_checkpoint,\n",
        "        architecture='pure50',\n",
        "        num_classes=NUM_CLASSES,\n",
        "        input_size=512,\n",
        "        device=device\n",
        "    )\n",
        "    print(f\"âœ… Loaded best model for testing\")\n",
        "except:\n",
        "    print(\"âš ï¸ Using current training model\")\n",
        "    trained_model = model\n",
        "    test_transform = get_pure_transforms(512, is_training=False)\n",
        "\n",
        "# Test on sample images\n",
        "emotion_classes = list(dataset.label2index.keys())\n",
        "sample_images = {}\n",
        "\n",
        "for emotion in emotion_classes:\n",
        "    emotion_path = os.path.join(data_root, emotion)\n",
        "    if os.path.isdir(emotion_path):\n",
        "        image_files = [f for f in os.listdir(emotion_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if image_files:\n",
        "            sample_images[emotion] = os.path.join(emotion_path, image_files[0])\n",
        "\n",
        "print(f\"\\nğŸ“· Testing on {len(sample_images)} sample images:\")\n",
        "print(\"=\"*60)\n",
        "\n",
        "for true_emotion, image_path in sample_images.items():\n",
        "    print(f\"\\nğŸ–¼ï¸ Testing: {os.path.basename(image_path)} (True: {true_emotion})\")\n",
        "    \n",
        "    try:\n",
        "        result = predict_emotion_pure(\n",
        "            image_path=image_path,\n",
        "            model=trained_model,\n",
        "            transform=test_transform,\n",
        "            device=device,\n",
        "            emotion_classes=emotion_classes\n",
        "        )\n",
        "        \n",
        "        if result['predicted']:\n",
        "            # Get predicted emotion\n",
        "            predicted_emotion = max((k, v) for k, v in result.items() if k != 'predicted')[0]\n",
        "            correct = predicted_emotion == true_emotion\n",
        "            \n",
        "            print(\"   ğŸ“Š Predictions:\")\n",
        "            sorted_emotions = sorted(result.items(), key=lambda x: x[1], reverse=True)\n",
        "            for emotion, score in sorted_emotions:\n",
        "                if emotion != 'predicted':\n",
        "                    indicator = \"ğŸ¯\" if emotion == true_emotion else \"  \"\n",
        "                    print(f\"     {indicator} {emotion}: {score:.3f}\")\n",
        "            \n",
        "            print(f\"   ğŸ† Predicted: {predicted_emotion} {'âœ…' if correct else 'âŒ'}\")\n",
        "        else:\n",
        "            print(\"   âŒ Prediction failed\")\n",
        "    except Exception as e:\n",
        "        print(f\"   âŒ Error: {e}\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"âœ… Testing completed!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ¯ Summary & Download Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training Summary and Download\n",
        "print(\"ğŸ¯ Pure50 Training Summary\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "print(f\"\\nğŸ—ï¸ Model Architecture:\")\n",
        "print(f\"   Architecture: Pure50 (Product Unit Residual Network)\")\n",
        "print(f\"   Block type: Bottleneck Product Blocks\")\n",
        "print(f\"   Layer config: [3, 4, 6, 3]\")\n",
        "print(f\"   Parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
        "print(f\"   Input size: 512x512\")\n",
        "print(f\"   Output classes: {NUM_CLASSES} emotions\")\n",
        "\n",
        "print(f\"\\nğŸ“Š Dataset Information:\")\n",
        "print(f\"   Total samples: {len(dataset):,}\")\n",
        "print(f\"   Emotion classes: {emotion_classes}\")\n",
        "print(f\"   Batch size: 8\")\n",
        "print(f\"   Training batches: {len(train_loader)}\")\n",
        "\n",
        "if hasattr(trainer, 'best_acc'):\n",
        "    print(f\"\\nğŸ† Training Results:\")\n",
        "    print(f\"   Best accuracy: {trainer.best_acc:.4f} ({trainer.best_acc*100:.2f}%)\")\n",
        "    if hasattr(trainer, 'train_losses') and len(trainer.train_losses) > 0:\n",
        "        print(f\"   Final loss: {trainer.train_losses[-1]:.4f}\")\n",
        "        print(f\"   Epochs completed: {len(trainer.train_losses)}\")\n",
        "\n",
        "print(f\"\\nğŸ’¾ Output Files:\")\n",
        "if os.path.exists(CHECKPOINT_DIR):\n",
        "    checkpoint_files = [f for f in os.listdir(CHECKPOINT_DIR) if f.endswith('.pth')]\n",
        "    for file in checkpoint_files:\n",
        "        file_path = os.path.join(CHECKPOINT_DIR, file)\n",
        "        file_size = os.path.getsize(file_path) / (1024**2)\n",
        "        print(f\"   {file}: {file_size:.1f} MB\")\n",
        "\n",
        "# Download for Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(f\"\\nğŸ“¥ Downloading trained model...\")\n",
        "    if os.path.exists(best_checkpoint):\n",
        "        files.download(best_checkpoint)\n",
        "        print(\"âœ… Model download completed!\")\n",
        "except ImportError:\n",
        "    print(f\"\\nğŸ’¾ Files saved locally in: {os.getcwd()}\")\n",
        "\n",
        "print(\"\\nğŸ”„ To use the trained model:\")\n",
        "print(\"```python\")\n",
        "print(\"from dog_emotion_classification.pure import load_pure_model, predict_emotion_pure\")\n",
        "print(\"\")\n",
        "print(\"# Load model\")\n",
        "print(\"model, transform = load_pure_model('best_model.pth', 'pure50', 4, 512)\")\n",
        "print(\"\")\n",
        "print(\"# Predict\")\n",
        "print(\"result = predict_emotion_pure('image.jpg', model, transform)\")\n",
        "print(\"print(result)\")\n",
        "print(\"```\")\n",
        "\n",
        "print(\"\\n\" + \"=\"*50)\n",
        "print(\"ğŸ‰ Pure50 training and testing completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## ğŸ‰ Conclusion\n",
        "\n",
        "### âœ… What we accomplished:\n",
        "\n",
        "1. **ğŸ§ª Package Testing**: Successfully tested the `dog_emotion_classification.pure` module\n",
        "2. **ğŸ—ï¸ Model Creation**: Created and tested Pure50 architecture (Bottleneck Product Blocks)\n",
        "3. **ğŸ“Š Data Processing**: Downloaded and prepared dog emotion dataset\n",
        "4. **ğŸš€ Training**: Trained Pure50 model with PureTrainer class\n",
        "5. **ğŸ“ˆ Evaluation**: Tested model predictions and analyzed results\n",
        "\n",
        "### ğŸ”¬ Pure50 Architecture Features:\n",
        "- **Product Units**: Multiplicative feature interactions instead of additive\n",
        "- **Bottleneck Blocks**: Efficient parameter usage with 1x1 â†’ 3x3 â†’ 1x1 convolutions\n",
        "- **No ReLU in Residual**: Pure networks don't use ReLU in product unit blocks\n",
        "- **512x512 Input**: High resolution for better emotion recognition\n",
        "\n",
        "### ğŸ“š Next Steps:\n",
        "1. **Try Different Architectures**: Pure18, Pure34, Pure101, Pure152\n",
        "2. **Hyperparameter Tuning**: Learning rate, batch size, augmentations\n",
        "3. **Data Augmentation**: More sophisticated transforms\n",
        "4. **Model Ensembling**: Combine multiple Pure architectures\n",
        "5. **Production Deployment**: Integrate with head detection pipeline\n",
        "\n",
        "---\n",
        "\n",
        "**ğŸ“– For detailed documentation, see: `PURE_MODULE_GUIDE.md`**\n",
        "\n",
        "**ğŸ• Happy Dog Emotion Recognition! ğŸ¯**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
