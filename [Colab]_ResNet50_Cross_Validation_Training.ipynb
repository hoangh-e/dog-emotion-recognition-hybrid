{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üêï Dog Emotion Classification - ResNet50 Cross-Validation Training\n",
        "\n",
        "Notebook n√†y s·∫Ω:\n",
        "1. **C√†i ƒë·∫∑t dependencies** v√† chu·∫©n b·ªã m√¥i tr∆∞·ªùng\n",
        "2. **Download dataset** dog emotion classification  \n",
        "3. **Train ResNet50** v·ªõi 50 epochs s·ª≠ d·ª•ng K-Fold Cross Validation\n",
        "4. **Evaluate** v·ªõi cross-validation scores v√† confusion matrix\n",
        "5. **Download models** v√† results v·ªÅ m√°y\n",
        "\n",
        "---\n",
        "**Author**: Dog Emotion Research Team  \n",
        "**Date**: 2025  \n",
        "**Runtime**: Google Colab (GPU T4/V100 recommended)  \n",
        "**Training**: ResNet50 v·ªõi ImageNet pretrained weights + Cross Validation\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîß Step 1: Setup Environment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Install required packages\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install opencv-python-headless pillow pandas tqdm gdown albumentations matplotlib seaborn\n",
        "!pip install scikit-learn\n",
        "\n",
        "# Check GPU and setup\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import json\n",
        "import zipfile\n",
        "\n",
        "print(f\"üî• PyTorch version: {torch.__version__}\")\n",
        "print(f\"üöÄ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéØ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Using CPU - training will be slower\")\n",
        "    device = torch.device('cpu')\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìä Step 2: Download & Prepare Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and extract dataset\n",
        "DATASET_ID = \"1ZAgz5u64i3LDbwMFpBXjzsKt6FrhNGdW\"\n",
        "DATASET_ZIP = \"cropped_dataset_4k_face.zip\"\n",
        "\n",
        "print(\"üì• Downloading dog emotion dataset...\")\n",
        "if not os.path.exists(DATASET_ZIP):\n",
        "    !gdown {DATASET_ID} -O {DATASET_ZIP}\n",
        "    print(f\"‚úÖ Dataset downloaded: {DATASET_ZIP}\")\n",
        "else:\n",
        "    print(f\"‚úÖ Dataset already exists: {DATASET_ZIP}\")\n",
        "\n",
        "# Extract dataset\n",
        "if not os.path.exists(\"cropped_dataset_4k_face\"):\n",
        "    print(\"üìÇ Extracting dataset...\")\n",
        "    with zipfile.ZipFile(DATASET_ZIP, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "    print(\"‚úÖ Dataset extracted successfully\")\n",
        "\n",
        "# Dataset paths\n",
        "data_root = os.path.join(\"cropped_dataset_4k_face\", \"Dog Emotion\")\n",
        "labels_csv = os.path.join(data_root, \"labels.csv\")\n",
        "\n",
        "print(f\"\\nüìÇ Dataset structure:\")\n",
        "emotions = [d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))]\n",
        "print(f\"   Emotion classes: {emotions}\")\n",
        "\n",
        "for emotion in emotions:\n",
        "    emotion_path = os.path.join(data_root, emotion)\n",
        "    if os.path.isdir(emotion_path):\n",
        "        count = len([f for f in os.listdir(emotion_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        print(f\"     {emotion}: {count} images\")\n",
        "\n",
        "print(f\"   Labels CSV: {'‚úÖ' if os.path.exists(labels_csv) else '‚ùå'} {labels_csv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Dataset class for cross-validation\n",
        "class DogEmotionDataset(Dataset):\n",
        "    def __init__(self, root, labels_csv, transform=None):\n",
        "        self.root = root\n",
        "        df = pd.read_csv(labels_csv)\n",
        "        self.items = df[['filename', 'label']].values\n",
        "        unique_labels = sorted(df['label'].unique())\n",
        "        self.label2index = {name: i for i, name in enumerate(unique_labels)}\n",
        "        self.index2label = {i: name for name, i in self.label2index.items()}\n",
        "        self.transform = transform\n",
        "        print(f\"üìä Dataset: {len(self.items)} samples\")\n",
        "        print(f\"üè∑Ô∏è  Classes: {list(self.label2index.keys())}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fn, label_str = self.items[idx]\n",
        "        label_idx = self.label2index[label_str]\n",
        "        img_path = os.path.join(self.root, label_str, fn)\n",
        "        \n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            return img, label_idx\n",
        "        except Exception as e:\n",
        "            # Fallback for corrupted images\n",
        "            img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            return img, label_idx\n",
        "\n",
        "# Create transforms for ResNet50 (224x224 ImageNet standard)\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create dataset\n",
        "dataset = DogEmotionDataset(data_root, labels_csv, train_transform)\n",
        "NUM_CLASSES = len(dataset.label2index)\n",
        "EMOTION_CLASSES = list(dataset.label2index.keys())\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset ready:\")\n",
        "print(f\"   Total samples: {len(dataset)}\")\n",
        "print(f\"   Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"   Emotion classes: {EMOTION_CLASSES}\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üîÑ Step 3: Cross-Validation Training Setup\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-validation configuration\n",
        "K_FOLDS = 5\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "print(f\"üîÑ Cross-Validation Configuration:\")\n",
        "print(f\"   K-Folds: {K_FOLDS}\")\n",
        "print(f\"   Epochs per fold: {EPOCHS}\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
        "\n",
        "# Prepare labels for stratified split\n",
        "labels = [dataset.label2index[item[1]] for item in dataset.items]\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Create stratified K-fold\n",
        "kfold = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "print(f\"\\nüìä Class distribution:\")\n",
        "unique, counts = np.unique(labels, return_counts=True)\n",
        "for i, (class_idx, count) in enumerate(zip(unique, counts)):\n",
        "    class_name = EMOTION_CLASSES[class_idx]\n",
        "    print(f\"   {class_name}: {count} samples ({count/len(labels)*100:.1f}%)\")\n",
        "\n",
        "# Results storage\n",
        "cv_results = {\n",
        "    'fold_accuracies': [],\n",
        "    'fold_losses': [],\n",
        "    'fold_train_histories': [],\n",
        "    'fold_val_histories': [],\n",
        "    'fold_predictions': [],\n",
        "    'fold_true_labels': [],\n",
        "    'models': []\n",
        "}\n",
        "\n",
        "print(f\"\\n‚úÖ Ready for {K_FOLDS}-fold cross-validation training!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training and evaluation functions\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train model for one epoch\"\"\"\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for images, labels in tqdm(dataloader, desc=\"Training\", leave=False):\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += labels.size(0)\n",
        "        correct += predicted.eq(labels).sum().item()\n",
        "    \n",
        "    accuracy = correct / total\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss, accuracy\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    \"\"\"Evaluate model\"\"\"\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predictions = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for images, labels in tqdm(dataloader, desc=\"Evaluating\", leave=False):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += labels.size(0)\n",
        "            correct += predicted.eq(labels).sum().item()\n",
        "            \n",
        "            all_predictions.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "    \n",
        "    accuracy = correct / total\n",
        "    avg_loss = total_loss / len(dataloader)\n",
        "    return avg_loss, accuracy, all_predictions, all_labels\n",
        "\n",
        "def create_model():\n",
        "    \"\"\"Create ResNet50 model\"\"\"\n",
        "    model = models.resnet50(pretrained=True)\n",
        "    model.fc = nn.Linear(model.fc.in_features, NUM_CLASSES)\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üöÄ Step 4: Cross-Validation Training\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create checkpoint directory\n",
        "os.makedirs(\"cv_checkpoints\", exist_ok=True)\n",
        "\n",
        "# Start cross-validation training\n",
        "print(\"üöÄ Starting 5-Fold Cross-Validation Training\")\n",
        "print(\"=\"*70)\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(np.arange(len(dataset)), labels)):\n",
        "    print(f\"\\nüîÑ FOLD {fold + 1}/{K_FOLDS}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Create data samplers\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    val_sampler = SubsetRandomSampler(val_idx)\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=2)\n",
        "    val_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=val_sampler, num_workers=2)\n",
        "    \n",
        "    # Create model for this fold\n",
        "    model = create_model()\n",
        "    model.to(device)\n",
        "    \n",
        "    # Training setup\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
        "    \n",
        "    # Training history for this fold\n",
        "    train_losses = []\n",
        "    train_accuracies = []\n",
        "    val_losses = []\n",
        "    val_accuracies = []\n",
        "    best_val_acc = 0.0\n",
        "    \n",
        "    print(f\"üìä Fold {fold + 1} - Train: {len(train_idx)} samples, Val: {len(val_idx)} samples\")\n",
        "    \n",
        "    # Training loop\n",
        "    start_time = time.time()\n",
        "    for epoch in range(EPOCHS):\n",
        "        # Training\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        train_losses.append(train_loss)\n",
        "        train_accuracies.append(train_acc)\n",
        "        \n",
        "        # Validation\n",
        "        val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion, device)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accuracies.append(val_acc)\n",
        "        \n",
        "        # Scheduler step\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Save best model for this fold\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'val_accuracy': val_acc,\n",
        "                'fold': fold\n",
        "            }, f\"cv_checkpoints/best_model_fold_{fold + 1}.pth\")\n",
        "        \n",
        "        # Progress update every 10 epochs\n",
        "        if (epoch + 1) % 10 == 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            eta = elapsed * (EPOCHS - epoch - 1) / (epoch + 1)\n",
        "            print(f\"  Epoch {epoch+1:2d}/{EPOCHS} | \"\n",
        "                  f\"Train: {train_acc:.4f} | Val: {val_acc:.4f} | \"\n",
        "                  f\"Time: {elapsed/60:.1f}m | ETA: {eta/60:.1f}m\")\n",
        "    \n",
        "    # Final evaluation on validation set\n",
        "    model.load_state_dict(torch.load(f\"cv_checkpoints/best_model_fold_{fold + 1}.pth\")['model_state_dict'])\n",
        "    final_val_loss, final_val_acc, val_predictions, val_true_labels = evaluate_model(\n",
        "        model, val_loader, criterion, device\n",
        "    )\n",
        "    \n",
        "    # Store results\n",
        "    cv_results['fold_accuracies'].append(final_val_acc)\n",
        "    cv_results['fold_losses'].append(final_val_loss)\n",
        "    cv_results['fold_train_histories'].append({'loss': train_losses, 'accuracy': train_accuracies})\n",
        "    cv_results['fold_val_histories'].append({'loss': val_losses, 'accuracy': val_accuracies})\n",
        "    cv_results['fold_predictions'].append(val_predictions)\n",
        "    cv_results['fold_true_labels'].append(val_true_labels)\n",
        "    cv_results['models'].append(f\"cv_checkpoints/best_model_fold_{fold + 1}.pth\")\n",
        "    \n",
        "    print(f\"‚úÖ Fold {fold + 1} completed - Best Val Accuracy: {final_val_acc:.4f}\")\n",
        "\n",
        "# Calculate cross-validation statistics\n",
        "mean_accuracy = np.mean(cv_results['fold_accuracies'])\n",
        "std_accuracy = np.std(cv_results['fold_accuracies'])\n",
        "mean_loss = np.mean(cv_results['fold_losses'])\n",
        "\n",
        "print(f\"\\nüéâ CROSS-VALIDATION COMPLETED!\")\n",
        "print(\"=\"*70)\n",
        "print(f\"üìä Results Summary:\")\n",
        "print(f\"   Mean Accuracy: {mean_accuracy:.4f} ¬± {std_accuracy:.4f}\")\n",
        "print(f\"   Mean Loss: {mean_loss:.4f}\")\n",
        "print(f\"   Accuracy Range: {min(cv_results['fold_accuracies']):.4f} - {max(cv_results['fold_accuracies']):.4f}\")\n",
        "\n",
        "for fold, acc in enumerate(cv_results['fold_accuracies']):\n",
        "    print(f\"   Fold {fold + 1}: {acc:.4f}\")\n",
        "\n",
        "print(f\"\\nüíæ Saved {K_FOLDS} models in cv_checkpoints/ directory\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üìä Step 5: Results Visualization & Analysis\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize cross-validation results\n",
        "fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
        "\n",
        "# 1. Training curves for each fold\n",
        "ax1 = axes[0, 0]\n",
        "for fold in range(K_FOLDS):\n",
        "    epochs = range(1, EPOCHS + 1)\n",
        "    ax1.plot(epochs, cv_results['fold_train_histories'][fold]['accuracy'], \n",
        "             label=f'Fold {fold+1}', alpha=0.7)\n",
        "ax1.set_title('Training Accuracy by Fold', fontweight='bold')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Accuracy')\n",
        "ax1.legend()\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Validation curves for each fold\n",
        "ax2 = axes[0, 1]\n",
        "for fold in range(K_FOLDS):\n",
        "    epochs = range(1, EPOCHS + 1)\n",
        "    ax2.plot(epochs, cv_results['fold_val_histories'][fold]['accuracy'], \n",
        "             label=f'Fold {fold+1}', alpha=0.7)\n",
        "ax2.set_title('Validation Accuracy by Fold', fontweight='bold')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy')\n",
        "ax2.legend()\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Cross-validation accuracy distribution\n",
        "ax3 = axes[0, 2]\n",
        "fold_numbers = range(1, K_FOLDS + 1)\n",
        "bars = ax3.bar(fold_numbers, cv_results['fold_accuracies'], alpha=0.7, color='skyblue')\n",
        "ax3.axhline(y=mean_accuracy, color='red', linestyle='--', label=f'Mean: {mean_accuracy:.4f}')\n",
        "ax3.set_title('Final Accuracy by Fold', fontweight='bold')\n",
        "ax3.set_xlabel('Fold')\n",
        "ax3.set_ylabel('Accuracy')\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3, axis='y')\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, cv_results['fold_accuracies']):\n",
        "    height = bar.get_height()\n",
        "    ax3.text(bar.get_x() + bar.get_width()/2., height + 0.005, f'{acc:.3f}',\n",
        "             ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 4. Loss curves comparison\n",
        "ax4 = axes[1, 0]\n",
        "for fold in range(K_FOLDS):\n",
        "    epochs = range(1, EPOCHS + 1)\n",
        "    ax4.plot(epochs, cv_results['fold_train_histories'][fold]['loss'], \n",
        "             label=f'Train Fold {fold+1}', alpha=0.5, linestyle='-')\n",
        "    ax4.plot(epochs, cv_results['fold_val_histories'][fold]['loss'], \n",
        "             label=f'Val Fold {fold+1}', alpha=0.5, linestyle='--')\n",
        "ax4.set_title('Training vs Validation Loss', fontweight='bold')\n",
        "ax4.set_xlabel('Epoch')\n",
        "ax4.set_ylabel('Loss')\n",
        "ax4.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# 5. Combined confusion matrix\n",
        "ax5 = axes[1, 1]\n",
        "all_predictions = np.concatenate(cv_results['fold_predictions'])\n",
        "all_true_labels = np.concatenate(cv_results['fold_true_labels'])\n",
        "cm = confusion_matrix(all_true_labels, all_predictions)\n",
        "cm_normalized = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "sns.heatmap(cm_normalized, annot=True, fmt='.3f', cmap='Blues', \n",
        "            xticklabels=EMOTION_CLASSES, yticklabels=EMOTION_CLASSES, ax=ax5)\n",
        "ax5.set_title('Normalized Confusion Matrix (All Folds)', fontweight='bold')\n",
        "ax5.set_xlabel('Predicted')\n",
        "ax5.set_ylabel('True')\n",
        "\n",
        "# 6. Accuracy statistics\n",
        "ax6 = axes[1, 2]\n",
        "ax6.text(0.1, 0.9, f'Cross-Validation Results', fontweight='bold', fontsize=14, transform=ax6.transAxes)\n",
        "ax6.text(0.1, 0.8, f'Mean Accuracy: {mean_accuracy:.4f}', fontsize=12, transform=ax6.transAxes)\n",
        "ax6.text(0.1, 0.7, f'Std Accuracy: {std_accuracy:.4f}', fontsize=12, transform=ax6.transAxes)\n",
        "ax6.text(0.1, 0.6, f'95% CI: [{mean_accuracy - 1.96*std_accuracy:.4f}, {mean_accuracy + 1.96*std_accuracy:.4f}]', \n",
        "         fontsize=12, transform=ax6.transAxes)\n",
        "ax6.text(0.1, 0.5, f'Min Accuracy: {min(cv_results[\"fold_accuracies\"]):.4f}', fontsize=12, transform=ax6.transAxes)\n",
        "ax6.text(0.1, 0.4, f'Max Accuracy: {max(cv_results[\"fold_accuracies\"]):.4f}', fontsize=12, transform=ax6.transAxes)\n",
        "ax6.text(0.1, 0.3, f'Epochs per fold: {EPOCHS}', fontsize=12, transform=ax6.transAxes)\n",
        "ax6.text(0.1, 0.2, f'Dataset size: {len(dataset)} images', fontsize=12, transform=ax6.transAxes)\n",
        "ax6.text(0.1, 0.1, f'Classes: {NUM_CLASSES} emotions', fontsize=12, transform=ax6.transAxes)\n",
        "ax6.set_xlim(0, 1)\n",
        "ax6.set_ylim(0, 1)\n",
        "ax6.axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print detailed classification report\n",
        "print(\"\\nüìã DETAILED CLASSIFICATION REPORT\")\n",
        "print(\"=\"*60)\n",
        "report = classification_report(all_true_labels, all_predictions, \n",
        "                             target_names=EMOTION_CLASSES, digits=4)\n",
        "print(report)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save comprehensive results to JSON\n",
        "results_summary = {\n",
        "    'experiment_info': {\n",
        "        'model': 'ResNet50',\n",
        "        'epochs_per_fold': EPOCHS,\n",
        "        'k_folds': K_FOLDS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'dataset_size': len(dataset),\n",
        "        'num_classes': NUM_CLASSES,\n",
        "        'emotion_classes': EMOTION_CLASSES\n",
        "    },\n",
        "    'cross_validation_results': {\n",
        "        'mean_accuracy': float(mean_accuracy),\n",
        "        'std_accuracy': float(std_accuracy),\n",
        "        'fold_accuracies': [float(acc) for acc in cv_results['fold_accuracies']],\n",
        "        'fold_losses': [float(loss) for loss in cv_results['fold_losses']],\n",
        "        'confidence_interval_95': [\n",
        "            float(mean_accuracy - 1.96*std_accuracy), \n",
        "            float(mean_accuracy + 1.96*std_accuracy)\n",
        "        ]\n",
        "    },\n",
        "    'classification_metrics': {\n",
        "        'confusion_matrix': cm.tolist(),\n",
        "        'classification_report': report\n",
        "    },\n",
        "    'model_paths': cv_results['models']\n",
        "}\n",
        "\n",
        "# Save results\n",
        "with open('cv_results_summary.json', 'w') as f:\n",
        "    json.dump(results_summary, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Results saved to cv_results_summary.json\")\n",
        "\n",
        "# Create ensemble model by averaging predictions\n",
        "print(\"\\nüîÑ Creating ensemble model from all folds...\")\n",
        "\n",
        "def predict_ensemble(image_path, model_paths, transform, device):\n",
        "    \"\"\"Predict using ensemble of all fold models\"\"\"\n",
        "    all_probs = []\n",
        "    \n",
        "    for model_path in model_paths:\n",
        "        # Load model\n",
        "        model = create_model()\n",
        "        checkpoint = torch.load(model_path, map_location=device)\n",
        "        model.load_state_dict(checkpoint['model_state_dict'])\n",
        "        model.to(device)\n",
        "        model.eval()\n",
        "        \n",
        "        # Predict\n",
        "        image = Image.open(image_path).convert('RGB')\n",
        "        input_tensor = transform(image).unsqueeze(0).to(device)\n",
        "        \n",
        "        with torch.no_grad():\n",
        "            outputs = model(input_tensor)\n",
        "            probabilities = torch.softmax(outputs, dim=1).cpu().numpy()[0]\n",
        "            all_probs.append(probabilities)\n",
        "    \n",
        "    # Average predictions\n",
        "    ensemble_probs = np.mean(all_probs, axis=0)\n",
        "    predicted_class = np.argmax(ensemble_probs)\n",
        "    \n",
        "    return predicted_class, ensemble_probs\n",
        "\n",
        "# Test ensemble on a few sample images\n",
        "print(\"üß™ Testing ensemble model on sample images...\")\n",
        "sample_results = []\n",
        "\n",
        "for emotion in EMOTION_CLASSES[:2]:  # Test on first 2 emotions\n",
        "    emotion_path = os.path.join(data_root, emotion)\n",
        "    if os.path.isdir(emotion_path):\n",
        "        image_files = [f for f in os.listdir(emotion_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
        "        if image_files:\n",
        "            sample_image = os.path.join(emotion_path, image_files[0])\n",
        "            pred_class, pred_probs = predict_ensemble(sample_image, cv_results['models'], val_transform, device)\n",
        "            \n",
        "            result = {\n",
        "                'image': sample_image,\n",
        "                'true_emotion': emotion,\n",
        "                'predicted_emotion': EMOTION_CLASSES[pred_class],\n",
        "                'confidence': float(pred_probs[pred_class]),\n",
        "                'all_probabilities': {EMOTION_CLASSES[i]: float(prob) for i, prob in enumerate(pred_probs)}\n",
        "            }\n",
        "            sample_results.append(result)\n",
        "            \n",
        "            print(f\"üì∑ {emotion}: {EMOTION_CLASSES[pred_class]} ({pred_probs[pred_class]:.3f} confidence)\")\n",
        "\n",
        "print(f\"\\nüíæ Models and results ready for download!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üì• Step 6: Download Models & Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download trained models and results\n",
        "try:\n",
        "    from google.colab import files\n",
        "    \n",
        "    print(\"üì¶ Downloading cross-validation results...\")\n",
        "    \n",
        "    # 1. Download the best model from best performing fold\n",
        "    best_fold_idx = np.argmax(cv_results['fold_accuracies'])\n",
        "    best_model_path = f\"cv_checkpoints/best_model_fold_{best_fold_idx + 1}.pth\"\n",
        "    \n",
        "    print(f\"üèÜ Best model: Fold {best_fold_idx + 1} (Accuracy: {cv_results['fold_accuracies'][best_fold_idx]:.4f})\")\n",
        "    files.download(best_model_path)\n",
        "    \n",
        "    # 2. Download results summary\n",
        "    files.download('cv_results_summary.json')\n",
        "    \n",
        "    # 3. Create and download a zip file with all models\n",
        "    import zipfile\n",
        "    with zipfile.ZipFile('all_cv_models.zip', 'w') as zipf:\n",
        "        for i in range(K_FOLDS):\n",
        "            model_path = f\"cv_checkpoints/best_model_fold_{i + 1}.pth\"\n",
        "            if os.path.exists(model_path):\n",
        "                zipf.write(model_path, f\"fold_{i + 1}_model.pth\")\n",
        "        zipf.write('cv_results_summary.json', 'cv_results_summary.json')\n",
        "    \n",
        "    files.download('all_cv_models.zip')\n",
        "    \n",
        "    # 4. Create inference script\n",
        "    inference_script = '''\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchvision.models as models\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import json\n",
        "\n",
        "def load_resnet50_model(model_path, num_classes=4):\n",
        "    \\\"\\\"\\\"Load ResNet50 model for emotion classification\\\"\\\"\\\"\n",
        "    model = models.resnet50(pretrained=False)\n",
        "    model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
        "    \n",
        "    checkpoint = torch.load(model_path, map_location='cpu')\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    model.eval()\n",
        "    \n",
        "    return model\n",
        "\n",
        "def predict_emotion(image_path, model, emotion_classes):\n",
        "    \\\"\\\"\\\"Predict emotion from image\\\"\\\"\\\"\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "    \n",
        "    image = Image.open(image_path).convert('RGB')\n",
        "    input_tensor = transform(image).unsqueeze(0)\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_tensor)\n",
        "        probabilities = torch.softmax(outputs, dim=1).numpy()[0]\n",
        "    \n",
        "    predicted_idx = probabilities.argmax()\n",
        "    confidence = probabilities[predicted_idx]\n",
        "    \n",
        "    return {\n",
        "        'predicted_emotion': emotion_classes[predicted_idx],\n",
        "        'confidence': float(confidence),\n",
        "        'all_probabilities': {emotion_classes[i]: float(prob) for i, prob in enumerate(probabilities)}\n",
        "    }\n",
        "\n",
        "# Example usage:\n",
        "if __name__ == \"__main__\":\n",
        "    # Load model\n",
        "    model = load_resnet50_model('best_model_fold_X.pth')  # Replace X with fold number\n",
        "    emotion_classes = ['angry', 'happy', 'relaxed', 'sad']  # Update based on your dataset\n",
        "    \n",
        "    # Predict\n",
        "    result = predict_emotion('your_image.jpg', model, emotion_classes)\n",
        "    print(f\"Predicted emotion: {result['predicted_emotion']} (confidence: {result['confidence']:.3f})\")\n",
        "'''\n",
        "    \n",
        "    with open('inference_script.py', 'w') as f:\n",
        "        f.write(inference_script)\n",
        "    \n",
        "    files.download('inference_script.py')\n",
        "    \n",
        "    print(\"‚úÖ Download completed! Files downloaded:\")\n",
        "    print(f\"   üìÑ {best_model_path} - Best performing model\")\n",
        "    print(f\"   üìÑ cv_results_summary.json - Complete results summary\")\n",
        "    print(f\"   üì¶ all_cv_models.zip - All 5 fold models + results\")\n",
        "    print(f\"   üêç inference_script.py - Python script for using the models\")\n",
        "\n",
        "except ImportError:\n",
        "    print(\"üíæ Running locally - models saved in cv_checkpoints/ directory\")\n",
        "    print(\"üìã Results summary saved in cv_results_summary.json\")\n",
        "    print(f\"üèÜ Best model: {best_model_path}\")\n",
        "    print(f\"   Best fold accuracy: {cv_results['fold_accuracies'][best_fold_idx]:.4f}\")\n",
        "    \n",
        "print(f\"\\nüéØ USAGE INSTRUCTIONS:\")\n",
        "print(f\"1. Load the best model: {best_model_path}\")\n",
        "print(f\"2. Use ResNet50 architecture with {NUM_CLASSES} classes\")\n",
        "print(f\"3. Input size: 224x224 pixels\")\n",
        "print(f\"4. Classes: {EMOTION_CLASSES}\")\n",
        "print(f\"5. Expected accuracy: {mean_accuracy:.4f} ¬± {std_accuracy:.4f}\")\n",
        "\n",
        "# Final summary\n",
        "print(f\"\\n\" + \"=\"*70)\n",
        "print(f\"üéâ RESNET50 CROSS-VALIDATION TRAINING COMPLETED!\")\n",
        "print(f\"üìä Final Results:\")\n",
        "print(f\"   ‚úÖ Mean CV Accuracy: {mean_accuracy:.4f} ¬± {std_accuracy:.4f}\")\n",
        "print(f\"   ‚úÖ Best Fold Accuracy: {max(cv_results['fold_accuracies']):.4f}\")\n",
        "print(f\"   ‚úÖ Total Training Time: ~{EPOCHS * K_FOLDS / 10:.0f} hours (estimated)\")\n",
        "print(f\"   ‚úÖ Models Trained: {K_FOLDS} ResNet50 models\")\n",
        "print(f\"   ‚úÖ Robust Evaluation: {K_FOLDS}-fold cross-validation\")\n",
        "print(f\"=\"*70)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## üéâ Conclusion\n",
        "\n",
        "### ‚úÖ What we accomplished:\n",
        "\n",
        "1. **üîß Environment Setup**: Configured Colab with PyTorch and required dependencies\n",
        "2. **üìä Dataset Preparation**: Downloaded and processed dog emotion dataset (4 classes)\n",
        "3. **üîÑ Cross-Validation**: Implemented 5-fold stratified cross-validation for robust evaluation\n",
        "4. **üöÄ ResNet50 Training**: Trained 50 epochs per fold with ImageNet pretrained weights\n",
        "5. **üìà Performance Analysis**: Comprehensive evaluation with accuracy, loss, and confusion matrix\n",
        "6. **üì¶ Model Ensemble**: Created ensemble predictions from all 5 folds\n",
        "7. **üì• Model Download**: Downloaded best models and inference scripts\n",
        "\n",
        "### üî¨ Key Features:\n",
        "\n",
        "**‚úÖ Robust Cross-Validation:**\n",
        "- **Stratified K-Fold**: Ensures balanced class distribution across folds\n",
        "- **Multiple Models**: 5 independent models for reliable performance estimation\n",
        "- **Statistical Analysis**: Mean accuracy with confidence intervals\n",
        "\n",
        "**üìä ResNet50 Benefits:**\n",
        "- **Transfer Learning**: ImageNet pretrained weights for faster convergence\n",
        "- **Proven Architecture**: Well-established CNN for image classification\n",
        "- **Balanced Performance**: Good accuracy with reasonable computational cost\n",
        "\n",
        "### üéØ Model Outputs:\n",
        "\n",
        "**Generated Files:**\n",
        "1. `best_model_fold_X.pth` - Best performing model from cross-validation\n",
        "2. `all_cv_models.zip` - All 5 fold models for ensemble use\n",
        "3. `cv_results_summary.json` - Complete experimental results and metrics\n",
        "4. `inference_script.py` - Ready-to-use Python script for predictions\n",
        "\n",
        "**Performance Metrics:**\n",
        "- **Cross-Validation Accuracy**: Statistical robust evaluation\n",
        "- **Confusion Matrix**: Per-class performance analysis  \n",
        "- **Training Curves**: Loss and accuracy progression visualization\n",
        "- **Classification Report**: Precision, recall, F1-score per emotion\n",
        "\n",
        "### üìö Usage & Next Steps:\n",
        "\n",
        "1. **Production Deployment**: Use best performing fold model for inference\n",
        "2. **Ensemble Inference**: Combine predictions from all 5 models for higher accuracy\n",
        "3. **Model Integration**: Integrate with existing dog emotion pipeline\n",
        "4. **Further Optimization**: Experiment with different architectures or hyperparameters\n",
        "5. **Data Augmentation**: Add more sophisticated augmentation techniques\n",
        "\n",
        "---\n",
        "\n",
        "**üìà Performance Summary**: ResNet50 with cross-validation provides statistically robust and reliable dog emotion classification with comprehensive evaluation metrics.\n",
        "\n",
        "**üêï Ready for Production Deployment! üéØ**\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
