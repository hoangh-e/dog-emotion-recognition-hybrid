# Pure Networks Module Guide

## T·ªïng quan

Module `dog_emotion_classification.pure` cung c·∫•p implementation ho√†n ch·ªânh c·ªßa **Product Unit Residual Networks (Pure)** cho b√†i to√°n ph√¢n lo·∫°i c·∫£m x√∫c ch√≥. Module h·ªó tr·ª£ nhi·ªÅu ki·∫øn tr√∫c kh√°c nhau v√† bao g·ªìm ƒë·∫ßy ƒë·ªß c√°c t√≠nh nƒÉng training v√† inference.

## C√°c Ki·∫øn tr√∫c ƒë∆∞·ª£c H·ªó tr·ª£

| Ki·∫øn tr√∫c | Blocks | M√¥ t·∫£ | Parameters (4 classes) |
|-----------|--------|--------|------------------------|
| **Pure18** | [2, 2, 2, 2] | Basic Product Blocks | ~11.2M |
| **Pure34** | [3, 4, 6, 3] | Basic Product Blocks | ~21.3M |
| **Pure50** | [3, 4, 6, 3] | Bottleneck Product Blocks | ~23.5M |
| **Pure101** | [3, 4, 23, 3] | Bottleneck Product Blocks | ~42.5M |
| **Pure152** | [3, 8, 36, 3] | Bottleneck Product Blocks | ~58.2M |

## C√†i ƒë·∫∑t v√† Import

```python
from dog_emotion_classification.pure import (
    # Model architectures
    Pure18, Pure34, Pure50, Pure101, Pure152, get_pure_model,
    # Training utilities
    PureTrainer, get_pure_transforms,
    # Inference utilities
    load_pure_model, predict_emotion_pure,
    # Download utilities
    download_pure_model
)
```

## 1. T·∫°o Model

### C√°ch 1: S·ª≠ d·ª•ng Constructor tr·ª±c ti·∫øp

```python
# T·∫°o c√°c model c·ª• th·ªÉ
model = Pure34(num_classes=4, input_size=512)
model = Pure50(num_classes=4, input_size=512)
```

### C√°ch 2: S·ª≠ d·ª•ng Factory function (Khuy·∫øn ngh·ªã)

```python
# Linh ho·∫°t h∆°n, c√≥ th·ªÉ thay ƒë·ªïi architecture d·ªÖ d√†ng
model = get_pure_model('pure50', num_classes=4, input_size=512)
model = get_pure_model('pure101', num_classes=4, input_size=512)
```

## 2. Training

### Setup c∆° b·∫£n

```python
import torch
from torch.utils.data import DataLoader
from dog_emotion_classification.pure import (
    get_pure_model, PureTrainer, get_pure_transforms
)

# 1. T·∫°o model
model = get_pure_model('pure50', num_classes=4, input_size=512)

# 2. T·∫°o trainer
trainer = PureTrainer(
    model=model,
    device='cuda',
    checkpoint_dir='checkpoints'
)

# 3. Setup training parameters
trainer.setup_training(
    learning_rate=1e-4,
    weight_decay=1e-4,
    step_size=10,
    gamma=0.1
)
```

### Chu·∫©n b·ªã Data

```python
# T·∫°o transforms cho training v√† validation
train_transform = get_pure_transforms(input_size=512, is_training=True)
val_transform = get_pure_transforms(input_size=512, is_training=False)

# T·∫°o DataLoaders (s·ª≠ d·ª•ng dataset c·ªßa b·∫°n)
train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True)
val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False)
```

### B·∫Øt ƒë·∫ßu Training

```python
# Training v·ªõi validation
trainer.train(
    train_loader=train_loader,
    val_loader=val_loader,
    epochs=30,
    save_best=True,
    save_interval=5
)

# Training ch·ªâ v·ªõi train set
trainer.train(
    train_loader=train_loader,
    epochs=30,
    save_best=True
)
```

### Load Checkpoint

```python
# Load checkpoint ƒë·ªÉ ti·∫øp t·ª•c training
trainer.load_checkpoint('checkpoints/best_model.pth')
```

## 3. Inference

### Load Model t·ª´ Checkpoint

```python
model, transform = load_pure_model(
    model_path='checkpoints/best_model.pth',
    architecture='pure50',
    num_classes=4,
    input_size=512,
    device='cuda'
)
```

### Prediction tr√™n m·ªôt ·∫£nh

```python
result = predict_emotion_pure(
    image_path='path/to/image.jpg',
    model=model,
    transform=transform,
    head_bbox=None,  # Optional: [x1, y1, x2, y2]
    device='cuda',
    emotion_classes=['sad', 'angry', 'happy', 'relaxed']
)

# Result format
# {
#     'sad': 0.2,
#     'angry': 0.1,
#     'happy': 0.6,
#     'relaxed': 0.1,
#     'predicted': True
# }
```

### Batch Prediction

```python
import cv2
import torch
from PIL import Image

def predict_batch(image_paths, model, transform, device='cuda'):
    """Predict emotions for multiple images"""
    model.eval()
    results = []
    
    with torch.no_grad():
        for img_path in image_paths:
            # Load and preprocess image
            image = cv2.imread(img_path)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            pil_image = Image.fromarray(image)
            
            # Transform and predict
            input_tensor = transform(pil_image).unsqueeze(0).to(device)
            outputs = model(input_tensor)
            probs = torch.softmax(outputs, dim=1).squeeze().cpu().numpy()
            
            # Map to emotion classes
            emotion_scores = {
                'sad': float(probs[0]),
                'angry': float(probs[1]), 
                'happy': float(probs[2]),
                'relaxed': float(probs[3])
            }
            results.append(emotion_scores)
    
    return results
```

## 4. Scripts c√≥ s·∫µn

### Training Scripts

```bash
# Train Pure34
python [train]_head_classification_pure34.py

# Train Pure50
python [train]_head_classification_pure50.py
```

### Demo Script

```bash
# Ch·∫°y demo ƒë·ªÉ hi·ªÉu c√°ch s·ª≠ d·ª•ng module
python demo_pure_training.py
```

## 5. V√≠ d·ª• Ho√†n ch·ªânh

### Training t·ª´ ƒë·∫ßu

```python
import pandas as pd
from torch.utils.data import Dataset, DataLoader
from PIL import Image
import os

class DogEmotionDataset(Dataset):
    def __init__(self, root, labels_csv, transform=None):
        self.root = root
        df = pd.read_csv(labels_csv)
        self.items = df[['filename', 'label']].values
        
        unique_labels = sorted(df['label'].unique())
        self.label2index = {name: i for i, name in enumerate(unique_labels)}
        self.transform = transform

    def __len__(self):
        return len(self.items)

    def __getitem__(self, idx):
        fn, label_str = self.items[idx]
        label_idx = self.label2index[label_str]
        img_path = os.path.join(self.root, label_str, fn)
        
        img = Image.open(img_path).convert('RGB')
        if self.transform:
            img = self.transform(img)
        return img, label_idx

# Complete training workflow
def train_complete():
    # 1. Create model
    model = get_pure_model('pure50', num_classes=4, input_size=512)
    
    # 2. Setup trainer
    trainer = PureTrainer(model, device='cuda', checkpoint_dir='checkpoints')
    trainer.setup_training(learning_rate=1e-4, weight_decay=1e-4)
    
    # 3. Prepare data
    train_transform = get_pure_transforms(512, is_training=True)
    dataset = DogEmotionDataset('data/images', 'data/labels.csv', train_transform)
    train_loader = DataLoader(dataset, batch_size=8, shuffle=True)
    
    # 4. Train
    trainer.train(train_loader=train_loader, epochs=30, save_best=True)
    
    print(f"‚úÖ Training completed! Best accuracy: {trainer.best_acc:.4f}")

if __name__ == "__main__":
    train_complete()
```

### Inference v√† Evaluation

```python
def evaluate_model():
    # Load trained model
    model, transform = load_pure_model(
        model_path='checkpoints/best_model.pth',
        architecture='pure50',
        num_classes=4,
        input_size=512,
        device='cuda'
    )
    
    # Test on images
    test_images = ['test1.jpg', 'test2.jpg', 'test3.jpg']
    
    for img_path in test_images:
        result = predict_emotion_pure(img_path, model, transform)
        
        print(f"üì∑ {img_path}:")
        for emotion, score in result.items():
            if emotion != 'predicted':
                print(f"   {emotion}: {score:.3f}")
        print()

if __name__ == "__main__":
    evaluate_model()
```

## 6. Tips v√† Best Practices

### Model Selection

- **Pure18/Pure34**: Nhanh h∆°n, √≠t parameters, ph√π h·ª£p cho prototype
- **Pure50**: C√¢n b·∫±ng t·ªët gi·ªØa accuracy v√† t·ªëc ƒë·ªô
- **Pure101/Pure152**: Accuracy cao nh·∫•t nh∆∞ng ch·∫≠m h∆°n

### Training Tips

```python
# S·ª≠ d·ª•ng learning rate scheduling
trainer.setup_training(
    learning_rate=1e-4,    # B·∫Øt ƒë·∫ßu v·ªõi LR cao h∆°n
    weight_decay=1e-4,     # Regularization
    step_size=10,          # Gi·∫£m LR m·ªói 10 epochs
    gamma=0.1              # Gi·∫£m LR xu·ªëng 10%
)

# Mixed precision training (t√πy ch·ªçn)
# C·∫ßn th√™m v√†o trainer n·∫øu mu·ªën tƒÉng t·ªëc
```

### Data Augmentation

```python
# Training transforms ƒë√£ bao g·ªìm augmentation ph√π h·ª£p
train_transform = get_pure_transforms(input_size=512, is_training=True)
# - RandomResizedCrop
# - RandomHorizontalFlip  
# - ColorJitter
# - Normalization

# Inference kh√¥ng c√≥ augmentation
val_transform = get_pure_transforms(input_size=512, is_training=False)
```

### Memory Optimization

```python
# Gi·∫£m batch size n·∫øu b·ªã out of memory
train_loader = DataLoader(dataset, batch_size=4, shuffle=True)  # Thay v√¨ 8

# S·ª≠ d·ª•ng gradient accumulation
# C·∫ßn modify trainer ƒë·ªÉ accumulate gradients qua nhi·ªÅu batches
```

## 7. Troubleshooting

### L·ªói th∆∞·ªùng g·∫∑p

1. **Out of Memory**: Gi·∫£m batch_size ho·∫∑c input_size
2. **Model kh√¥ng converge**: Th·ª≠ learning rate th·∫•p h∆°n (1e-5)
3. **Import error**: ƒê·∫£m b·∫£o ƒë√£ c√†i ƒë·∫∑t ƒë√∫ng dependencies

### Dependencies

```bash
pip install torch torchvision tqdm pandas opencv-python pillow gdown
```

## 8. T√≠ch h·ª£p v·ªõi Pipeline hi·ªán t·∫°i

ƒê·ªÉ t√≠ch h·ª£p v·ªõi notebook `[Data] T·∫°o data cho ML.ipynb`:

```python
# Thay th·∫ø ph·∫ßn load model c≈©
from dog_emotion_classification.pure import load_pure_model, predict_emotion_pure

# Load Pure model
pure_model, pure_transform = load_pure_model(
    model_path="pure50_best.pth",
    architecture="pure50", 
    num_classes=4,
    input_size=512
)

# Thay th·∫ø function prediction
def predict_emotion_classification(image_path, model, transform, head_bbox=None):
    return predict_emotion_pure(image_path, model, transform, head_bbox)
```

---

## T√†i li·ªáu tham kh·∫£o

- **Paper g·ªëc**: "Deep residual learning with product units"
- **Based on ResNet**: He et al. "Deep Residual Learning for Image Recognition"
- **Product Units**: Multiplication-based feature interactions thay v√¨ addition

V·ªõi module n√†y, b·∫°n c√≥ th·ªÉ d·ªÖ d√†ng th·ª≠ nghi·ªám v·ªõi c√°c ki·∫øn tr√∫c Pure kh√°c nhau v√† t·ªëi ∆∞u h√≥a model cho b√†i to√°n ph√¢n lo·∫°i c·∫£m x√∫c ch√≥! 