{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üêï Dog Emotion Classification - NFNet Cross-Validation Training\n",
        "\n",
        "Notebook n√†y s·∫Ω:\n",
        "1. **Clone repository** t·ª´ GitHub v√† c√†i ƒë·∫∑t dependencies\n",
        "2. **Import NFNet module** t·ª´ `dog_emotion_classification.nfnet`\n",
        "3. **Download dataset** dog emotion classification  \n",
        "4. **Train NFNet** v·ªõi 50 epochs s·ª≠ d·ª•ng K-Fold Cross Validation\n",
        "5. **Evaluate** v·ªõi cross-validation scores v√† confusion matrix\n",
        "6. **Download models** v√† results v·ªÅ m√°y\n",
        "\n",
        "---\n",
        "**Author**: Dog Emotion Research Team  \n",
        "**Date**: 2025  \n",
        "**Runtime**: Google Colab (GPU T4/V100 recommended)  \n",
        "**Training**: NFNet (Normalizer-Free Network) v·ªõi Cross Validation  \n",
        "**Repository**: https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git  \n",
        "**Module**: `dog_emotion_classification.nfnet`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß STEP 1: Clone Repository v√† Setup Environment\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone repository t·ª´ GitHub\n",
        "REPO_URL = \"https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git\"\n",
        "REPO_NAME = \"dog-emotion-recognition-hybrid\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    print(f\"üì• Cloning repository from {REPO_URL}\")\n",
        "    !git clone {REPO_URL}\n",
        "    print(\"‚úÖ Repository cloned successfully!\")\n",
        "else:\n",
        "    print(f\"‚úÖ Repository already exists: {REPO_NAME}\")\n",
        "\n",
        "# Change to repository directory\n",
        "os.chdir(REPO_NAME)\n",
        "print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Add to Python path ƒë·ªÉ import modules\n",
        "if os.getcwd() not in sys.path:\n",
        "    sys.path.insert(0, os.getcwd())\n",
        "    print(\"‚úÖ Added repository to Python path\")\n",
        "\n",
        "# Install required packages\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install opencv-python-headless pillow pandas tqdm gdown albumentations matplotlib seaborn\n",
        "!pip install scikit-learn timm ultralytics\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üß™ STEP 2: Import Libraries v√† NFNet Module\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import json\n",
        "import zipfile\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# üéØ Import NFNet t·ª´ custom module\n",
        "try:\n",
        "    from dog_emotion_classification.nfnet import (\n",
        "        load_nfnet_model, \n",
        "        predict_emotion_nfnet,\n",
        "        get_nfnet_transforms,\n",
        "        create_nfnet_model,\n",
        "        NFNetModel\n",
        "    )\n",
        "    print(\"‚úÖ Successfully imported NFNet module from dog_emotion_classification.nfnet\")\n",
        "    print(\"üìã Available functions:\")\n",
        "    print(\"   - load_nfnet_model()\")\n",
        "    print(\"   - predict_emotion_nfnet()\")\n",
        "    print(\"   - get_nfnet_transforms()\")\n",
        "    print(\"   - create_nfnet_model()\")\n",
        "    print(\"   - NFNetModel class\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import NFNet module: {e}\")\n",
        "    print(\"Please ensure you're in the repository directory and the module exists.\")\n",
        "    raise\n",
        "\n",
        "# Device setup\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nüî• PyTorch version: {torch.__version__}\")\n",
        "print(f\"üöÄ CUDA available: {torch.cuda.is_available()}\")\n",
        "print(f\"üéØ Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéÆ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "np.random.seed(42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset and Training\n",
        "class DogEmotionDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.transform = transform\n",
        "        self.classes = ['angry', 'happy', 'relaxed', 'sad']\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "        \n",
        "        self.samples = []\n",
        "        for class_name in self.classes:\n",
        "            class_dir = self.data_dir / class_name\n",
        "            if class_dir.exists():\n",
        "                for img_path in class_dir.glob('*.jpg'):\n",
        "                    self.samples.append((str(img_path), self.class_to_idx[class_name]))\n",
        "        \n",
        "        print(f\"üìÅ Dataset: {len(self.samples)} images, Classes: {self.classes}\")\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB').resize((224, 224), Image.LANCZOS)\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            return image, label\n",
        "        except:\n",
        "            dummy = Image.new('RGB', (224, 224), 'black')\n",
        "            if self.transform:\n",
        "                dummy = self.transform(dummy)\n",
        "            return dummy, label\n",
        "\n",
        "# Transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(0.5),\n",
        "    transforms.ColorJitter(0.2, 0.2, 0.2, 0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Config\n",
        "EPOCHS, BATCH_SIZE, LR = 50, 16, 1e-4\n",
        "NUM_CLASSES, K_FOLDS = 4, 5\n",
        "EMOTION_CLASSES = ['angry', 'happy', 'relaxed', 'sad']\n",
        "\n",
        "# Dataset\n",
        "dataset = DogEmotionDataset(\"dog_emotion_dataset\", train_transform)\n",
        "labels = [sample[1] for sample in dataset.samples]\n",
        "kfold = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "print(f\"üìä Config: {EPOCHS} epochs, batch {BATCH_SIZE}, lr {LR}, device {device}\")\n",
        "\n",
        "def train_epoch(model, loader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    for data, target in tqdm(loader, desc=\"Training\"):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        total_loss += loss.item()\n",
        "        _, pred = torch.max(output, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (pred == target).sum().item()\n",
        "    \n",
        "    return total_loss / len(loader), 100. * correct / total\n",
        "\n",
        "def validate_epoch(model, loader, criterion, device):\n",
        "    model.eval()\n",
        "    total_loss, correct, total = 0, 0, 0\n",
        "    all_preds, all_targets = [], []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(loader, desc=\"Validation\"):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            total_loss += loss.item()\n",
        "            _, pred = torch.max(output, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (pred == target).sum().item()\n",
        "            \n",
        "            all_preds.extend(pred.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "    \n",
        "    return total_loss / len(loader), 100. * correct / total, all_preds, all_targets\n",
        "\n",
        "print(\"‚úÖ Dataset and functions ready!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-Validation Training\n",
        "print(\"üéØ Starting 5-Fold Cross-Validation Training...\")\n",
        "fold_results, all_val_accs = [], []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(range(len(dataset)), labels)):\n",
        "    print(f\"\\n{'='*60}\\nüîÑ FOLD {fold + 1}/5\\n{'='*60}\")\n",
        "    \n",
        "    # Data loaders\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    val_sampler = SubsetRandomSampler(val_idx)\n",
        "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=2)\n",
        "    val_dataset = DogEmotionDataset(\"dog_emotion_dataset\", val_transform)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, num_workers=2)\n",
        "    \n",
        "    print(f\"üìä Training: {len(train_idx)}, Validation: {len(val_idx)}\")\n",
        "    \n",
        "    # Model\n",
        "    model = NFNetModel(num_classes=NUM_CLASSES, variant='F0').to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=LR, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=EPOCHS)\n",
        "    \n",
        "    # Training history\n",
        "    train_losses, train_accs, val_losses, val_accs = [], [], [], []\n",
        "    best_val_acc, best_model_state = 0.0, None\n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
        "        \n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        val_loss, val_acc, val_preds, val_targets = validate_epoch(model, val_loader, criterion, device)\n",
        "        scheduler.step()\n",
        "        \n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict().copy()\n",
        "        \n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "        \n",
        "        print(f\"Train: {train_loss:.4f}, {train_acc:.2f}% | Val: {val_loss:.4f}, {val_acc:.2f}%\")\n",
        "    \n",
        "    # Final evaluation\n",
        "    model.load_state_dict(best_model_state)\n",
        "    final_loss, final_acc, final_preds, final_targets = validate_epoch(model, val_loader, criterion, device)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Fold {fold + 1} completed! Best Val Acc: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    fold_results.append({\n",
        "        'fold': fold + 1,\n",
        "        'train_losses': train_losses,\n",
        "        'train_accs': train_accs,\n",
        "        'val_losses': val_losses,\n",
        "        'val_accs': val_accs,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'final_preds': final_preds,\n",
        "        'final_targets': final_targets,\n",
        "        'model_state': best_model_state\n",
        "    })\n",
        "    all_val_accs.append(best_val_acc)\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "mean_acc = np.mean(all_val_accs)\n",
        "std_acc = np.std(all_val_accs)\n",
        "\n",
        "print(f\"\\nüéâ CROSS-VALIDATION COMPLETED!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"üìä Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"üìà Fold Accuracies: {[f'{acc:.2f}%' for acc in all_val_accs]}\")\n",
        "print(f\"üèÜ Best Fold: {np.argmax(all_val_accs) + 1} ({max(all_val_accs):.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization and Results\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "# Training curves\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "for result in fold_results:\n",
        "    epochs = range(1, len(result['train_losses']) + 1)\n",
        "    plt.plot(epochs, result['train_losses'], label=f\"Fold {result['fold']}\", alpha=0.7)\n",
        "plt.title('Training Loss Across Folds', fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Validation curves\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "for result in fold_results:\n",
        "    epochs = range(1, len(result['val_accs']) + 1)\n",
        "    plt.plot(epochs, result['val_accs'], label=f\"Fold {result['fold']}\", alpha=0.7)\n",
        "plt.title('Validation Accuracy Across Folds', fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Fold comparison\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "fold_names = [f'Fold {i+1}' for i in range(K_FOLDS)]\n",
        "bars = plt.bar(fold_names, all_val_accs, color=sns.color_palette(\"husl\", K_FOLDS))\n",
        "plt.title('Best Validation Accuracy by Fold', fontweight='bold')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "for bar, acc in zip(bars, all_val_accs):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "             f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "plt.axhline(y=mean_acc, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_acc:.1f}%')\n",
        "plt.legend()\n",
        "\n",
        "# Confusion Matrix\n",
        "best_fold_idx = np.argmax(all_val_accs)\n",
        "best_result = fold_results[best_fold_idx]\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "cm = confusion_matrix(best_result['final_targets'], best_result['final_preds'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=EMOTION_CLASSES, yticklabels=EMOTION_CLASSES)\n",
        "plt.title(f'Confusion Matrix - Best Fold ({best_fold_idx+1})', fontweight='bold')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "# Training vs Validation\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "epochs = range(1, len(best_result['train_accs']) + 1)\n",
        "plt.plot(epochs, best_result['train_accs'], label='Training', linewidth=2)\n",
        "plt.plot(epochs, best_result['val_accs'], label='Validation', linewidth=2)\n",
        "plt.title(f'Training vs Validation - Best Fold ({best_fold_idx+1})', fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# Statistics\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "ax6.axis('off')\n",
        "stats_text = f\"\"\"\n",
        "üìä NFNet Cross-Validation Results\n",
        "\n",
        "üéØ Model Performance:\n",
        "   ‚Ä¢ Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\n",
        "   ‚Ä¢ Best Fold: {best_fold_idx+1} ({max(all_val_accs):.2f}%)\n",
        "   ‚Ä¢ Worst Fold: {np.argmin(all_val_accs)+1} ({min(all_val_accs):.2f}%)\n",
        "\n",
        "‚öôÔ∏è Training Configuration:\n",
        "   ‚Ä¢ Architecture: NFNet-F0 (Normalizer-Free)\n",
        "   ‚Ä¢ Epochs per fold: {EPOCHS}\n",
        "   ‚Ä¢ Batch size: {BATCH_SIZE}\n",
        "   ‚Ä¢ Learning rate: {LR}\n",
        "   ‚Ä¢ Device: {device}\n",
        "\n",
        "üìà Data Information:\n",
        "   ‚Ä¢ Total samples: {len(dataset)}\n",
        "   ‚Ä¢ Classes: {len(EMOTION_CLASSES)}\n",
        "   ‚Ä¢ Folds: {K_FOLDS} (stratified)\n",
        "\"\"\"\n",
        "\n",
        "ax6.text(0.1, 0.9, stats_text, transform=ax6.transAxes, fontsize=12,\n",
        "         verticalalignment='top', fontfamily='monospace',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightcyan\", alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('nfnet_cross_validation_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "# Save model\n",
        "best_model = NFNetModel(num_classes=NUM_CLASSES, variant='F0')\n",
        "best_model.load_state_dict(fold_results[best_fold_idx]['model_state'])\n",
        "model_filename = f'nfnet_best_fold_{best_fold_idx+1}_acc_{max(all_val_accs):.2f}.pth'\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': best_model.state_dict(),\n",
        "    'model_config': {'num_classes': NUM_CLASSES, 'architecture': 'NFNet-F0', 'variant': 'F0'},\n",
        "    'training_info': {\n",
        "        'best_fold': best_fold_idx + 1,\n",
        "        'best_accuracy': max(all_val_accs),\n",
        "        'mean_accuracy': mean_acc,\n",
        "        'std_accuracy': std_acc,\n",
        "        'epochs': EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LR\n",
        "    },\n",
        "    'class_names': EMOTION_CLASSES\n",
        "}, model_filename)\n",
        "\n",
        "# Save results\n",
        "results_filename = 'nfnet_training_results.json'\n",
        "with open(results_filename, 'w') as f:\n",
        "    json.dump({\n",
        "        'cross_validation_results': {\n",
        "            'mean_accuracy': float(mean_acc),\n",
        "            'std_accuracy': float(std_acc),\n",
        "            'fold_accuracies': [float(acc) for acc in all_val_accs],\n",
        "            'best_fold': int(best_fold_idx + 1),\n",
        "            'best_accuracy': float(max(all_val_accs))\n",
        "        },\n",
        "        'training_config': {'epochs': EPOCHS, 'batch_size': BATCH_SIZE, 'learning_rate': LR, 'device': str(device)},\n",
        "        'dataset_info': {'total_samples': len(dataset), 'num_classes': NUM_CLASSES, 'class_names': EMOTION_CLASSES}\n",
        "    }, f, indent=2)\n",
        "\n",
        "# Download files\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"\\nüì• Downloading files...\")\n",
        "    files.download(model_filename)\n",
        "    files.download(results_filename)\n",
        "    files.download('nfnet_cross_validation_results.png')\n",
        "    print(\"‚úÖ Files downloaded!\")\n",
        "except ImportError:\n",
        "    print(\"üìÅ Files saved locally\")\n",
        "\n",
        "print(f\"\\nüéâ NFNET TRAINING COMPLETED!\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"üìä FINAL RESULTS:\")\n",
        "print(f\"   üéØ Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"   üèÜ Best Fold: {best_fold_idx+1} with {max(all_val_accs):.2f}% accuracy\")\n",
        "print(f\"   üìà All Fold Accuracies: {[f'{acc:.2f}%' for acc in all_val_accs]}\")\n",
        "print(f\"   üíæ Model: {model_filename}\")\n",
        "print(f\"   üìä Results: {results_filename}\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "print(f\"\\nüìã HOW TO USE:\")\n",
        "print(f\"model = NFNetModel(num_classes=4, variant='F0')\")\n",
        "print(f\"checkpoint = torch.load('{model_filename}')\")\n",
        "print(f\"model.load_state_dict(checkpoint['model_state_dict'])\")\n",
        "print(f\"Classes: {EMOTION_CLASSES}\")\n",
        "\n",
        "print(f\"\\nüéØ NFNet training completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "ü§ñ NFNet Cross-Validation Training for Dog Emotion Recognition\n",
        "===============================================================\n",
        "\n",
        "Complete pipeline for training NFNet (Normalizer-Free Networks) on dog emotion dataset with:\n",
        "- Automatic dataset download and preparation\n",
        "- 5-fold stratified cross-validation\n",
        "- 50 epochs training per fold\n",
        "- Comprehensive visualization and evaluation\n",
        "- Model saving and download\n",
        "\n",
        "Author: Dog Emotion Recognition Team\n",
        "Date: 2025\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import warnings\n",
        "import time\n",
        "import zipfile\n",
        "import json\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üöÄ Starting NFNet Cross-Validation Training Pipeline\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# Install packages\n",
        "packages = [\n",
        "    'torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121',\n",
        "    'gdown scikit-learn matplotlib seaborn Pillow numpy pandas tqdm opencv-python'\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    print(f\"Installing {package.split()[0]}...\")\n",
        "    os.system(f\"pip install {package} -q\")\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")\n",
        "\n",
        "# Imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import gdown\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "\n",
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üîß Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "# Download dataset\n",
        "dataset_url = \"https://drive.google.com/uc?id=1ZAgz5u64i3LDbwMFpBXjzsKt6FrhNGdW\"\n",
        "dataset_zip = \"dog_emotion_dataset.zip\"\n",
        "\n",
        "if not os.path.exists(dataset_zip):\n",
        "    print(\"üì• Downloading dataset...\")\n",
        "    gdown.download(dataset_url, dataset_zip, quiet=False)\n",
        "    print(\"‚úÖ Dataset downloaded successfully!\")\n",
        "\n",
        "# Extract dataset\n",
        "dataset_dir = \"dog_emotion_dataset\"\n",
        "if not os.path.exists(dataset_dir):\n",
        "    print(\"üìÇ Extracting dataset...\")\n",
        "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "    print(\"‚úÖ Dataset extracted successfully!\")\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
