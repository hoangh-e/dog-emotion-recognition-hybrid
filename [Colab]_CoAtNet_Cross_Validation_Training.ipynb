{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # üêï Dog Emotion Classification - CoAtNet Cross-Validation Training\n",
        "\n",
        "# Notebook n√†y s·∫Ω:\n",
        "# 1. **Clone repository** t·ª´ GitHub v√† c√†i ƒë·∫∑t dependencies\n",
        "# 2. **Import CoAtNet module** t·ª´ `dog_emotion_classification.coatnet`\n",
        "# 3. **Download dataset** dog emotion classification  \n",
        "# 4. **Train CoAtNet** v·ªõi 50 epochs s·ª≠ d·ª•ng K-Fold Cross Validation\n",
        "# 5. **Evaluate** v·ªõi cross-validation scores v√† confusion matrix\n",
        "# 6. **Download models** v√† results v·ªÅ m√°y\n",
        "\n",
        "# ---\n",
        "# **Author**: Dog Emotion Research Team  \n",
        "# **Date**: 2025  \n",
        "# **Runtime**: Google Colab (GPU T4/V100 recommended)  \n",
        "# **Training**: CoAtNet (Convolution and Attention Network) v·ªõi Cross Validation  \n",
        "# **Repository**: https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git  \n",
        "# **Module**: `dog_emotion_classification.coatnet`\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß STEP 1: Clone Repository v√† Setup Environment\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone repository t·ª´ GitHub\n",
        "REPO_URL = \"https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git\"\n",
        "REPO_NAME = \"dog-emotion-recognition-hybrid\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    print(f\"üì• Cloning repository from {REPO_URL}\")\n",
        "    !git clone {REPO_URL}\n",
        "    print(\"‚úÖ Repository cloned successfully!\")\n",
        "else:\n",
        "    print(f\"‚úÖ Repository already exists: {REPO_NAME}\")\n",
        "\n",
        "# Change to repository directory\n",
        "os.chdir(REPO_NAME)\n",
        "print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Add to Python path ƒë·ªÉ import modules\n",
        "if os.getcwd() not in sys.path:\n",
        "    sys.path.insert(0, os.getcwd())\n",
        "    print(\"‚úÖ Added repository to Python path\")\n",
        "\n",
        "# Install required packages\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install opencv-python-headless pillow pandas tqdm gdown albumentations matplotlib seaborn\n",
        "!pip install scikit-learn timm ultralytics\n",
        "\n",
        "# üéØ Import CoAtNet t·ª´ custom module\n",
        "try:\n",
        "    from dog_emotion_classification.coatnet import (\n",
        "        load_coatnet_model, \n",
        "        predict_emotion_coatnet,\n",
        "        get_coatnet_transforms,\n",
        "        create_coatnet_model,\n",
        "        CoAtNetModel\n",
        "    )\n",
        "    print(\"‚úÖ Successfully imported CoAtNet module from dog_emotion_classification.coatnet\")\n",
        "    print(\"üìã Available functions:\")\n",
        "    print(\"   - load_coatnet_model()\")\n",
        "    print(\"   - predict_emotion_coatnet()\")\n",
        "    print(\"   - get_coatnet_transforms()\")\n",
        "    print(\"   - create_coatnet_model()\")\n",
        "    print(\"   - CoAtNetModel class\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import CoAtNet module: {e}\")\n",
        "    print(\"Please ensure you're in the repository directory and the module exists.\")\n",
        "    raise\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import gdown\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "import time\n",
        "import zipfile\n",
        "import json\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Set random seeds\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"\\nüîß Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, qkv_bias=False, attn_drop=0., proj_drop=0.):\n",
        "        super().__init__()\n",
        "        self.num_heads = num_heads\n",
        "        head_dim = dim // num_heads\n",
        "        self.scale = head_dim ** -0.5\n",
        "\n",
        "        self.qkv = nn.Linear(dim, dim * 3, bias=qkv_bias)\n",
        "        self.attn_drop = nn.Dropout(attn_drop)\n",
        "        self.proj = nn.Linear(dim, dim)\n",
        "        self.proj_drop = nn.Dropout(proj_drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, N, C = x.shape\n",
        "        qkv = self.qkv(x).reshape(B, N, 3, self.num_heads, C // self.num_heads).permute(2, 0, 3, 1, 4)\n",
        "        q, k, v = qkv[0], qkv[1], qkv[2]\n",
        "\n",
        "        attn = (q @ k.transpose(-2, -1)) * self.scale\n",
        "        attn = attn.softmax(dim=-1)\n",
        "        attn = self.attn_drop(attn)\n",
        "\n",
        "        x = (attn @ v).transpose(1, 2).reshape(B, N, C)\n",
        "        x = self.proj(x)\n",
        "        x = self.proj_drop(x)\n",
        "        return x\n",
        "\n",
        "class TransformerBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, mlp_ratio=4., qkv_bias=False, \n",
        "                 drop=0., attn_drop=0., norm_layer=nn.LayerNorm):\n",
        "        super().__init__()\n",
        "        self.norm1 = norm_layer(dim)\n",
        "        self.attn = MultiHeadAttention(dim, num_heads=num_heads, qkv_bias=qkv_bias,\n",
        "                                     attn_drop=attn_drop, proj_drop=drop)\n",
        "        self.norm2 = norm_layer(dim)\n",
        "        mlp_hidden_dim = int(dim * mlp_ratio)\n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, mlp_hidden_dim),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop),\n",
        "            nn.Linear(mlp_hidden_dim, dim),\n",
        "            nn.Dropout(drop)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = x + self.attn(self.norm1(x))\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        return x\n",
        "\n",
        "class CoAtNetStage(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, depth, stage_type='conv', \n",
        "                 num_heads=8, mlp_ratio=4., stride=1):\n",
        "        super().__init__()\n",
        "        self.stage_type = stage_type\n",
        "        \n",
        "        layers = []\n",
        "        for i in range(depth):\n",
        "            if stage_type == 'conv':\n",
        "                layer_stride = stride if i == 0 else 1\n",
        "                layers.append(MBConv(in_channels if i == 0 else out_channels, \n",
        "                                   out_channels, stride=layer_stride))\n",
        "            else:  # transformer\n",
        "                if i == 0 and in_channels != out_channels:\n",
        "                    layers.append(nn.Conv2d(in_channels, out_channels, 1, stride=stride))\n",
        "                layers.append(TransformerBlock(out_channels, num_heads, mlp_ratio))\n",
        "        \n",
        "        self.layers = nn.ModuleList(layers)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        for layer in self.layers:\n",
        "            if self.stage_type == 'conv':\n",
        "                x = layer(x)\n",
        "            else:  # transformer\n",
        "                if isinstance(layer, nn.Conv2d):\n",
        "                    x = layer(x)\n",
        "                else:\n",
        "                    B, C, H, W = x.shape\n",
        "                    x = x.flatten(2).transpose(1, 2)  # B, H*W, C\n",
        "                    x = layer(x)\n",
        "                    x = x.transpose(1, 2).reshape(B, C, H, W)\n",
        "        return x\n",
        "\n",
        "class CoAtNetModel(nn.Module):\n",
        "    def __init__(self, num_classes=4, depths=[2, 2, 3, 5, 2], dims=[64, 96, 192, 384, 768]):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Stem\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, dims[0], 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(dims[0]),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        # Stages\n",
        "        self.stages = nn.ModuleList()\n",
        "        \n",
        "        # Conv stages (S0, S1)\n",
        "        for i in range(2):\n",
        "            stage = CoAtNetStage(\n",
        "                dims[i], dims[i+1], depths[i], 'conv',\n",
        "                stride=2 if i > 0 else 1\n",
        "            )\n",
        "            self.stages.append(stage)\n",
        "        \n",
        "        # Transformer stages (S2, S3, S4)\n",
        "        for i in range(2, 5):\n",
        "            stage = CoAtNetStage(\n",
        "                dims[i], dims[i] if i < 4 else dims[i-1], depths[i], 'transformer',\n",
        "                stride=2 if i == 2 else 1\n",
        "            )\n",
        "            self.stages.append(stage)\n",
        "        \n",
        "        # Head\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.head = nn.Linear(dims[-2], num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        \n",
        "        for stage in self.stages:\n",
        "            x = stage(x)\n",
        "        \n",
        "        x = self.global_pool(x)\n",
        "        x = x.flatten(1)\n",
        "        x = self.head(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "print(\"‚úÖ CoAtNet model architecture defined!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Dataset and Training Setup\n",
        "from pathlib import Path\n",
        "\n",
        "class DogEmotionDataset(Dataset):\n",
        "    def __init__(self, data_dir, transform=None):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.transform = transform\n",
        "        self.classes = ['angry', 'happy', 'relaxed', 'sad']\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "        \n",
        "        self.samples = []\n",
        "        self._load_samples()\n",
        "        \n",
        "        print(f\"üìÅ Dataset loaded: {len(self.samples)} images\")\n",
        "        print(f\"üìä Classes: {self.classes}\")\n",
        "        \n",
        "    def _load_samples(self):\n",
        "        for class_name in self.classes:\n",
        "            class_dir = self.data_dir / class_name\n",
        "            if class_dir.exists():\n",
        "                for img_path in class_dir.glob('*.jpg'):\n",
        "                    if img_path.is_file():\n",
        "                        self.samples.append((str(img_path), self.class_to_idx[class_name]))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        \n",
        "        try:\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            image = image.resize((224, 224), Image.LANCZOS)\n",
        "            \n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            return image, label\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading image {img_path}: {e}\")\n",
        "            dummy_image = Image.new('RGB', (224, 224), color='black')\n",
        "            if self.transform:\n",
        "                dummy_image = self.transform(dummy_image)\n",
        "            return dummy_image, label\n",
        "\n",
        "# Data transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Training configuration\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 1e-4\n",
        "NUM_CLASSES = 4\n",
        "K_FOLDS = 5\n",
        "EMOTION_CLASSES = ['angry', 'happy', 'relaxed', 'sad']\n",
        "\n",
        "print(f\"üìä Training Configuration:\")\n",
        "print(f\"   - Epochs per fold: {EPOCHS}\")\n",
        "print(f\"   - Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   - Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"   - Device: {device}\")\n",
        "\n",
        "# Load dataset and prepare for cross-validation\n",
        "dataset = DogEmotionDataset(dataset_dir, transform=train_transform)\n",
        "labels = [sample[1] for sample in dataset.samples]\n",
        "\n",
        "# K-fold cross-validation\n",
        "kfold = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n",
        "\n",
        "print(\"‚úÖ Dataset and training setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Cross-Validation Training\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(tqdm(dataloader, desc=\"Training\")):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "    \n",
        "    return running_loss / len(dataloader), 100. * correct / total\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(dataloader, desc=\"Validation\"):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "            \n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "    \n",
        "    return running_loss / len(dataloader), 100. * correct / total, all_preds, all_targets\n",
        "\n",
        "# Start cross-validation training\n",
        "print(\"üéØ Starting 5-Fold Cross-Validation Training...\")\n",
        "\n",
        "fold_results = []\n",
        "all_val_accs = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(range(len(dataset)), labels)):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üîÑ FOLD {fold + 1}/5\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Create data samplers\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    val_sampler = SubsetRandomSampler(val_idx)\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=2)\n",
        "    val_dataset = DogEmotionDataset(dataset_dir, transform=val_transform)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, sampler=val_sampler, num_workers=2)\n",
        "    \n",
        "    print(f\"üìä Fold {fold + 1} data:\")\n",
        "    print(f\"   - Training samples: {len(train_idx)}\")\n",
        "    print(f\"   - Validation samples: {len(val_idx)}\")\n",
        "    \n",
        "    # Create model\n",
        "    model = CoAtNetModel(num_classes=NUM_CLASSES).to(device)\n",
        "    \n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
        "    \n",
        "    # Training history\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "    \n",
        "    best_val_acc = 0.0\n",
        "    best_model_state = None\n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
        "        \n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        \n",
        "        # Validate\n",
        "        val_loss, val_acc, val_preds, val_targets = validate_epoch(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict().copy()\n",
        "        \n",
        "        # Record history\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "        \n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "    \n",
        "    # Load best model for final evaluation\n",
        "    model.load_state_dict(best_model_state)\n",
        "    final_val_loss, final_val_acc, final_preds, final_targets = validate_epoch(model, val_loader, criterion, device)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Fold {fold + 1} completed!\")\n",
        "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    # Store results\n",
        "    fold_results.append({\n",
        "        'fold': fold + 1,\n",
        "        'train_losses': train_losses,\n",
        "        'train_accs': train_accs,\n",
        "        'val_losses': val_losses,\n",
        "        'val_accs': val_accs,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'final_preds': final_preds,\n",
        "        'final_targets': final_targets,\n",
        "        'model_state': best_model_state\n",
        "    })\n",
        "    all_val_accs.append(best_val_acc)\n",
        "    \n",
        "    # Memory cleanup\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Calculate overall statistics\n",
        "mean_acc = np.mean(all_val_accs)\n",
        "std_acc = np.std(all_val_accs)\n",
        "\n",
        "print(f\"\\nüéâ CROSS-VALIDATION COMPLETED!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"üìä Final Results:\")\n",
        "print(f\"   - Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"   - Individual Folds: {[f'{acc:.2f}%' for acc in all_val_accs]}\")\n",
        "print(f\"   - Best Fold: {np.argmax(all_val_accs) + 1} ({max(all_val_accs):.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization and Results\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "# 1. Training curves\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "for result in fold_results:\n",
        "    epochs = range(1, len(result['train_losses']) + 1)\n",
        "    plt.plot(epochs, result['train_losses'], label=f\"Fold {result['fold']}\", alpha=0.7)\n",
        "plt.title('Training Loss Across Folds', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Validation curves\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "for result in fold_results:\n",
        "    epochs = range(1, len(result['val_accs']) + 1)\n",
        "    plt.plot(epochs, result['val_accs'], label=f\"Fold {result['fold']}\", alpha=0.7)\n",
        "plt.title('Validation Accuracy Across Folds', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Fold comparison\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "fold_names = [f'Fold {i+1}' for i in range(K_FOLDS)]\n",
        "bars = plt.bar(fold_names, all_val_accs, color=sns.color_palette(\"husl\", K_FOLDS))\n",
        "plt.title('Best Validation Accuracy by Fold', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "for bar, acc in zip(bars, all_val_accs):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "             f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "plt.axhline(y=mean_acc, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_acc:.1f}%')\n",
        "plt.legend()\n",
        "\n",
        "# 4. Confusion Matrix\n",
        "best_fold_idx = np.argmax(all_val_accs)\n",
        "best_result = fold_results[best_fold_idx]\n",
        "\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "cm = confusion_matrix(best_result['final_targets'], best_result['final_preds'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=EMOTION_CLASSES, yticklabels=EMOTION_CLASSES)\n",
        "plt.title(f'Confusion Matrix - Best Fold ({best_fold_idx+1})', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "# 5. Training vs Validation for best fold\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "epochs = range(1, len(best_result['train_accs']) + 1)\n",
        "plt.plot(epochs, best_result['train_accs'], label='Training', linewidth=2)\n",
        "plt.plot(epochs, best_result['val_accs'], label='Validation', linewidth=2)\n",
        "plt.title(f'Training vs Validation - Best Fold ({best_fold_idx+1})', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Statistics summary\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "ax6.axis('off')\n",
        "stats_text = f\"\"\"\n",
        "üìä CoAtNet Cross-Validation Results\n",
        "\n",
        "üéØ Model Performance:\n",
        "   ‚Ä¢ Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\n",
        "   ‚Ä¢ Best Fold: {best_fold_idx+1} ({max(all_val_accs):.2f}%)\n",
        "   ‚Ä¢ Worst Fold: {np.argmin(all_val_accs)+1} ({min(all_val_accs):.2f}%)\n",
        "\n",
        "‚öôÔ∏è Training Configuration:\n",
        "   ‚Ä¢ Architecture: CoAtNet (Conv + Attention)\n",
        "   ‚Ä¢ Epochs per fold: {EPOCHS}\n",
        "   ‚Ä¢ Batch size: {BATCH_SIZE}\n",
        "   ‚Ä¢ Learning rate: {LEARNING_RATE}\n",
        "   ‚Ä¢ Device: {device}\n",
        "\n",
        "üìà Data Information:\n",
        "   ‚Ä¢ Total samples: {len(dataset)}\n",
        "   ‚Ä¢ Classes: {len(EMOTION_CLASSES)}\n",
        "   ‚Ä¢ Folds: {K_FOLDS} (stratified)\n",
        "\"\"\"\n",
        "\n",
        "ax6.text(0.1, 0.9, stats_text, transform=ax6.transAxes, fontsize=12,\n",
        "         verticalalignment='top', fontfamily='monospace',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('coatnet_cross_validation_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Visualizations created and saved!\")\n",
        "\n",
        "# Save best model\n",
        "best_model = CoAtNetModel(num_classes=NUM_CLASSES)\n",
        "best_model.load_state_dict(fold_results[best_fold_idx]['model_state'])\n",
        "model_filename = f'coatnet_best_fold_{best_fold_idx+1}_acc_{max(all_val_accs):.2f}.pth'\n",
        "\n",
        "torch.save({\n",
        "    'model_state_dict': best_model.state_dict(),\n",
        "    'model_config': {\n",
        "        'num_classes': NUM_CLASSES,\n",
        "        'architecture': 'CoAtNet',\n",
        "        'depths': [2, 2, 3, 5, 2],\n",
        "        'dims': [64, 96, 192, 384, 768]\n",
        "    },\n",
        "    'training_info': {\n",
        "        'best_fold': best_fold_idx + 1,\n",
        "        'best_accuracy': max(all_val_accs),\n",
        "        'mean_accuracy': mean_acc,\n",
        "        'std_accuracy': std_acc,\n",
        "        'epochs': EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE\n",
        "    },\n",
        "    'class_names': EMOTION_CLASSES\n",
        "}, model_filename)\n",
        "\n",
        "print(f\"‚úÖ Model saved as: {model_filename}\")\n",
        "\n",
        "# Save results\n",
        "results_filename = 'coatnet_training_results.json'\n",
        "training_results = {\n",
        "    'cross_validation_results': {\n",
        "        'mean_accuracy': float(mean_acc),\n",
        "        'std_accuracy': float(std_acc),\n",
        "        'fold_accuracies': [float(acc) for acc in all_val_accs],\n",
        "        'best_fold': int(best_fold_idx + 1),\n",
        "        'best_accuracy': float(max(all_val_accs))\n",
        "    },\n",
        "    'training_config': {\n",
        "        'epochs': EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'device': str(device)\n",
        "    },\n",
        "    'dataset_info': {\n",
        "        'total_samples': len(dataset),\n",
        "        'num_classes': NUM_CLASSES,\n",
        "        'class_names': EMOTION_CLASSES\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(results_filename, 'w') as f:\n",
        "    json.dump(training_results, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Training results saved as: {results_filename}\")\n",
        "\n",
        "# Download files\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"\\nüì• Downloading files...\")\n",
        "    files.download(model_filename)\n",
        "    files.download(results_filename)\n",
        "    files.download('coatnet_cross_validation_results.png')\n",
        "    print(\"‚úÖ Files downloaded successfully!\")\n",
        "except ImportError:\n",
        "    print(\"üìÅ Files saved locally\")\n",
        "\n",
        "print(f\"\\nüéâ COATNET TRAINING COMPLETED!\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"üìä FINAL RESULTS:\")\n",
        "print(f\"   üéØ Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"   üèÜ Best Fold: {best_fold_idx+1} with {max(all_val_accs):.2f}% accuracy\")\n",
        "print(f\"   üìà All Fold Accuracies: {[f'{acc:.2f}%' for acc in all_val_accs]}\")\n",
        "print(f\"   üíæ Model: {model_filename}\")\n",
        "print(f\"   üìä Results: {results_filename}\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "print(f\"\\nüìã HOW TO USE:\")\n",
        "print(f\"model = CoAtNetModel(num_classes=4)\")\n",
        "print(f\"checkpoint = torch.load('{model_filename}')\")\n",
        "print(f\"model.load_state_dict(checkpoint['model_state_dict'])\")\n",
        "print(f\"Classes: {EMOTION_CLASSES}\")\n",
        "\n",
        "print(f\"\\nüéØ CoAtNet training completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üêï Dog Emotion Classification - CoAtNet Cross-Validation Training\n",
        "\n",
        "Notebook n√†y s·∫Ω:\n",
        "1. **C√†i ƒë·∫∑t dependencies** v√† chu·∫©n b·ªã m√¥i tr∆∞·ªùng\n",
        "2. **Download dataset** dog emotion classification  \n",
        "3. **Train CoAtNet** v·ªõi 50 epochs s·ª≠ d·ª•ng K-Fold Cross Validation\n",
        "4. **Evaluate** v·ªõi cross-validation scores v√† confusion matrix\n",
        "5. **Download models** v√† results v·ªÅ m√°y\n",
        "\n",
        "---\n",
        "**Author**: Dog Emotion Research Team  \n",
        "**Date**: 2025  \n",
        "**Runtime**: Google Colab (GPU T4/V100 recommended)  \n",
        "**Training**: CoAtNet (Convolution and Attention Network) v·ªõi Cross Validation\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
