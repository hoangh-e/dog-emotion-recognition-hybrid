{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ü§ñ CoAtNet Cross-Validation Training for Dog Emotion Recognition\n\n## T·ªïng quan\nNotebook n√†y hu·∫•n luy·ªán m√¥ h√¨nh **CoAtNet** cho b√†i to√°n nh·∫≠n di·ªán c·∫£m x√∫c ch√≥ v·ªõi:\n- **Clone repository** t·ª´ GitHub\n- **Import CoAtNet module** t·ª´ dog_emotion_classification package\n- **5-fold Cross-Validation** ƒë·ªÉ ƒë√°nh gi√° robust\n- **50 epochs** hu·∫•n luy·ªán cho m·ªói fold\n- **T·ª± ƒë·ªông t·∫£i dataset** t·ª´ Google Drive\n- **Visualization** k·∫øt qu·∫£ training v√† confusion matrix\n- **T·ª± ƒë·ªông l∆∞u model** v√† t·∫£i v·ªÅ m√°y\n\n## C√°ch s·ª≠ d·ª•ng\n1. **Ch·∫°y \"Run All\"** - T·∫•t c·∫£ s·∫Ω ƒë∆∞·ª£c th·ª±c hi·ªán t·ª± ƒë·ªông\n2. **Ch·ªù k·∫øt qu·∫£** - Kho·∫£ng 3-4 gi·ªù cho 5 folds √ó 50 epochs\n3. **T·∫£i model** - File .pth s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông download v·ªÅ m√°y\n4. **Xem k·∫øt qu·∫£** - Accuracy, confusion matrix, v√† training curves\n\n## Y√™u c·∫ßu\n- **GPU**: Khuy·∫øn ngh·ªã s·ª≠ d·ª•ng GPU ƒë·ªÉ training nhanh h∆°n\n- **RAM**: T·ªëi thi·ªÉu 12GB RAM\n- **Disk**: Kho·∫£ng 5GB cho dataset v√† model\n\n---\n**L∆∞u √Ω**: CoAtNet model cho dog emotion classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n\"\"\"\nü§ñ CoAtNet Cross-Validation Training for Dog Emotion Recognition\n======================================================================\n\nComplete pipeline for training CoAtNet on dog emotion dataset with:\n- Automatic dataset download and preparation\n- 5-fold stratified cross-validation\n- 50 epochs training per fold\n- Comprehensive visualization and evaluation\n- Model saving and download\n\nAuthor: Dog Emotion Recognition Team\nDate: 2024\n\"\"\"\n\nimport os\nimport sys\nimport warnings\nimport time\nfrom datetime import datetime\nimport zipfile\nimport shutil\nfrom pathlib import Path\n\n# Suppress warnings\nwarnings.filterwarnings('ignore')\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\nprint(\"üöÄ Starting CoAtNet Cross-Validation Training Pipeline\")\nprint(\"=\" * 60)\n\n# =====================================\n# 1. PACKAGE INSTALLATION\n# =====================================\n\nprint(\"\\nüì¶ Installing required packages...\")\npackages = [\n    'torch>=1.9.0',\n    'torchvision>=0.10.0', \n    'scikit-learn>=1.0.0',\n    'matplotlib>=3.3.0',\n    'seaborn>=0.11.0',\n    'gdown>=4.0.0',\n    'Pillow>=8.0.0',\n    'numpy>=1.21.0',\n    'pandas>=1.3.0',\n    'tqdm>=4.60.0'\n]\n\nfor package in packages:\n    try:\n        os.system(f'pip install {package} --quiet')\n        print(f\"‚úÖ {package}\")\n    except Exception as e:\n        print(f\"‚ùå Failed to install {package}: {e}\")\n\nprint(\"üì¶ Package installation completed!\")\n\n# =====================================\n# 1.5. CLONE REPOSITORY & IMPORT MODULES\n# =====================================\n\nprint(\"\\nüì• Cloning repository and importing custom modules...\")\n\n# Clone repository t·ª´ GitHub\nREPO_URL = \"https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git\"\nif not os.path.exists(\"dog-emotion-recognition-hybrid\"):\n    print(\"üì• Cloning repository from GitHub...\")\n    os.system(f\"git clone {REPO_URL}\")\n\n# Change to repository directory v√† th√™m v√†o Python path\nos.chdir(\"dog-emotion-recognition-hybrid\")\nsys.path.insert(0, os.getcwd())\n\n# Import modules t·ª´ custom package\nprint(\"üì¶ Importing custom modules...\")\nfrom dog_emotion_classification.coatnet import (\n    load_coatnet_model,\n    predict_emotion_coatnet,\n    get_coatnet_transforms,\n    create_coatnet_model\n)\n\n# =====================================\n# 2. IMPORTS\n# =====================================\n\nprint(\"\\nüìö Importing libraries...\")\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\nimport torchvision.transforms as transforms\nimport torchvision.models as models\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix\nfrom PIL import Image\nimport gdown\nfrom tqdm import tqdm\nimport json\nimport random\n\n# Check GPU availability\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"üîß Using device: {device}\")\n\nif torch.cuda.is_available():\n    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n\n# =====================================\n# 3. DATASET DOWNLOAD\n# =====================================\n\nprint(\"\\nüíæ Downloading dataset...\")\n\n# Google Drive dataset ID\ndataset_id = \"1ZAgz5u64i3LDbwMFpBXjzsKt6FrhNGdW\"\ndataset_zip = \"cropped_dataset_4k_face.zip\"\n\nif not os.path.exists(\"cropped_dataset_4k_face\"):\n    print(\"üì• Downloading dataset from Google Drive...\")\n    try:\n        gdown.download(f'https://drive.google.com/uc?id={dataset_id}', dataset_zip, quiet=False)\n        \n        print(\"üìÇ Extracting dataset...\")\n        with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n            zip_ref.extractall('.')\n        \n        os.remove(dataset_zip)\n        print(\"‚úÖ Dataset downloaded and extracted successfully!\")\n        \n    except Exception as e:\n        print(f\"‚ùå Error downloading dataset: {e}\")\n        print(\"Please check your internet connection and try again.\")\n        sys.exit(1)\nelse:\n    print(\"‚úÖ Dataset already exists!\")\n\n# =====================================\n# 4. DATASET CLASS\n# =====================================\n\nclass DogEmotionDataset(Dataset):\n    \"\"\"Dataset class for dog emotion recognition\"\"\"\n    \n    def __init__(self, root, labels_csv, transform=None):\n        self.root = root\n        df = pd.read_csv(labels_csv)\n        self.items = df[['filename', 'label']].values\n        unique_labels = sorted(df['label'].unique())\n        self.label2index = {name: i for i, name in enumerate(unique_labels)}\n        self.index2label = {i: name for name, i in self.label2index.items()}\n        self.transform = transform\n        print(f\"üìä Dataset: {len(self.items)} samples\")\n        print(f\"üè∑Ô∏è  Classes: {list(self.label2index.keys())}\")\n\n    def __len__(self):\n        return len(self.items)\n    \n    def __getitem__(self, idx):\n        fn, label_str = self.items[idx]\n        label_idx = self.label2index[label_str]\n        img_path = os.path.join(self.root, label_str, fn)\n        \n        try:\n            img = Image.open(img_path).convert('RGB')\n            if self.transform:\n                img = self.transform(img)\n            return img, label_idx\n        except Exception as e:\n            # Fallback for corrupted images\n            img = Image.new('RGB', (224, 224), (0, 0, 0))\n            if self.transform:\n                img = self.transform(img)\n            return img, label_idx\n\n# =====================================\n# 5. DATA PREPARATION\n# =====================================\n\nprint(\"\\nüîç Preparing dataset...\")\n\n# Dataset paths\ndata_root = os.path.join(\"cropped_dataset_4k_face\", \"Dog Emotion\")\nlabels_csv = os.path.join(data_root, \"labels.csv\")\n\nprint(f\"\\nüìÇ Dataset structure:\")\nemotions = [d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))]\nprint(f\"   Emotion classes: {emotions}\")\n\nfor emotion in emotions:\n    emotion_path = os.path.join(data_root, emotion)\n    if os.path.isdir(emotion_path):\n        count = len([f for f in os.listdir(emotion_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n        print(f\"     {emotion}: {count} images\")\n\nprint(f\"   Labels CSV: {'‚úÖ' if os.path.exists(labels_csv) else '‚ùå'} {labels_csv}\")\n\n# Create dataset\ndataset = DogEmotionDataset(data_root, labels_csv, None)  # Transform will be set later\nNUM_CLASSES = len(dataset.label2index)\nEMOTION_CLASSES = list(dataset.label2index.keys())\n\nprint(f\"\\n‚úÖ Dataset ready:\")\nprint(f\"   Total samples: {len(dataset)}\")\nprint(f\"   Number of classes: {NUM_CLASSES}\")\nprint(f\"   Emotion classes: {EMOTION_CLASSES}\")\n\n# =====================================\n# 6. TRAINING FUNCTIONS\n# =====================================\n\ndef train_epoch(model, dataloader, criterion, optimizer, device):\n    \"\"\"Train model for one epoch\"\"\"\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    pbar = tqdm(dataloader, desc=\"Training\")\n    for images, labels in pbar:\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        # Statistics\n        running_loss += loss.item()\n        _, predicted = torch.max(outputs.data, 1)\n        total += labels.size(0)\n        correct += (predicted == labels).sum().item()\n        \n        # Update progress bar\n        pbar.set_postfix({\n            'Loss': f'{loss.item():.4f}',\n            'Acc': f'{100.*correct/total:.2f}%'\n        })\n    \n    epoch_loss = running_loss / len(dataloader)\n    epoch_acc = 100. * correct / total\n    \n    return epoch_loss, epoch_acc\n\ndef evaluate_model(model, dataloader, criterion, device):\n    \"\"\"Evaluate model on validation set\"\"\"\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    all_predicted = []\n    all_labels = []\n    \n    with torch.no_grad():\n        pbar = tqdm(dataloader, desc=\"Evaluating\")\n        for images, labels in pbar:\n            images, labels = images.to(device), labels.to(device)\n            \n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item()\n            _, predicted = torch.max(outputs.data, 1)\n            total += labels.size(0)\n            correct += (predicted == labels).sum().item()\n            \n            all_predicted.extend(predicted.cpu().numpy())\n            all_labels.extend(labels.cpu().numpy())\n            \n            pbar.set_postfix({\n                'Loss': f'{loss.item():.4f}',\n                'Acc': f'{100.*correct/total:.2f}%'\n            })\n    \n    epoch_loss = running_loss / len(dataloader)\n    epoch_acc = 100. * correct / total\n    \n    return epoch_loss, epoch_acc, all_predicted, all_labels\n\n# =====================================\n# 7. CROSS-VALIDATION TRAINING\n# =====================================\n\nprint(\"\\nüéØ Starting 5-Fold Cross-Validation Training...\")\n\n# Training parameters\nn_folds = 5\nepochs = 50\nbatch_size = 16\nlearning_rate = 1e-4\ninput_size = 224\n\n# Data transforms\ntrain_transform = transforms.Compose([\n    transforms.Resize((input_size, input_size)),\n    transforms.RandomHorizontalFlip(p=0.5),\n    transforms.RandomRotation(degrees=15),\n    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\nval_transform = transforms.Compose([\n    transforms.Resize((input_size, input_size)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n])\n\n# Prepare labels for stratified split\nlabels = [dataset.label2index[item[1]] for item in dataset.items]\nlabels = np.array(labels)\n\n# Initialize cross-validation\nskf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n\n# Storage for results\nfold_results = []\nall_train_losses = []\nall_val_losses = []\nall_train_accs = []\nall_val_accs = []\n\n# Training loop\nfor fold, (train_idx, val_idx) in enumerate(skf.split(np.arange(len(dataset)), labels)):\n    print(f\"\\n{'='*20} FOLD {fold+1}/{n_folds} {'='*20}\")\n    \n    print(f\"Train samples: {len(train_idx)}\")\n    print(f\"Validation samples: {len(val_idx)}\")\n    \n    # Create data samplers\n    train_sampler = SubsetRandomSampler(train_idx)\n    val_sampler = SubsetRandomSampler(val_idx)\n    \n    # Set transforms\n    dataset.transform = train_transform\n    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n    \n    dataset.transform = val_transform  \n    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler, num_workers=2)\n    \n    # Create model using custom function\n    model = create_coatnet_model(num_classes=NUM_CLASSES)\n    model = model.to(device)\n    \n    # Loss and optimizer\n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n    \n    # Training tracking\n    train_losses = []\n    val_losses = []\n    train_accs = []\n    val_accs = []\n    best_val_acc = 0.0\n    \n    # Training epochs\n    for epoch in range(epochs):\n        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n        print(\"-\" * 30)\n        \n        # Train\n        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n        \n        # Validate\n        val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion, device)\n        \n        # Update scheduler\n        scheduler.step()\n        \n        # Save metrics\n        train_losses.append(train_loss)\n        val_losses.append(val_loss)\n        train_accs.append(train_acc)\n        val_accs.append(val_acc)\n        \n        # Print progress\n        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n        \n        # Save best model\n        if val_acc > best_val_acc:\n            best_val_acc = val_acc\n            torch.save(model.state_dict(), f'coatnet_fold_{fold+1}_best.pth')\n            print(f\"üíæ New best model saved! Accuracy: {best_val_acc:.2f}%\")\n    \n    # Store fold results\n    fold_results.append({\n        'fold': fold + 1,\n        'best_val_acc': best_val_acc,\n        'train_losses': train_losses,\n        'val_losses': val_losses,\n        'train_accs': train_accs,\n        'val_accs': val_accs\n    })\n    \n    all_train_losses.append(train_losses)\n    all_val_losses.append(val_losses)\n    all_train_accs.append(train_accs)\n    all_val_accs.append(val_accs)\n    \n    print(f\"\\n‚úÖ Fold {fold+1} completed! Best validation accuracy: {best_val_acc:.2f}%\")\n\n# =====================================\n# 8. RESULTS ANALYSIS\n# =====================================\n\nprint(\"\\nüìä Training Results Analysis\")\nprint(\"=\" * 50)\n\n# Calculate statistics\nfold_accuracies = [result['best_val_acc'] for result in fold_results]\nmean_acc = np.mean(fold_accuracies)\nstd_acc = np.std(fold_accuracies)\n\nprint(f\"Cross-Validation Results:\")\nprint(f\"Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\nprint(f\"Best Fold: {max(fold_accuracies):.2f}%\")\nprint(f\"Worst Fold: {min(fold_accuracies):.2f}%\")\n\nprint(\"\\nFold-by-fold results:\")\nfor i, acc in enumerate(fold_accuracies):\n    print(f\"Fold {i+1}: {acc:.2f}%\")\n\n# =====================================\n# 9. VISUALIZATION\n# =====================================\n\nprint(\"\\nüìà Creating visualizations...\")\n\n# Set up plotting style\nplt.style.use('default')\nsns.set_palette(\"husl\")\n\n# Create comprehensive visualization\nfig, axes = plt.subplots(2, 2, figsize=(15, 12))\nfig.suptitle('CoAtNet Cross-Validation Training Results', fontsize=16, fontweight='bold')\n\n# 1. Training and Validation Loss\nax1 = axes[0, 0]\nfor fold in range(n_folds):\n    epochs_range = range(1, epochs + 1)\n    ax1.plot(epochs_range, all_train_losses[fold], alpha=0.7, label=f'Fold {fold+1} Train')\n    ax1.plot(epochs_range, all_val_losses[fold], alpha=0.7, linestyle='--', label=f'Fold {fold+1} Val')\n\nax1.set_title('Training and Validation Loss')\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss')\nax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nax1.grid(True, alpha=0.3)\n\n# 2. Training and Validation Accuracy\nax2 = axes[0, 1]\nfor fold in range(n_folds):\n    epochs_range = range(1, epochs + 1)\n    ax2.plot(epochs_range, all_train_accs[fold], alpha=0.7, label=f'Fold {fold+1} Train')\n    ax2.plot(epochs_range, all_val_accs[fold], alpha=0.7, linestyle='--', label=f'Fold {fold+1} Val')\n\nax2.set_title('Training and Validation Accuracy')\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Accuracy (%)')\nax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\nax2.grid(True, alpha=0.3)\n\n# 3. Cross-Validation Accuracy Distribution\nax3 = axes[1, 0]\nax3.bar(range(1, n_folds + 1), fold_accuracies, alpha=0.7, color='skyblue', edgecolor='navy')\nax3.axhline(y=mean_acc, color='red', linestyle='--', label=f'Mean: {mean_acc:.2f}%')\nax3.set_title('Cross-Validation Accuracy by Fold')\nax3.set_xlabel('Fold')\nax3.set_ylabel('Accuracy (%)')\nax3.set_xticks(range(1, n_folds + 1))\nax3.legend()\nax3.grid(True, alpha=0.3)\n\n# Add accuracy values on bars\nfor i, acc in enumerate(fold_accuracies):\n    ax3.text(i + 1, acc + 0.5, f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n\n# 4. Model Performance Summary\nax4 = axes[1, 1]\nax4.axis('off')\n\n# Create summary text\nsummary_text = f\"\"\"\nCOATNET TRAINING SUMMARY\n{'='*len(display_name)}\n\nDataset: Dog Emotion Recognition\nArchitecture: CoAtNet\nInput Size: 224√ó224\nClasses: {NUM_CLASSES}\n\nTraining Configuration:\n‚Ä¢ Folds: {n_folds}\n‚Ä¢ Epochs per fold: {epochs}\n‚Ä¢ Batch size: {batch_size}\n‚Ä¢ Learning rate: {learning_rate}\n‚Ä¢ Optimizer: Adam\n\nResults:\n‚Ä¢ Mean CV Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\n‚Ä¢ Best Fold Accuracy: {max(fold_accuracies):.2f}%\n‚Ä¢ Total Training Time: {datetime.now().strftime('%H:%M:%S')}\n\nClasses: {', '.join(EMOTION_CLASSES)}\n\"\"\"\n\nax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes, fontsize=11,\n         verticalalignment='top', fontfamily='monospace',\n         bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n\nplt.tight_layout()\nplt.show()\n\n# =====================================\n# 10. SAVE RESULTS\n# =====================================\n\nprint(\"\\nüíæ Saving results...\")\n\n# Save training history\nresults_data = {\n    'fold_results': fold_results,\n    'mean_accuracy': mean_acc,\n    'std_accuracy': std_acc,\n    'emotion_classes': EMOTION_CLASSES,\n    'training_config': {\n        'n_folds': n_folds,\n        'epochs': epochs,\n        'batch_size': batch_size,\n        'learning_rate': learning_rate,\n        'input_size': input_size\n    }\n}\n\nwith open('coatnet_training_results.json', 'w') as f:\n    json.dump(results_data, f, indent=2)\n\nprint(\"‚úÖ Results saved to coatnet_training_results.json\")\n\n# =====================================\n# 11. MODEL DOWNLOAD\n# =====================================\n\nprint(\"\\nüì• Preparing models for download...\")\n\n# Find best model\nbest_fold = fold_accuracies.index(max(fold_accuracies)) + 1\nbest_model_file = f'coatnet_fold_{best_fold}_best.pth'\n\nprint(f\"\\nüèÜ Best model: {best_model_file} (Accuracy: {max(fold_accuracies):.2f}%)\")\n\n# Download best model (in Colab)\ntry:\n    from google.colab import files\n    print(f\"\\nüì• Downloading best model: {best_model_file}\")\n    files.download(best_model_file)\n    files.download('coatnet_training_results.json')\n    print(\"‚úÖ Files downloaded successfully!\")\nexcept ImportError:\n    print(\"‚ö†Ô∏è Not running in Colab - files saved locally\")\n\nprint(\"\\nüéâ CoAtNet Cross-Validation Training Completed!\")\nprint(\"=\" * 60)\nprint(f\"‚úÖ Final Results:\")\nprint(f\"   Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\nprint(f\"   Best Model: {best_model_file} ({max(fold_accuracies):.2f}%)\")\nprint(f\"   Classes: {EMOTION_CLASSES}\")\nprint(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}