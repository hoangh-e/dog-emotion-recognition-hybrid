{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üêï Dog Emotion Classification - MaxViT Cross-Validation Training\n",
        "\n",
        "Notebook n√†y s·∫Ω:\n",
        "1. **C√†i ƒë·∫∑t dependencies** v√† chu·∫©n b·ªã m√¥i tr∆∞·ªùng\n",
        "2. **Download dataset** dog emotion classification  \n",
        "3. **Train MaxViT** v·ªõi 50 epochs s·ª≠ d·ª•ng K-Fold Cross Validation\n",
        "4. **Evaluate** v·ªõi cross-validation scores v√† confusion matrix\n",
        "5. **Download models** v√† results v·ªÅ m√°y\n",
        "\n",
        "---\n",
        "**Author**: Dog Emotion Research Team  \n",
        "**Date**: 2025  \n",
        "**Runtime**: Google Colab (GPU T4/V100 recommended)  \n",
        "**Training**: MaxViT (Multi-Axis Vision Transformer) v·ªõi Cross Validation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# üîß STEP 1: Clone Repository v√† Setup Environment\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Clone repository t·ª´ GitHub\n",
        "REPO_URL = \"https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git\"\n",
        "REPO_NAME = \"dog-emotion-recognition-hybrid\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    print(f\"üì• Cloning repository from {REPO_URL}\")\n",
        "    !git clone {REPO_URL}\n",
        "    print(\"‚úÖ Repository cloned successfully!\")\n",
        "else:\n",
        "    print(f\"‚úÖ Repository already exists: {REPO_NAME}\")\n",
        "\n",
        "# Change to repository directory\n",
        "os.chdir(REPO_NAME)\n",
        "print(f\"üìÅ Current directory: {os.getcwd()}\")\n",
        "\n",
        "# Add to Python path ƒë·ªÉ import modules\n",
        "if os.getcwd() not in sys.path:\n",
        "    sys.path.insert(0, os.getcwd())\n",
        "    print(\"‚úÖ Added repository to Python path\")\n",
        "\n",
        "# Install required packages\n",
        "print(\"üì¶ Installing dependencies...\")\n",
        "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
        "!pip install opencv-python-headless pillow pandas tqdm gdown albumentations matplotlib seaborn\n",
        "!pip install scikit-learn timm ultralytics\n",
        "\n",
        "# üéØ Import MaxViT t·ª´ custom module\n",
        "try:\n",
        "    from dog_emotion_classification.maxvit import (\n",
        "        load_maxvit_model, \n",
        "        predict_emotion_maxvit,\n",
        "        get_maxvit_transforms,\n",
        "        create_maxvit_model,\n",
        "        MaxViTModel\n",
        "    )\n",
        "    print(\"‚úÖ Successfully imported MaxViT module from dog_emotion_classification.maxvit\")\n",
        "    print(\"üìã Available functions:\")\n",
        "    print(\"   - load_maxvit_model()\")\n",
        "    print(\"   - predict_emotion_maxvit()\")\n",
        "    print(\"   - get_maxvit_transforms()\")\n",
        "    print(\"   - create_maxvit_model()\")\n",
        "    print(\"   - MaxViTModel class\")\n",
        "except ImportError as e:\n",
        "    print(f\"‚ùå Failed to import MaxViT module: {e}\")\n",
        "    print(\"Please ensure you're in the repository directory and the module exists.\")\n",
        "    raise\n",
        "\n",
        "# Import libraries\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "from PIL import Image\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "import math\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import KFold, StratifiedKFold\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "import json\n",
        "import zipfile\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(f\"\\nüî• PyTorch version: {torch.__version__}\")\n",
        "print(f\"üöÄ CUDA available: {torch.cuda.is_available()}\")\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"üéØ GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"üíæ GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
        "    device = torch.device('cuda')\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Using CPU - training will be slower\")\n",
        "    device = torch.device('cpu')\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"‚úÖ Environment setup complete!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Download and extract dataset\n",
        "DATASET_ID = \"1ZAgz5u64i3LDbwMFpBXjzsKt6FrhNGdW\"\n",
        "DATASET_ZIP = \"cropped_dataset_4k_face.zip\"\n",
        ""cropped_dataset_4k_face" = \"data\"\n",
        "\n",
        "print(\"üì• Downloading dog emotion dataset...\")\n",
        "if not os.path.exists(DATASET_ZIP):\n",
        "    !gdown {DATASET_ID} -O {DATASET_ZIP}\n",
        "    print(f\"‚úÖ Dataset downloaded: {DATASET_ZIP}\")\n",
        "else:\n",
        "    print(f\"‚úÖ Dataset already exists: {DATASET_ZIP}\")\n",
        "\n",
        "# Extract dataset\n",
        "if not os.path.exists("cropped_dataset_4k_face"):\n",
        "    print(\"üìÇ Extracting dataset...\")\n",
        "    with zipfile.ZipFile(DATASET_ZIP, 'r') as zip_ref:\n",
        "        zip_ref.extractall(".")\n",
        "    print(\"‚úÖ Dataset extracted successfully\")\n",
        "\n",
        "# Dataset paths\n",
        "data_root = os.path.join("cropped_dataset_4k_face", \"cropped_dataset_4k_face\", \"Dog Emotion\")\n",
        "labels_csv = os.path.join(data_root, \"labels.csv\")\n",
        "\n",
        "print(f\"\\nüìÇ Dataset structure:\")\n",
        "emotions = [d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))]\n",
        "print(f\"   Emotion classes: {emotions}\")\n",
        "\n",
        "for emotion in emotions:\n",
        "    emotion_path = os.path.join(data_root, emotion)\n",
        "    if os.path.isdir(emotion_path):\n",
        "        count = len([f for f in os.listdir(emotion_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        print(f\"     {emotion}: {count} images\")\n",
        "\n",
        "print(f\"   Labels CSV: {'‚úÖ' if os.path.exists(labels_csv) else '‚ùå'} {labels_csv}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create Dataset class and MaxViT model implementation\n",
        "class DogEmotionDataset(Dataset):\n",
        "    def __init__(self, root, labels_csv, transform=None):\n",
        "        self.root = root\n",
        "        df = pd.read_csv(labels_csv)\n",
        "        self.items = df[['filename', 'label']].values\n",
        "        unique_labels = sorted(df['label'].unique())\n",
        "        self.label2index = {name: i for i, name in enumerate(unique_labels)}\n",
        "        self.index2label = {i: name for name, i in self.label2index.items()}\n",
        "        self.transform = transform\n",
        "        print(f\"üìä Dataset: {len(self.items)} samples\")\n",
        "        print(f\"üè∑Ô∏è  Classes: {list(self.label2index.keys())}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fn, label_str = self.items[idx]\n",
        "        label_idx = self.label2index[label_str]\n",
        "        img_path = os.path.join(self.root, label_str, fn)\n",
        "        \n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            return img, label_idx\n",
        "        except Exception as e:\n",
        "            img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            return img, label_idx\n",
        "\n",
        "# MaxViT Model Implementation\n",
        "class MBConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, expand_ratio=4):\n",
        "        super(MBConv, self).__init__()\n",
        "        self.stride = stride\n",
        "        self.use_residual = stride == 1 and in_channels == out_channels\n",
        "        \n",
        "        hidden_dim = in_channels * expand_ratio\n",
        "        \n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(in_channels, hidden_dim, 1, bias=False),\n",
        "            nn.BatchNorm2d(hidden_dim),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Conv2d(hidden_dim, hidden_dim, kernel_size, stride, kernel_size//2, groups=hidden_dim, bias=False),\n",
        "            nn.BatchNorm2d(hidden_dim),\n",
        "            nn.ReLU6(inplace=True),\n",
        "            nn.Conv2d(hidden_dim, out_channels, 1, bias=False),\n",
        "            nn.BatchNorm2d(out_channels),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        if self.use_residual:\n",
        "            return x + self.conv(x)\n",
        "        else:\n",
        "            return self.conv(x)\n",
        "\n",
        "class MaxViTBlock(nn.Module):\n",
        "    def __init__(self, dim, num_heads=8, window_size=7):\n",
        "        super().__init__()\n",
        "        self.dim = dim\n",
        "        self.num_heads = num_heads\n",
        "        self.window_size = window_size\n",
        "        \n",
        "        self.norm1 = nn.LayerNorm(dim)\n",
        "        self.attn = nn.MultiheadAttention(dim, num_heads, batch_first=True)\n",
        "        self.norm2 = nn.LayerNorm(dim)\n",
        "        \n",
        "        self.mlp = nn.Sequential(\n",
        "            nn.Linear(dim, dim * 4),\n",
        "            nn.GELU(),\n",
        "            nn.Linear(dim * 4, dim),\n",
        "        )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        \n",
        "        # Reshape for attention\n",
        "        x = x.flatten(2).transpose(1, 2)  # B, H*W, C\n",
        "        \n",
        "        # Multi-head attention\n",
        "        x_norm = self.norm1(x)\n",
        "        attn_out, _ = self.attn(x_norm, x_norm, x_norm)\n",
        "        x = x + attn_out\n",
        "        \n",
        "        # MLP\n",
        "        x = x + self.mlp(self.norm2(x))\n",
        "        \n",
        "        # Reshape back\n",
        "        x = x.transpose(1, 2).reshape(B, C, H, W)\n",
        "        return x\n",
        "\n",
        "class MaxViTModel(nn.Module):\n",
        "    def __init__(self, num_classes=4, embed_dim=768):\n",
        "        super().__init__()\n",
        "        \n",
        "        # Stem\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, 3, 1, 1, bias=False),\n",
        "            nn.BatchNorm2d(64),\n",
        "            nn.ReLU(inplace=True),\n",
        "        )\n",
        "        \n",
        "        # Stages\n",
        "        self.stage1 = nn.Sequential(\n",
        "            MBConv(64, 96, stride=2),\n",
        "            MBConv(96, 96),\n",
        "        )\n",
        "        \n",
        "        self.stage2 = nn.Sequential(\n",
        "            MBConv(96, 192, stride=2),\n",
        "            MBConv(192, 192),\n",
        "            MaxViTBlock(192, num_heads=6),\n",
        "        )\n",
        "        \n",
        "        self.stage3 = nn.Sequential(\n",
        "            MBConv(192, 384, stride=2),\n",
        "            MBConv(384, 384),\n",
        "            MaxViTBlock(384, num_heads=12),\n",
        "        )\n",
        "        \n",
        "        self.stage4 = nn.Sequential(\n",
        "            MBConv(384, embed_dim, stride=2),\n",
        "            MBConv(embed_dim, embed_dim),\n",
        "            MaxViTBlock(embed_dim, num_heads=16),\n",
        "        )\n",
        "        \n",
        "        # Head\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.stage1(x)\n",
        "        x = self.stage2(x)\n",
        "        x = self.stage3(x)\n",
        "        x = self.stage4(x)\n",
        "        \n",
        "        x = self.global_pool(x)\n",
        "        x = x.flatten(1)\n",
        "        x = self.head(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "# Create transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Create dataset\n",
        "dataset = DogEmotionDataset(data_root, labels_csv, train_transform)\n",
        "NUM_CLASSES = len(dataset.label2index)\n",
        "EMOTION_CLASSES = list(dataset.label2index.keys())\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset ready:\")\n",
        "print(f\"   Total samples: {len(dataset)}\")\n",
        "print(f\"   Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"   Emotion classes: {EMOTION_CLASSES}\")\n",
        "\n",
        "# Cross-validation configuration\n",
        "K_FOLDS = 5\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "print(f\"\\nüîÑ Cross-Validation Configuration:\")\n",
        "print(f\"   K-Folds: {K_FOLDS}\")\n",
        "print(f\"   Epochs per fold: {EPOCHS}\")\n",
        "print(f\"   Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   Learning rate: {LEARNING_RATE}\")\n",
        "\n",
        "# Prepare labels for stratified split\n",
        "labels = [dataset.label2index[item[1]] for item in dataset.items]\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Create stratified K-fold\n",
        "kfold = StratifiedKFold(n_splits=K_FOLDS, shuffle=True, random_state=42)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Training and evaluation functions\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device, epoch, total_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(dataloader, desc=f\"Epoch {epoch+1}/{total_epochs}\")\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "        \n",
        "        if batch_idx % 10 == 0:\n",
        "            pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "    \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        for data, target in tqdm(dataloader, desc=\"Validation\"):\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "            \n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "    \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    return epoch_loss, epoch_acc, all_preds, all_targets\n",
        "\n",
        "# Cross-validation training\n",
        "print(\"üéØ Starting 5-Fold Cross-Validation Training...\")\n",
        "\n",
        "# Store results\n",
        "fold_results = []\n",
        "all_val_accs = []\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(range(len(dataset)), labels)):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üîÑ FOLD {fold + 1}/5\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Create data samplers\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    val_sampler = SubsetRandomSampler(val_idx)\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(dataset, batch_size=BATCH_SIZE, sampler=train_sampler, num_workers=2)\n",
        "    val_loader = DataLoader(\n",
        "        DogEmotionDataset(data_root, labels_csv, val_transform), \n",
        "        batch_size=BATCH_SIZE, sampler=val_sampler, num_workers=2\n",
        "    )\n",
        "    \n",
        "    print(f\"üìä Fold {fold + 1} data:\")\n",
        "    print(f\"   - Training samples: {len(train_idx)}\")\n",
        "    print(f\"   - Validation samples: {len(val_idx)}\")\n",
        "    \n",
        "    # Create model\n",
        "    model = MaxViTModel(num_classes=NUM_CLASSES).to(device)\n",
        "    \n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
        "    \n",
        "    # Training history\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "    \n",
        "    best_val_acc = 0.0\n",
        "    best_model_state = None\n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in range(EPOCHS):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{EPOCHS}\")\n",
        "        \n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch, EPOCHS)\n",
        "        \n",
        "        # Validate\n",
        "        val_loss, val_acc, val_preds, val_targets = validate_epoch(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict().copy()\n",
        "        \n",
        "        # Record history\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "        \n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "    \n",
        "    # Load best model for final evaluation\n",
        "    model.load_state_dict(best_model_state)\n",
        "    final_val_loss, final_val_acc, final_preds, final_targets = validate_epoch(model, val_loader, criterion, device)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Fold {fold + 1} completed!\")\n",
        "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    # Store results\n",
        "    fold_results.append({\n",
        "        'fold': fold + 1,\n",
        "        'train_losses': train_losses,\n",
        "        'train_accs': train_accs,\n",
        "        'val_losses': val_losses,\n",
        "        'val_accs': val_accs,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'final_preds': final_preds,\n",
        "        'final_targets': final_targets,\n",
        "        'model_state': best_model_state\n",
        "    })\n",
        "    all_val_accs.append(best_val_acc)\n",
        "    \n",
        "    # Memory cleanup\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Calculate overall statistics\n",
        "mean_acc = np.mean(all_val_accs)\n",
        "std_acc = np.std(all_val_accs)\n",
        "\n",
        "print(f\"\\nüéâ CROSS-VALIDATION COMPLETED!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"üìä Final Results:\")\n",
        "print(f\"   - Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"   - Individual Folds: {[f'{acc:.2f}%' for acc in all_val_accs]}\")\n",
        "print(f\"   - Best Fold: {np.argmax(all_val_accs) + 1} ({max(all_val_accs):.2f}%)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualization and model saving\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create comprehensive plots\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "# 1. Training curves for all folds\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "for result in fold_results:\n",
        "    epochs = range(1, len(result['train_losses']) + 1)\n",
        "    plt.plot(epochs, result['train_losses'], label=f\"Fold {result['fold']}\", alpha=0.7)\n",
        "plt.title('Training Loss Across Folds', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Validation curves for all folds\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "for result in fold_results:\n",
        "    epochs = range(1, len(result['val_accs']) + 1)\n",
        "    plt.plot(epochs, result['val_accs'], label=f\"Fold {result['fold']}\", alpha=0.7)\n",
        "plt.title('Validation Accuracy Across Folds', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Fold comparison\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "fold_names = [f'Fold {i+1}' for i in range(K_FOLDS)]\n",
        "bars = plt.bar(fold_names, all_val_accs, color=sns.color_palette(\"husl\", K_FOLDS))\n",
        "plt.title('Best Validation Accuracy by Fold', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, all_val_accs):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "             f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Add mean line\n",
        "plt.axhline(y=mean_acc, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_acc:.1f}%')\n",
        "plt.legend()\n",
        "\n",
        "# 4. Confusion Matrix for best fold\n",
        "best_fold_idx = np.argmax(all_val_accs)\n",
        "best_result = fold_results[best_fold_idx]\n",
        "\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "cm = confusion_matrix(best_result['final_targets'], best_result['final_preds'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=EMOTION_CLASSES,\n",
        "            yticklabels=EMOTION_CLASSES)\n",
        "plt.title(f'Confusion Matrix - Best Fold ({best_fold_idx+1})', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "# 5. Training vs Validation curves for best fold\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "epochs = range(1, len(best_result['train_accs']) + 1)\n",
        "plt.plot(epochs, best_result['train_accs'], label='Training', linewidth=2)\n",
        "plt.plot(epochs, best_result['val_accs'], label='Validation', linewidth=2)\n",
        "plt.title(f'Training vs Validation - Best Fold ({best_fold_idx+1})', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Statistics summary\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "ax6.axis('off')\n",
        "stats_text = f\"\"\"\n",
        "üìä MaxViT Cross-Validation Results\n",
        "\n",
        "üéØ Model Performance:\n",
        "   ‚Ä¢ Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\n",
        "   ‚Ä¢ Best Fold: {best_fold_idx+1} ({max(all_val_accs):.2f}%)\n",
        "   ‚Ä¢ Worst Fold: {np.argmin(all_val_accs)+1} ({min(all_val_accs):.2f}%)\n",
        "\n",
        "‚öôÔ∏è Training Configuration:\n",
        "   ‚Ä¢ Architecture: MaxViT (Multi-Axis ViT)\n",
        "   ‚Ä¢ Epochs per fold: {EPOCHS}\n",
        "   ‚Ä¢ Batch size: {BATCH_SIZE}\n",
        "   ‚Ä¢ Learning rate: {LEARNING_RATE}\n",
        "   ‚Ä¢ Device: {device}\n",
        "\n",
        "üìà Data Information:\n",
        "   ‚Ä¢ Total samples: {len(dataset)}\n",
        "   ‚Ä¢ Classes: {len(EMOTION_CLASSES)}\n",
        "   ‚Ä¢ Folds: {K_FOLDS} (stratified)\n",
        "\"\"\"\n",
        "\n",
        "ax6.text(0.1, 0.9, stats_text, transform=ax6.transAxes, fontsize=12,\n",
        "         verticalalignment='top', fontfamily='monospace',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightgreen\", alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('maxvit_cross_validation_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Visualizations created and saved!\")\n",
        "\n",
        "# Save best model\n",
        "best_model = MaxViTModel(num_classes=NUM_CLASSES)\n",
        "best_model.load_state_dict(fold_results[best_fold_idx]['model_state'])\n",
        "model_filename = f'maxvit_best_fold_{best_fold_idx+1}_acc_{max(all_val_accs):.2f}.pth'\n",
        "\n",
        "# Save model state dict\n",
        "torch.save({\n",
        "    'model_state_dict': best_model.state_dict(),\n",
        "    'model_config': {\n",
        "        'num_classes': NUM_CLASSES,\n",
        "        'architecture': 'MaxViT',\n",
        "        'embed_dim': 768\n",
        "    },\n",
        "    'training_info': {\n",
        "        'best_fold': best_fold_idx + 1,\n",
        "        'best_accuracy': max(all_val_accs),\n",
        "        'mean_accuracy': mean_acc,\n",
        "        'std_accuracy': std_acc,\n",
        "        'epochs': EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE\n",
        "    },\n",
        "    'class_names': EMOTION_CLASSES\n",
        "}, model_filename)\n",
        "\n",
        "print(f\"‚úÖ Model saved as: {model_filename}\")\n",
        "\n",
        "# Save training results\n",
        "results_filename = 'maxvit_training_results.json'\n",
        "training_results = {\n",
        "    'cross_validation_results': {\n",
        "        'mean_accuracy': float(mean_acc),\n",
        "        'std_accuracy': float(std_acc),\n",
        "        'fold_accuracies': [float(acc) for acc in all_val_accs],\n",
        "        'best_fold': int(best_fold_idx + 1),\n",
        "        'best_accuracy': float(max(all_val_accs))\n",
        "    },\n",
        "    'training_config': {\n",
        "        'epochs': EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'device': str(device)\n",
        "    },\n",
        "    'dataset_info': {\n",
        "        'total_samples': len(dataset),\n",
        "        'num_classes': NUM_CLASSES,\n",
        "        'class_names': EMOTION_CLASSES\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(results_filename, 'w') as f:\n",
        "    json.dump(training_results, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Training results saved as: {results_filename}\")\n",
        "\n",
        "# Download files (for Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"\\nüì• Downloading files...\")\n",
        "    files.download(model_filename)\n",
        "    files.download(results_filename)\n",
        "    files.download('maxvit_cross_validation_results.png')\n",
        "    print(\"‚úÖ Files downloaded successfully!\")\n",
        "except ImportError:\n",
        "    print(\"üìÅ Files saved locally (not in Colab environment)\")\n",
        "\n",
        "print(f\"\\nüéâ MAXVIT CROSS-VALIDATION TRAINING COMPLETED!\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"üìä FINAL RESULTS SUMMARY:\")\n",
        "print(f\"   üéØ Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"   üèÜ Best Fold: {best_fold_idx+1} with {max(all_val_accs):.2f}% accuracy\")\n",
        "print(f\"   üìà All Fold Accuracies: {[f'{acc:.2f}%' for acc in all_val_accs]}\")\n",
        "print(f\"   üíæ Model saved as: {model_filename}\")\n",
        "print(f\"   üìä Results saved as: {results_filename}\")\n",
        "print(f\"   üñºÔ∏è Visualization saved as: maxvit_cross_validation_results.png\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "print(f\"\\nüìã HOW TO USE THE TRAINED MODEL:\")\n",
        "print(f\"1. Load the model:\")\n",
        "print(f\"   model = MaxViTModel(num_classes=4)\")\n",
        "print(f\"   checkpoint = torch.load('{model_filename}')\")\n",
        "print(f\"   model.load_state_dict(checkpoint['model_state_dict'])\")\n",
        "print(f\"2. Use for inference on new dog images\")\n",
        "print(f\"3. Classes: {EMOTION_CLASSES}\")\n",
        "\n",
        "print(f\"\\nüéØ MaxViT training completed successfully!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
