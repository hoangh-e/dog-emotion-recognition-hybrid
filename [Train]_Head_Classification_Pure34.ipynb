{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9v02Plo_zxyK",
        "outputId": "cd085971-f49e-43ac-ad08-6d17e90c8e90"
      },
      "outputs": [],
      "source": [
        "!gdown 1G2DkYk-vpbTOZJhpgOm9Sj1peYnLqvie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "T9x10DQE0D8m",
        "outputId": "1ee46e5a-883c-46cd-ee15-a49c07a47ed3"
      },
      "outputs": [],
      "source": [
        "!pip install torch torchvision albumentations pandas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VziHvAU-zjXA",
        "outputId": "52346de0-839b-4762-d9f1-bc27b654ce95"
      },
      "outputs": [],
      "source": [
        "\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "zip_path = \"/content/cropped_dataset_4k_face.zip\"\n",
        "extract_path = \"/content/data\"  # nơi chứa dữ liệu sau giải nén\n",
        "\n",
        "with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(extract_path)\n",
        "\n",
        "# Kiểm tra kết quả\n",
        "print(\"File sau khi giải nén:\")\n",
        "print(os.listdir(extract_path))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "yb2K_XcOzysp"
      },
      "outputs": [],
      "source": [
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import pandas as pd\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class MyDataset(Dataset):\n",
        "    def __init__(self, root, labels_csv, transform=None):\n",
        "        self.root = root\n",
        "        df = pd.read_csv(labels_csv)\n",
        "        self.items = df[['filename', 'label']].values\n",
        "\n",
        "        # Tạo ánh xạ label → chỉ số\n",
        "        unique_labels = sorted(df['label'].unique())\n",
        "        self.label2index = {name: i for i, name in enumerate(unique_labels)}\n",
        "\n",
        "        self.transform = transform\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        fn, label_str = self.items[idx]\n",
        "        label_idx = self.label2index[label_str]\n",
        "        img_path = os.path.join(self.root, label_str, fn)\n",
        "        img = Image.open(img_path).convert('RGB')\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "        return img, label_idx\n",
        "\n",
        "\n",
        "\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(512),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485,0.456,0.406],\n",
        "                         std=[0.229,0.224,0.225]),\n",
        "])\n",
        "dataset = MyDataset('/content/data/Dog Emotion', '/content/data/Dog Emotion/labels.csv', transform)\n",
        "loader = DataLoader(dataset, batch_size=8, shuffle=True, num_workers=2)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "odfLzSl_1NrA",
        "outputId": "dadb1ff8-911f-4820-bc76-e48d0da41997"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import importlib\n",
        "import pure34\n",
        "import torch.nn as nn\n",
        "from pure34 import PURe34\n",
        "importlib.reload(pure34)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "hCwm55d00fba",
        "outputId": "365e9392-84cb-49d1-a4b4-19a093852bd3"
      },
      "outputs": [],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = PURe34(num_classes=4).to(device)\n",
        "opt = torch.optim.SGD(model.parameters(), lr=0.01, momentum=0.9, weight_decay=1e-4)\n",
        "sched = torch.optim.lr_scheduler.CosineAnnealingLR(opt, T_max=20)\n",
        "crit = nn.CrossEntropyLoss()\n",
        "\n",
        "for epoch in range(20):\n",
        "    model.train()\n",
        "    total, correct = 0,0\n",
        "    try:\n",
        "      for imgs, labels in loader:\n",
        "          imgs, labels = imgs.to(device), labels.to(device)\n",
        "          opt.zero_grad()\n",
        "          logits = model(imgs)\n",
        "          loss = crit(logits, labels)\n",
        "          loss.backward()\n",
        "          opt.step()\n",
        "\n",
        "          pred = logits.argmax(dim=1)\n",
        "          total += labels.size(0)\n",
        "          correct += (pred==labels).sum().item()\n",
        "    except FileNotFoundError:\n",
        "        print('error')\n",
        "        continue\n",
        "    sched.step()\n",
        "    print(f'Epoch {epoch+1}  Acc={correct/total:.4f}  LR={sched.get_last_lr()[0]:.4f}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hLiuNrbf1K5A"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
