# %%
!pip install gdown

# %%
!gdown '1lKIyy2brZJDljHLuAbM3SuBEzTiyiPrq' --output processed_dataset.csv
!gdown '1I4jfPhccUnENqqBoF88mQLotOjrlO4Xt' --output raw_predictions.csv

# %% [markdown]
# ## 1. ğŸ”§ CÃ i Ä‘áº·t vÃ  Import

# %%
import subprocess
import sys

# CÃ i Ä‘áº·t scikit-learn náº¿u chÆ°a cÃ³
try:
    import sklearn
except ImportError:
    subprocess.run([sys.executable, '-m', 'pip', 'install', 'scikit-learn'])

# CÃ i Ä‘áº·t dog_emotion_ml package (náº¿u cÃ³)
try:
    subprocess.run([sys.executable, '-m', 'pip', 'install', 'git+https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git'],
                   capture_output=True, text=True)
    print("âœ… ÄÃ£ cÃ i Ä‘áº·t dog_emotion_ml package")
except:
    print("âš ï¸  KhÃ´ng thá»ƒ cÃ i Ä‘áº·t dog_emotion_ml package, sáº½ sá»­ dá»¥ng implementation tá»± viáº¿t")

# %%
# Import cÃ¡c thÆ° viá»‡n
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.preprocessing import StandardScaler, MaxAbsScaler
from sklearn.model_selection import train_test_split
import warnings
warnings.filterwarnings('ignore')

print("âœ… ÄÃ£ import thÃ nh cÃ´ng cÃ¡c thÆ° viá»‡n!")


# %% [markdown]
# ## 2. ğŸ“‚ Táº£i vÃ  Kiá»ƒm tra Dá»¯ liá»‡u

# %%
CSV_FILE_PATH = "/content/processed_dataset.csv"  # ğŸ”„ THAY Äá»”I ÄÆ¯á»œNG DáºªN NÃ€Y

# Náº¿u khÃ´ng cÃ³ file, táº¡o dá»¯ liá»‡u máº«u Ä‘á»ƒ demo
def create_sample_data(n_samples=1000):
    """Táº¡o dá»¯ liá»‡u máº«u Ä‘á»ƒ demo"""
    np.random.seed(42)

    # Táº¡o ResNet emotion features (xÃ¡c suáº¥t)
    emotion_data = np.random.dirichlet([2, 1, 3, 1], n_samples)  # Bias toward happy

    # Táº¡o YOLO tail features (cÃ³ thá»ƒ lÃ  xÃ¡c suáº¥t hoáº·c binary)
    tail_data = np.random.dirichlet([1, 2, 1], n_samples)  # Bias toward up

    # Táº¡o labels
    labels = np.random.choice(['sad', 'angry', 'happy', 'relaxed'],
                             n_samples, p=[0.2, 0.15, 0.45, 0.2])

    # Táº¡o DataFrame
    data = pd.DataFrame({
        'filename': [f'dog_image_{i:04d}.jpg' for i in range(n_samples)],
        'sad': emotion_data[:, 0],
        'angry': emotion_data[:, 1],
        'happy': emotion_data[:, 2],
        'relaxed': emotion_data[:, 3],
        'down': tail_data[:, 0],
        'up': tail_data[:, 1],
        'mid': tail_data[:, 2],
        'label': labels
    })

    return data

# Thá»­ táº£i dá»¯ liá»‡u thá»±c, náº¿u khÃ´ng cÃ³ thÃ¬ táº¡o dá»¯ liá»‡u máº«u
try:
    df = pd.read_csv(CSV_FILE_PATH)
    print(f"âœ… ÄÃ£ táº£i dá»¯ liá»‡u tá»«: {CSV_FILE_PATH}")
    print(f"ğŸ“Š KÃ­ch thÆ°á»›c dá»¯ liá»‡u: {df.shape}")
except:
    print("âš ï¸  KhÃ´ng tÃ¬m tháº¥y file dá»¯ liá»‡u, táº¡o dá»¯ liá»‡u máº«u...")
    df = create_sample_data(1000)
    print(f"ğŸ“Š ÄÃ£ táº¡o dá»¯ liá»‡u máº«u: {df.shape}")

# Hiá»ƒn thá»‹ thÃ´ng tin dá»¯ liá»‡u
print("\nğŸ“‹ ThÃ´ng tin dá»¯ liá»‡u:")
print(df.info())

print("\nğŸ“Š Máº«u dá»¯ liá»‡u (5 dÃ²ng Ä‘áº§u):")
print(df.head())

# %%
# Kiá»ƒm tra cÃ¡c cá»™t cáº§n thiáº¿t
REQUIRED_COLUMNS = {
    'emotion_cols': ['sad', 'angry', 'happy', 'relaxed'],
    'tail_cols': ['down', 'up', 'mid'],
    'other_cols': ['filename', 'label']
}

print("ğŸ” Kiá»ƒm tra cáº¥u trÃºc dá»¯ liá»‡u:")
missing_cols = []

for col_type, cols in REQUIRED_COLUMNS.items():
    for col in cols:
        if col in df.columns:
            print(f"   âœ… {col}")
        else:
            print(f"   âŒ {col} (thiáº¿u)")
            missing_cols.append(col)

if missing_cols:
    print(f"\nâš ï¸  Cáº£nh bÃ¡o: Thiáº¿u cÃ¡c cá»™t: {missing_cols}")
    print("Vui lÃ²ng kiá»ƒm tra láº¡i tÃªn cá»™t trong file CSV")
else:
    print(f"\nâœ… Táº¥t cáº£ cá»™t cáº§n thiáº¿t Ä‘á»u cÃ³ sáºµn!")


# %% [markdown]
# ## 3. ğŸ“ˆ PhÃ¢n tÃ­ch Dá»¯ liá»‡u TrÆ°á»›c Chuáº©n hÃ³a

# %%
# PhÃ¢n tÃ­ch thá»‘ng kÃª mÃ´ táº£
emotion_cols = ['sad', 'angry', 'happy', 'relaxed']
tail_cols = ['down', 'up', 'mid']

print("ğŸ“Š THá»NG KÃŠ MÃ” Táº¢ - TRÆ¯á»šC CHUáº¨N HÃ“A")
print("=" * 50)

print("\nğŸ­ ResNet Emotion Features:")
emotion_stats = df[emotion_cols].describe()
print(emotion_stats)

print("\nğŸ• YOLO Tail Features:")
tail_stats = df[tail_cols].describe()
print(tail_stats)

# Kiá»ƒm tra tá»•ng xÃ¡c suáº¥t
print("\nğŸ” Kiá»ƒm tra tá»•ng xÃ¡c suáº¥t:")
emotion_sums = df[emotion_cols].sum(axis=1)
tail_sums = df[tail_cols].sum(axis=1)

print(f"Emotion features - Tá»•ng trung bÃ¬nh: {emotion_sums.mean():.4f} (Â±{emotion_sums.std():.4f})")
print(f"Tail features - Tá»•ng trung bÃ¬nh: {tail_sums.mean():.4f} (Â±{tail_sums.std():.4f})")


# %%
# Visualize phÃ¢n phá»‘i dá»¯ liá»‡u trÆ°á»›c chuáº©n hÃ³a
fig, axes = plt.subplots(2, 4, figsize=(16, 8))
fig.suptitle('ğŸ“Š PhÃ¢n Phá»‘i Dá»¯ Liá»‡u TRÆ¯á»šC Chuáº©n HÃ³a', fontsize=16, fontweight='bold')

# Plot emotion features
for i, col in enumerate(emotion_cols):
    axes[0, i].hist(df[col], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
    axes[0, i].set_title(f'Emotion: {col}')
    axes[0, i].set_xlabel('GiÃ¡ trá»‹')
    axes[0, i].set_ylabel('Táº§n suáº¥t')
    axes[0, i].grid(True, alpha=0.3)

# Plot tail features
for i, col in enumerate(tail_cols):
    axes[1, i].hist(df[col], bins=30, alpha=0.7, color='lightcoral', edgecolor='black')
    axes[1, i].set_title(f'Tail: {col}')
    axes[1, i].set_xlabel('GiÃ¡ trá»‹')
    axes[1, i].set_ylabel('Táº§n suáº¥t')
    axes[1, i].grid(True, alpha=0.3)

# Empty subplot
axes[1, 3].axis('off')

plt.tight_layout()
plt.show()

# %%
# PhÃ¢n tÃ­ch correlation
print("ğŸ”— Ma tráº­n tÆ°Æ¡ng quan:")
correlation_matrix = df[emotion_cols + tail_cols].corr()

plt.figure(figsize=(10, 8))
sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0,
            square=True, fmt='.3f', cbar_kws={'label': 'Correlation'})
plt.title('Ma Tráº­n TÆ°Æ¡ng Quan - TrÆ°á»›c Chuáº©n HÃ³a', fontsize=14, fontweight='bold')
plt.tight_layout()
plt.show()

# %% [markdown]
# ## 4. ğŸ”„ Thá»±c hiá»‡n Chuáº©n hÃ³a Dá»¯ liá»‡u

# %%
# Class Ä‘á»ƒ thá»±c hiá»‡n chuáº©n hÃ³a dá»¯ liá»‡u
class DataNormalizer:
    """
    Class chuáº©n hÃ³a dá»¯ liá»‡u theo phÆ°Æ¡ng phÃ¡p:
    - ResNet emotion features: Z-score normalization (StandardScaler)
    - YOLO tail features: Pass-through (khÃ´ng chuáº©n hÃ³a)
    """

    def __init__(self):
        self.emotion_scaler = StandardScaler()
        self.tail_scaler = None  # Pass-through
        self.is_fitted = False

    def fit(self, X_emotion, X_tail=None):
        """
        Fit scaler trÃªn dá»¯ liá»‡u training

        Args:
            X_emotion: array-like, emotion features [sad, angry, happy, relaxed]
            X_tail: array-like, tail features [down, up, mid] (optional)
        """
        print("ğŸ”§ Fitting normalizers...")

        # Fit emotion scaler (Z-score)
        self.emotion_scaler.fit(X_emotion)
        print(f"   âœ… Emotion scaler fitted - Mean: {self.emotion_scaler.mean_}")
        print(f"   âœ… Emotion scaler fitted - Std: {self.emotion_scaler.scale_}")

        # Tail features: pass-through (khÃ´ng cáº§n fit)
        if X_tail is not None:
            print(f"   âœ… Tail features: pass-through (khÃ´ng chuáº©n hÃ³a)")

        self.is_fitted = True
        return self

    def transform(self, X_emotion, X_tail=None):
        """
        Transform dá»¯ liá»‡u

        Args:
            X_emotion: array-like, emotion features
            X_tail: array-like, tail features (optional)

        Returns:
            tuple: (emotion_normalized, tail_passthrough)
        """
        if not self.is_fitted:
            raise ValueError("Normalizer chÆ°a Ä‘Æ°á»£c fit. Gá»i fit() trÆ°á»›c.")

        # Transform emotion features (Z-score)
        X_emotion_norm = self.emotion_scaler.transform(X_emotion)

        # Tail features: pass-through
        X_tail_norm = X_tail.copy() if X_tail is not None else None

        return X_emotion_norm, X_tail_norm

    def fit_transform(self, X_emotion, X_tail=None):
        """Fit vÃ  transform trong má»™t bÆ°á»›c"""
        return self.fit(X_emotion, X_tail).transform(X_emotion, X_tail)

    def inverse_transform_emotion(self, X_emotion_normalized):
        """Inverse transform cho emotion features"""
        if not self.is_fitted:
            raise ValueError("Normalizer chÆ°a Ä‘Æ°á»£c fit.")
        return self.emotion_scaler.inverse_transform(X_emotion_normalized)


# %%
# Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ chuáº©n hÃ³a
print("ğŸ“‹ Chuáº©n bá»‹ dá»¯ liá»‡u Ä‘á»ƒ chuáº©n hÃ³a...")

# TÃ¡ch features
X_emotion = df[emotion_cols].values
X_tail = df[tail_cols].values

print(f"   Emotion features shape: {X_emotion.shape}")
print(f"   Tail features shape: {X_tail.shape}")

# Kiá»ƒm tra dá»¯ liá»‡u trÆ°á»›c chuáº©n hÃ³a
print(f"\nğŸ“Š Thá»‘ng kÃª TRÆ¯á»šC chuáº©n hÃ³a:")
print(f"   Emotion - Mean: {X_emotion.mean(axis=0)}")
print(f"   Emotion - Std: {X_emotion.std(axis=0)}")
print(f"   Tail - Mean: {X_tail.mean(axis=0)}")
print(f"   Tail - Std: {X_tail.std(axis=0)}")

# %%
# Thá»±c hiá»‡n chuáº©n hÃ³a
print("ğŸ”„ Thá»±c hiá»‡n chuáº©n hÃ³a dá»¯ liá»‡u...")

# Khá»Ÿi táº¡o normalizer
normalizer = DataNormalizer()

# Fit vÃ  transform
X_emotion_norm, X_tail_norm = normalizer.fit_transform(X_emotion, X_tail)

print(f"\nâœ… HoÃ n thÃ nh chuáº©n hÃ³a!")
print(f"   Emotion normalized shape: {X_emotion_norm.shape}")
print(f"   Tail passthrough shape: {X_tail_norm.shape}")

# Kiá»ƒm tra káº¿t quáº£ sau chuáº©n hÃ³a
print(f"\nğŸ“Š Thá»‘ng kÃª SAU chuáº©n hÃ³a:")
print(f"   Emotion - Mean: {X_emotion_norm.mean(axis=0)}")
print(f"   Emotion - Std: {X_emotion_norm.std(axis=0)}")
print(f"   Tail - Mean: {X_tail_norm.mean(axis=0)} (khÃ´ng Ä‘á»•i)")
print(f"   Tail - Std: {X_tail_norm.std(axis=0)} (khÃ´ng Ä‘á»•i)")


# %% [markdown]
# ## 5. ğŸ“Š PhÃ¢n tÃ­ch Káº¿t quáº£ Chuáº©n hÃ³a
# 

# %%
# So sÃ¡nh trÆ°á»›c vÃ  sau chuáº©n hÃ³a
fig, axes = plt.subplots(3, 4, figsize=(16, 12))
fig.suptitle('ğŸ“Š So SÃ¡nh TRÆ¯á»šC vÃ  SAU Chuáº©n HÃ³a', fontsize=16, fontweight='bold')

# Emotion features - TrÆ°á»›c chuáº©n hÃ³a
for i, col in enumerate(emotion_cols):
    axes[0, i].hist(X_emotion[:, i], bins=30, alpha=0.7, color='lightblue',
                    edgecolor='black', label='TrÆ°á»›c')
    axes[0, i].set_title(f'TRÆ¯á»šC: {col}')
    axes[0, i].set_xlabel('GiÃ¡ trá»‹')
    axes[0, i].set_ylabel('Táº§n suáº¥t')
    axes[0, i].grid(True, alpha=0.3)
    axes[0, i].legend()

# Emotion features - Sau chuáº©n hÃ³a (Z-score)
for i, col in enumerate(emotion_cols):
    axes[1, i].hist(X_emotion_norm[:, i], bins=30, alpha=0.7, color='lightgreen',
                    edgecolor='black', label='Sau (Z-score)')
    axes[1, i].set_title(f'SAU: {col} (Z-score)')
    axes[1, i].set_xlabel('GiÃ¡ trá»‹ chuáº©n hÃ³a')
    axes[1, i].set_ylabel('Táº§n suáº¥t')
    axes[1, i].grid(True, alpha=0.3)
    axes[1, i].legend()

# Tail features - Pass-through (khÃ´ng Ä‘á»•i)
for i, col in enumerate(tail_cols):
    axes[2, i].hist(X_tail_norm[:, i], bins=30, alpha=0.7, color='lightyellow',
                    edgecolor='black', label='Pass-through')
    axes[2, i].set_title(f'TAIL: {col} (Pass-through)')
    axes[2, i].set_xlabel('GiÃ¡ trá»‹')
    axes[2, i].set_ylabel('Táº§n suáº¥t')
    axes[2, i].grid(True, alpha=0.3)
    axes[2, i].legend()

# Empty subplot
axes[2, 3].axis('off')

plt.tight_layout()
plt.show()


# %%
# Kiá»ƒm tra tÃ­nh cháº¥t Z-score
print("ğŸ” KIá»‚M TRA TÃNH CHáº¤T Z-SCORE:")
print("=" * 40)

for i, col in enumerate(emotion_cols):
    mean_val = X_emotion_norm[:, i].mean()
    std_val = X_emotion_norm[:, i].std()
    print(f"{col:10s}: Mean = {mean_val:8.6f}, Std = {std_val:8.6f}")

print(f"\nâœ… Káº¿t quáº£ mong Ä‘á»£i: Mean â‰ˆ 0.000000, Std â‰ˆ 1.000000")

# Kiá»ƒm tra tail features khÃ´ng Ä‘á»•i
print(f"\nğŸ” KIá»‚M TRA TAIL FEATURES (Pass-through):")
print("=" * 45)

tail_unchanged = np.allclose(X_tail, X_tail_norm)
print(f"Tail features khÃ´ng thay Ä‘á»•i: {tail_unchanged}")

if tail_unchanged:
    print("âœ… Tail features Ä‘Æ°á»£c pass-through thÃ nh cÃ´ng!")
else:
    print("âŒ CÃ³ lá»—i trong quÃ¡ trÃ¬nh pass-through tail features")


# %% [markdown]
# ## 6. ğŸ’¾ Táº¡o Dataset ÄÃ£ Chuáº©n hÃ³a

# %%
# Táº¡o DataFrame má»›i vá»›i dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a
print("ğŸ’¾ Táº¡o dataset Ä‘Ã£ chuáº©n hÃ³a...")

# Táº¡o DataFrame má»›i
df_normalized = df.copy()

# Cáº­p nháº­t emotion features vá»›i giÃ¡ trá»‹ Ä‘Ã£ chuáº©n hÃ³a
for i, col in enumerate(emotion_cols):
    df_normalized[col] = X_emotion_norm[:, i]

# Tail features giá»¯ nguyÃªn (pass-through)
for i, col in enumerate(tail_cols):
    df_normalized[col] = X_tail_norm[:, i]

# ThÃªm suffix Ä‘á»ƒ phÃ¢n biá»‡t
df_normalized.columns = [col + '_normalized' if col in emotion_cols + tail_cols else col
                        for col in df_normalized.columns]

print(f"âœ… ÄÃ£ táº¡o dataset chuáº©n hÃ³a: {df_normalized.shape}")

# Hiá»ƒn thá»‹ máº«u dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a
print(f"\nğŸ“Š Máº«u dá»¯ liá»‡u Ä‘Ã£ chuáº©n hÃ³a:")
print(df_normalized.head())


# %%
# Táº¡o dataset cuá»‘i cÃ¹ng vá»›i tÃªn cá»™t gá»‘c
print("ğŸ“‹ Táº¡o dataset cuá»‘i cÃ¹ng...")

# Dataset cuá»‘i cÃ¹ng vá»›i tÃªn cá»™t gá»‘c
df_final = df.copy()

# Cáº­p nháº­t emotion features
for i, col in enumerate(emotion_cols):
    df_final[col] = X_emotion_norm[:, i]

# Tail features giá»¯ nguyÃªn
for i, col in enumerate(tail_cols):
    df_final[col] = X_tail_norm[:, i]

print(f"âœ… Dataset cuá»‘i cÃ¹ng: {df_final.shape}")

# So sÃ¡nh trÆ°á»›c vÃ  sau
print(f"\nğŸ“Š So sÃ¡nh máº«u dá»¯ liá»‡u:")
print("TRÆ¯á»šC chuáº©n hÃ³a:")
print(df[emotion_cols + tail_cols].head(3))

print("\nSAU chuáº©n hÃ³a:")
print(df_final[emotion_cols + tail_cols].head(3))


# %% [markdown]
# ## 7. ğŸ’¾ LÆ°u Káº¿t quáº£

# %%
# LÆ°u dataset Ä‘Ã£ chuáº©n hÃ³a
OUTPUT_FILE = "/content/normalized_data.csv"  # ğŸ”„ THAY Äá»”I ÄÆ¯á»œNG DáºªN NÃ€Y

print(f"ğŸ’¾ LÆ°u dataset Ä‘Ã£ chuáº©n hÃ³a...")

# LÆ°u file CSV
df_final.to_csv(OUTPUT_FILE, index=False)
print(f"âœ… ÄÃ£ lÆ°u: {OUTPUT_FILE}")

# LÆ°u thÃ´ng tin chuáº©n hÃ³a
SCALER_INFO_FILE = "/content/normalization_info.txt"

with open(SCALER_INFO_FILE, 'w', encoding='utf-8') as f:
    f.write("THÃ”NG TIN CHUáº¨N HÃ“A Dá»® LIá»†U\n")
    f.write("=" * 50 + "\n\n")

    f.write("PHÆ¯Æ NG PHÃP CHUáº¨N HÃ“A:\n")
    f.write(f"- ResNet emotion features: Z-score normalization (StandardScaler)\n")
    f.write(f"- YOLO tail features: Pass-through (khÃ´ng chuáº©n hÃ³a)\n\n")

    f.write("EMOTION FEATURES (Z-score):\n")
    f.write(f"- Columns: {emotion_cols}\n")
    f.write(f"- Original mean: {X_emotion.mean(axis=0)}\n")
    f.write(f"- Original std: {X_emotion.std(axis=0)}\n")
    f.write(f"- Normalized mean: {X_emotion_norm.mean(axis=0)}\n")
    f.write(f"- Normalized std: {X_emotion_norm.std(axis=0)}\n\n")

    f.write("TAIL FEATURES (Pass-through):\n")
    f.write(f"- Columns: {tail_cols}\n")
    f.write(f"- Mean: {X_tail.mean(axis=0)} (khÃ´ng Ä‘á»•i)\n")
    f.write(f"- Std: {X_tail.std(axis=0)} (khÃ´ng Ä‘á»•i)\n\n")

    f.write(f"DATASET INFO:\n")
    f.write(f"- Tá»•ng sá»‘ máº«u: {len(df_final)}\n")
    f.write(f"- Tá»•ng sá»‘ features: {len(emotion_cols + tail_cols)}\n")
    f.write(f"- File Ä‘áº§u ra: {OUTPUT_FILE}\n")

print(f"âœ… ÄÃ£ lÆ°u thÃ´ng tin chuáº©n hÃ³a: {SCALER_INFO_FILE}")


# %%
# LÆ°u scaler Ä‘á»ƒ sá»­ dá»¥ng sau nÃ y
import joblib

SCALER_FILE = "/content/emotion_scaler.pkl"

# LÆ°u scaler
joblib.dump(normalizer.emotion_scaler, SCALER_FILE)
print(f"âœ… ÄÃ£ lÆ°u emotion scaler: {SCALER_FILE}")

# Test load scaler
loaded_scaler = joblib.load(SCALER_FILE)
print(f"âœ… Test load scaler thÃ nh cÃ´ng!")


# %% [markdown]
# ## 8. âœ… TÃ³m táº¯t vÃ  HÆ°á»›ng dáº«n Sá»­ dá»¥ng

# %%
# TÃ³m táº¯t káº¿t quáº£
print("ğŸ‰ HOÃ€N THÃ€NH CHUáº¨N HÃ“A Dá»® LIá»†U!")
print("=" * 50)

print(f"\nğŸ“Š THá»NG KÃŠ Tá»”NG QUAN:")
print(f"   ğŸ“ File Ä‘áº§u vÃ o: {CSV_FILE_PATH}")
print(f"   ğŸ“ File Ä‘áº§u ra: {OUTPUT_FILE}")
print(f"   ğŸ“ˆ Sá»‘ máº«u: {len(df_final):,}")
print(f"   ğŸ¯ Emotion features: {len(emotion_cols)} (Z-score normalized)")
print(f"   ğŸ• Tail features: {len(tail_cols)} (pass-through)")

print(f"\nğŸ”§ PHÆ¯Æ NG PHÃP CHUáº¨N HÃ“A:")
print(f"   âœ… ResNet emotion features: StandardScaler (Z-score)")
print(f"      - Trung bÃ¬nh: 0.000000")
print(f"      - Äá»™ lá»‡ch chuáº©n: 1.000000")
print(f"   âœ… YOLO tail features: Pass-through")
print(f"      - Giá»¯ nguyÃªn giÃ¡ trá»‹ gá»‘c")

print(f"\nğŸ“ FILES ÄÃƒ Táº O:")
print(f"   ğŸ“„ {OUTPUT_FILE} - Dataset Ä‘Ã£ chuáº©n hÃ³a")
print(f"   ğŸ“„ {SCALER_INFO_FILE} - ThÃ´ng tin chuáº©n hÃ³a")
print(f"   ğŸ“„ {SCALER_FILE} - Emotion scaler (Ä‘á»ƒ sá»­ dá»¥ng sau)")

print(f"\nğŸš€ HÆ¯á»šNG DáºªN Sá»¬ Dá»¤NG:")
print(f"   1. Sá»­ dá»¥ng {OUTPUT_FILE} Ä‘á»ƒ huáº¥n luyá»‡n ML models")
print(f"   2. Load scaler tá»« {SCALER_FILE} Ä‘á»ƒ chuáº©n hÃ³a dá»¯ liá»‡u má»›i:")
print(f"""
   import joblib
   scaler = joblib.load('{SCALER_FILE}')
   new_emotion_normalized = scaler.transform(new_emotion_data)
   # Tail features khÃ´ng cáº§n chuáº©n hÃ³a
   """)

print(f"\nâœ… Dataset Ä‘Ã£ sáºµn sÃ ng cho viá»‡c huáº¥n luyá»‡n Machine Learning!")

# %% [markdown]
# ## 9. ğŸ§ª Demo Sá»­ dá»¥ng Dataset ÄÃ£ Chuáº©n hÃ³a

# %%
# Demo nhanh viá»‡c sá»­ dá»¥ng dataset Ä‘Ã£ chuáº©n hÃ³a
print("ğŸ§ª DEMO Sá»¬ Dá»¤NG DATASET ÄÃƒ CHUáº¨N HÃ“A")
print("=" * 45)

# Load dataset Ä‘Ã£ chuáº©n hÃ³a
df_demo = pd.read_csv(OUTPUT_FILE)
print(f"âœ… ÄÃ£ load dataset: {df_demo.shape}")

# TÃ¡ch features vÃ  labels
X_emotion_final = df_demo[emotion_cols].values
X_tail_final = df_demo[tail_cols].values
X_combined = np.hstack([X_emotion_final, X_tail_final])
y = df_demo['label'].values

print(f"ğŸ“Š Features shape: {X_combined.shape}")
print(f"ğŸ¯ Labels shape: {y.shape}")

# Kiá»ƒm tra phÃ¢n phá»‘i labels
from collections import Counter
label_dist = Counter(y)
print(f"\nğŸ“ˆ PhÃ¢n phá»‘i labels:")
for label, count in label_dist.items():
    percentage = (count / len(y)) * 100
    print(f"   {label}: {count} ({percentage:.1f}%)")

# Demo train-test split
from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    X_combined, y, test_size=0.2, random_state=42, stratify=y
)

print(f"\nğŸ“Š Train-Test Split:")
print(f"   Training set: {X_train.shape}")
print(f"   Test set: {X_test.shape}")

print(f"\nğŸ‰ Dataset Ä‘Ã£ sáºµn sÃ ng cho Machine Learning!")
print(f"   - Features Ä‘Ã£ Ä‘Æ°á»£c chuáº©n hÃ³a Ä‘Ãºng cÃ¡ch")
print(f"   - CÃ³ thá»ƒ sá»­ dá»¥ng trá»±c tiáº¿p cho cÃ¡c thuáº­t toÃ¡n ML")
print(f"   - Emotion features: Z-score normalized")
print(f"   - Tail features: Pass-through")



