{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üß† NASNet Cross-Validation Training for Dog Emotion Recognition\n",
        "\n",
        "## T·ªïng quan\n",
        "Notebook n√†y hu·∫•n luy·ªán m√¥ h√¨nh **NASNet (Neural Architecture Search Network)** cho b√†i to√°n nh·∫≠n di·ªán c·∫£m x√∫c ch√≥ v·ªõi:\n",
        "- **Clone repository** t·ª´ GitHub\n",
        "- **Import NASNet module** t·ª´ dog_emotion_classification package\n",
        "- **5-fold Cross-Validation** ƒë·ªÉ ƒë√°nh gi√° robust\n",
        "- **30 epochs** hu·∫•n luy·ªán cho m·ªói fold\n",
        "- **T·ª± ƒë·ªông t·∫£i dataset** t·ª´ Google Drive\n",
        "- **Visualization** k·∫øt qu·∫£ training v√† confusion matrix\n",
        "- **T·ª± ƒë·ªông l∆∞u model** v√† t·∫£i v·ªÅ m√°y\n",
        "\n",
        "## ƒê·∫∑c ƒëi·ªÉm NASNet\n",
        "- **Neural Architecture Search**: Ki·∫øn tr√∫c ƒë∆∞·ª£c t√¨m ki·∫øm t·ª± ƒë·ªông\n",
        "- **Efficient**: C√¢n b·∫±ng gi·ªØa accuracy v√† efficiency\n",
        "- **Scalable**: C√≥ th·ªÉ scale t·ª´ mobile ƒë·∫øn large variants\n",
        "- **State-of-the-art**: Performance cao tr√™n nhi·ªÅu datasets\n",
        "\n",
        "## C√°ch s·ª≠ d·ª•ng\n",
        "1. **Ch·∫°y \"Run All\"** - T·∫•t c·∫£ s·∫Ω ƒë∆∞·ª£c th·ª±c hi·ªán t·ª± ƒë·ªông\n",
        "2. **Ch·ªù k·∫øt qu·∫£** - Kho·∫£ng 2-3 gi·ªù cho 5 folds √ó 30 epochs\n",
        "3. **T·∫£i model** - File .pth s·∫Ω t·ª± ƒë·ªông t·∫£i v·ªÅ\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "üß† NASNet Cross-Validation Training for Dog Emotion Recognition\n",
        "==============================================================\n",
        "\n",
        "Complete pipeline for training NASNet on dog emotion dataset with:\n",
        "- Automatic dataset download and preparation\n",
        "- 5-fold stratified cross-validation\n",
        "- 30 epochs training per fold\n",
        "- Comprehensive visualization and evaluation\n",
        "- Model saving and download\n",
        "\n",
        "Author: Dog Emotion Recognition Team\n",
        "Date: 2024\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import time\n",
        "from datetime import datetime\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "print(\"üöÄ Starting NASNet Cross-Validation Training Pipeline\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# =============================================================================\n",
        "# 1. CLONE REPOSITORY\n",
        "# =============================================================================\n",
        "print(\"\\nüîÑ Cloning repository from GitHub...\")\n",
        "REPO_URL = \"https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git\"\n",
        "REPO_NAME = \"dog-emotion-recognition-hybrid\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    os.system(f\"git clone {REPO_URL}\")\n",
        "    print(\"‚úÖ Repository cloned successfully\")\n",
        "else:\n",
        "    print(\"‚úÖ Repository already exists\")\n",
        "\n",
        "os.chdir(REPO_NAME)\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "# =============================================================================\n",
        "# 2. PACKAGE INSTALLATION\n",
        "# =============================================================================\n",
        "print(\"\\nüì¶ Installing required packages...\")\n",
        "\n",
        "# Install packages\n",
        "packages = [\n",
        "    'torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121',\n",
        "    'gdown',\n",
        "    'scikit-learn',\n",
        "    'matplotlib',\n",
        "    'seaborn',\n",
        "    'Pillow',\n",
        "    'numpy',\n",
        "    'pandas',\n",
        "    'tqdm',\n",
        "    'opencv-python'\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    print(f\"Installing {package.split()[0]}...\")\n",
        "    os.system(f\"pip install {package} -q\")\n",
        "\n",
        "print(\"‚úÖ All packages installed successfully!\")\n",
        "\n",
        "# =============================================================================\n",
        "# 3. IMPORTS\n",
        "# =============================================================================\n",
        "print(\"\\nüìö Importing libraries...\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.models import mobilenet_v3_large\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from PIL import Image\n",
        "import cv2\n",
        "import gdown\n",
        "import json\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from tqdm import tqdm\n",
        "import random\n",
        "from collections import Counter\n",
        "\n",
        "# Import NASNet from our custom module\n",
        "from dog_emotion_classification.nasnet import (\n",
        "    load_nasnet_model,\n",
        "    predict_emotion_nasnet,\n",
        "    get_nasnet_transforms,\n",
        "    create_simple_nasnet\n",
        ")\n",
        "\n",
        "# Set random seeds for reproducibility\n",
        "torch.manual_seed(42)\n",
        "torch.cuda.manual_seed(42)\n",
        "np.random.seed(42)\n",
        "random.seed(42)\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üîß Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "# =============================================================================\n",
        "# 4. DATASET DOWNLOAD AND PREPARATION\n",
        "# =============================================================================\n",
        "print(\"\\nüíæ Downloading and preparing dataset...\")\n",
        "\n",
        "# Download dataset from Google Drive\n",
        "dataset_url = \"https://drive.google.com/uc?id=1ZAgz5u64i3LDbwMFpBXjzsKt6FrhNGdW\"\n",
        "dataset_zip = \"dog_emotion_dataset.zip\"\n",
        "\n",
        "if not os.path.exists(dataset_zip):\n",
        "    print(\"üì• Downloading dataset...\")\n",
        "    gdown.download(dataset_url, dataset_zip, quiet=False)\n",
        "    print(\"‚úÖ Dataset downloaded successfully!\")\n",
        "else:\n",
        "    print(\"üìÅ Dataset already exists, skipping download\")\n",
        "\n",
        "# Extract dataset\n",
        "dataset_dir = \"dog_emotion_dataset\"\n",
        "if not os.path.exists(dataset_dir):\n",
        "    print(\"üìÇ Extracting dataset...\")\n",
        "    with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "    print(\"‚úÖ Dataset extracted successfully!\")\n",
        "else:\n",
        "    print(\"üìÅ Dataset already extracted\")\n",
        "\n",
        "# =============================================================================\n",
        "# 5. NASNET MODEL ARCHITECTURE\n",
        "# =============================================================================\n",
        "print(\"\\nüèóÔ∏è Using NASNet from our custom module...\")\n",
        "        out1 = self.relu(self.bn1(self.conv1(x)))\n",
        "        out2 = self.relu(self.bn2(self.conv2(x)))\n",
        "        out3 = self.relu(self.bn3(self.conv3(x)))\n",
        "        \n",
        "        # Combine outputs\n",
        "        if self.downsample is not None:\n",
        "            residual = self.downsample(x)\n",
        "        else:\n",
        "            residual = x\n",
        "        \n",
        "        # Simple combination strategy\n",
        "        out = out1 + out2 + out3\n",
        "        if out.size() == residual.size():\n",
        "            out = out + residual\n",
        "        \n",
        "        return out\n",
        "\n",
        "class NASNetModel(nn.Module):\n",
        "    \"\"\"Custom NASNet for Dog Emotion Recognition\"\"\"\n",
        "    def __init__(self, num_classes=4, num_cells=6, channels=32):\n",
        "        super(NASNetModel, self).__init__()\n",
        "        \n",
        "        # Stem\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv2d(3, channels, 3, 2, 1, bias=False),\n",
        "            nn.BatchNorm2d(channels),\n",
        "            nn.ReLU(inplace=True)\n",
        "        )\n",
        "        \n",
        "        # NASNet cells\n",
        "        self.cells = nn.ModuleList()\n",
        "        in_channels = channels\n",
        "        \n",
        "        for i in range(num_cells):\n",
        "            is_reduction = (i % 2 == 1)  # Reduction every other cell\n",
        "            out_channels = channels * (2 ** (i // 2))\n",
        "            \n",
        "            self.cells.append(NASNetCell(in_channels, out_channels, is_reduction))\n",
        "            in_channels = out_channels\n",
        "        \n",
        "        # Classifier\n",
        "        self.global_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.classifier = nn.Linear(in_channels, num_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        \n",
        "        for cell in self.cells:\n",
        "            x = cell(x)\n",
        "        \n",
        "        x = self.global_pool(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.classifier(x)\n",
        "        \n",
        "        return x\n",
        "\n",
        "def create_nasnet_model(num_classes=4):\n",
        "    \"\"\"Create NASNet model\"\"\"\n",
        "    model = NASNetModel(num_classes=num_classes)\n",
        "    return model\n",
        "\n",
        "print(\"‚úÖ NASNet model architecture defined!\")\n",
        "\n",
        "# =============================================================================\n",
        "# 5. DATASET CLASS\n",
        "# =============================================================================\n",
        "print(\"\\nüìä Setting up dataset class...\")\n",
        "\n",
        "class DogEmotionDataset(Dataset):\n",
        "    \"\"\"Custom dataset for dog emotion recognition\"\"\"\n",
        "    \n",
        "    def __init__(self, data_dir, transform=None, target_size=(224, 224)):\n",
        "        self.data_dir = Path(data_dir)\n",
        "        self.transform = transform\n",
        "        self.target_size = target_size\n",
        "        \n",
        "        # Emotion classes\n",
        "        self.classes = ['angry', 'happy', 'relaxed', 'sad']\n",
        "        self.class_to_idx = {cls: idx for idx, cls in enumerate(self.classes)}\n",
        "        \n",
        "        # Load all images\n",
        "        self.samples = []\n",
        "        self._load_samples()\n",
        "        \n",
        "        print(f\"üìÅ Dataset loaded: {len(self.samples)} images\")\n",
        "        print(f\"üìä Classes: {self.classes}\")\n",
        "        \n",
        "        # Print class distribution\n",
        "        class_counts = Counter([sample[1] for sample in self.samples])\n",
        "        for cls, count in class_counts.items():\n",
        "            print(f\"   {self.classes[cls]}: {count} images\")\n",
        "    \n",
        "    def _load_samples(self):\n",
        "        \"\"\"Load all image samples\"\"\"\n",
        "        for class_name in self.classes:\n",
        "            class_dir = self.data_dir / class_name\n",
        "            if class_dir.exists():\n",
        "                for img_path in class_dir.glob('*.jpg'):\n",
        "                    if img_path.is_file():\n",
        "                        self.samples.append((str(img_path), self.class_to_idx[class_name]))\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        img_path, label = self.samples[idx]\n",
        "        \n",
        "        try:\n",
        "            # Load image\n",
        "            image = Image.open(img_path).convert('RGB')\n",
        "            \n",
        "            # Resize image\n",
        "            image = image.resize(self.target_size, Image.LANCZOS)\n",
        "            \n",
        "            # Apply transforms\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            return image, label\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è Error loading image {img_path}: {e}\")\n",
        "            # Return a dummy image\n",
        "            dummy_image = Image.new('RGB', self.target_size, color='black')\n",
        "            if self.transform:\n",
        "                dummy_image = self.transform(dummy_image)\n",
        "            return dummy_image, label\n",
        "\n",
        "# =============================================================================\n",
        "# 6. DATA TRANSFORMS\n",
        "# =============================================================================\n",
        "print(\"\\nüîÑ Setting up data transforms...\")\n",
        "\n",
        "# Training transforms with augmentation\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=10),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Validation transforms\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"‚úÖ Data transforms configured!\")\n",
        "\n",
        "# =============================================================================\n",
        "# 7. TRAINING FUNCTIONS\n",
        "# =============================================================================\n",
        "print(\"\\nüèãÔ∏è Setting up training functions...\")\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(dataloader, desc=\"Training\", leave=False)\n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "        \n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'Loss': f'{loss.item():.4f}',\n",
        "            'Acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate_epoch(model, dataloader, criterion, device):\n",
        "    \"\"\"Validate for one epoch\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_preds = []\n",
        "    all_targets = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(dataloader, desc=\"Validation\", leave=False)\n",
        "        for data, target in pbar:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "            \n",
        "            all_preds.extend(predicted.cpu().numpy())\n",
        "            all_targets.extend(target.cpu().numpy())\n",
        "            \n",
        "            pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "    \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc, all_preds, all_targets\n",
        "\n",
        "def train_fold(fold_num, train_dataset, val_dataset, num_epochs=30, batch_size=16, learning_rate=1e-4):\n",
        "    \"\"\"Train one fold\"\"\"\n",
        "    print(f\"\\nüîÑ Training Fold {fold_num + 1}\")\n",
        "    print(\"-\" * 50)\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    \n",
        "    # Create NASNet model using our custom module\n",
        "    model = create_simple_nasnet(num_classes=4, device=device).to(device)\n",
        "    \n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)\n",
        "    \n",
        "    # Training history\n",
        "    train_losses = []\n",
        "    train_accs = []\n",
        "    val_losses = []\n",
        "    val_accs = []\n",
        "    \n",
        "    best_val_acc = 0.0\n",
        "    best_model_state = None\n",
        "    \n",
        "    # Training loop\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f\"\\nEpoch {epoch + 1}/{num_epochs}\")\n",
        "        \n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        \n",
        "        # Validate\n",
        "        val_loss, val_acc, val_preds, val_targets = validate_epoch(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            best_model_state = model.state_dict().copy()\n",
        "        \n",
        "        # Record history\n",
        "        train_losses.append(train_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_losses.append(val_loss)\n",
        "        val_accs.append(val_acc)\n",
        "        \n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "    \n",
        "    # Load best model\n",
        "    model.load_state_dict(best_model_state)\n",
        "    \n",
        "    # Final validation\n",
        "    final_val_loss, final_val_acc, final_preds, final_targets = validate_epoch(model, val_loader, criterion, device)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Fold {fold_num + 1} completed!\")\n",
        "    print(f\"Best Validation Accuracy: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    return {\n",
        "        'model': model,\n",
        "        'train_losses': train_losses,\n",
        "        'train_accs': train_accs,\n",
        "        'val_losses': val_losses,\n",
        "        'val_accs': val_accs,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'final_preds': final_preds,\n",
        "        'final_targets': final_targets\n",
        "    }\n",
        "\n",
        "print(\"‚úÖ Training functions ready!\")\n",
        "\n",
        "# =============================================================================\n",
        "# 8. CROSS-VALIDATION TRAINING\n",
        "# =============================================================================\n",
        "print(\"\\nüéØ Starting 5-Fold Cross-Validation Training...\")\n",
        "\n",
        "# Load full dataset\n",
        "full_dataset = DogEmotionDataset(\n",
        "    data_dir=dataset_dir,\n",
        "    transform=None,  # Will be set per fold\n",
        "    target_size=(224, 224)\n",
        ")\n",
        "\n",
        "# Prepare data for stratified k-fold\n",
        "X = list(range(len(full_dataset)))\n",
        "y = [full_dataset.samples[i][1] for i in X]\n",
        "\n",
        "# 5-fold stratified cross-validation\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Training parameters\n",
        "NUM_EPOCHS = 30\n",
        "BATCH_SIZE = 16\n",
        "LEARNING_RATE = 1e-4\n",
        "\n",
        "# Store results\n",
        "fold_results = []\n",
        "all_val_accs = []\n",
        "\n",
        "print(f\"üìä Training Configuration:\")\n",
        "print(f\"   - Epochs per fold: {NUM_EPOCHS}\")\n",
        "print(f\"   - Batch size: {BATCH_SIZE}\")\n",
        "print(f\"   - Learning rate: {LEARNING_RATE}\")\n",
        "print(f\"   - Device: {device}\")\n",
        "\n",
        "# Start training\n",
        "start_time = time.time()\n",
        "\n",
        "for fold, (train_idx, val_idx) in enumerate(kfold.split(X, y)):\n",
        "    print(f\"\\n{'='*60}\")\n",
        "    print(f\"üîÑ FOLD {fold + 1}/5\")\n",
        "    print(f\"{'='*60}\")\n",
        "    \n",
        "    # Create fold datasets\n",
        "    train_samples = [full_dataset.samples[i] for i in train_idx]\n",
        "    val_samples = [full_dataset.samples[i] for i in val_idx]\n",
        "    \n",
        "    # Create datasets with transforms\n",
        "    train_dataset = DogEmotionDataset(dataset_dir, transform=train_transform)\n",
        "    train_dataset.samples = train_samples\n",
        "    \n",
        "    val_dataset = DogEmotionDataset(dataset_dir, transform=val_transform)\n",
        "    val_dataset.samples = val_samples\n",
        "    \n",
        "    print(f\"üìä Fold {fold + 1} data:\")\n",
        "    print(f\"   - Training samples: {len(train_samples)}\")\n",
        "    print(f\"   - Validation samples: {len(val_samples)}\")\n",
        "    \n",
        "    # Train fold\n",
        "    fold_result = train_fold(fold, train_dataset, val_dataset, NUM_EPOCHS, BATCH_SIZE, LEARNING_RATE)\n",
        "    fold_results.append(fold_result)\n",
        "    all_val_accs.append(fold_result['best_val_acc'])\n",
        "    \n",
        "    # Memory cleanup\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Calculate overall statistics\n",
        "mean_acc = np.mean(all_val_accs)\n",
        "std_acc = np.std(all_val_accs)\n",
        "total_time = time.time() - start_time\n",
        "\n",
        "print(f\"\\nüéâ CROSS-VALIDATION COMPLETED!\")\n",
        "print(f\"{'='*60}\")\n",
        "print(f\"üìä Final Results:\")\n",
        "print(f\"   - Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"   - Individual Folds: {[f'{acc:.2f}%' for acc in all_val_accs]}\")\n",
        "print(f\"   - Total Training Time: {total_time/3600:.2f} hours\")\n",
        "print(f\"   - Best Fold: {np.argmax(all_val_accs) + 1} ({max(all_val_accs):.2f}%)\")\n",
        "\n",
        "# =============================================================================\n",
        "# 9. VISUALIZATION\n",
        "# =============================================================================\n",
        "print(\"\\nüìä Creating visualizations...\")\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create comprehensive plots\n",
        "fig = plt.figure(figsize=(20, 15))\n",
        "\n",
        "# 1. Training curves for all folds\n",
        "ax1 = plt.subplot(2, 3, 1)\n",
        "for fold, result in enumerate(fold_results):\n",
        "    epochs = range(1, len(result['train_losses']) + 1)\n",
        "    plt.plot(epochs, result['train_losses'], label=f'Fold {fold+1}', alpha=0.7)\n",
        "plt.title('Training Loss Across Folds', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Validation curves for all folds\n",
        "ax2 = plt.subplot(2, 3, 2)\n",
        "for fold, result in enumerate(fold_results):\n",
        "    epochs = range(1, len(result['val_accs']) + 1)\n",
        "    plt.plot(epochs, result['val_accs'], label=f'Fold {fold+1}', alpha=0.7)\n",
        "plt.title('Validation Accuracy Across Folds', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Fold comparison\n",
        "ax3 = plt.subplot(2, 3, 3)\n",
        "fold_names = [f'Fold {i+1}' for i in range(5)]\n",
        "bars = plt.bar(fold_names, all_val_accs, color=sns.color_palette(\"husl\", 5))\n",
        "plt.title('Best Validation Accuracy by Fold', fontsize=14, fontweight='bold')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.ylim(0, 100)\n",
        "\n",
        "# Add value labels on bars\n",
        "for bar, acc in zip(bars, all_val_accs):\n",
        "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 1,\n",
        "             f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# Add mean line\n",
        "plt.axhline(y=mean_acc, color='red', linestyle='--', alpha=0.7, label=f'Mean: {mean_acc:.1f}%')\n",
        "plt.legend()\n",
        "\n",
        "# 4. Confusion Matrix for best fold\n",
        "best_fold_idx = np.argmax(all_val_accs)\n",
        "best_result = fold_results[best_fold_idx]\n",
        "\n",
        "ax4 = plt.subplot(2, 3, 4)\n",
        "cm = confusion_matrix(best_result['final_targets'], best_result['final_preds'])\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
        "            xticklabels=['angry', 'happy', 'relaxed', 'sad'],\n",
        "            yticklabels=['angry', 'happy', 'relaxed', 'sad'])\n",
        "plt.title(f'Confusion Matrix - Best Fold ({best_fold_idx+1})', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "\n",
        "# 5. Training vs Validation curves for best fold\n",
        "ax5 = plt.subplot(2, 3, 5)\n",
        "epochs = range(1, len(best_result['train_accs']) + 1)\n",
        "plt.plot(epochs, best_result['train_accs'], label='Training', linewidth=2)\n",
        "plt.plot(epochs, best_result['val_accs'], label='Validation', linewidth=2)\n",
        "plt.title(f'Training vs Validation - Best Fold ({best_fold_idx+1})', fontsize=14, fontweight='bold')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Accuracy (%)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "\n",
        "# 6. Statistics summary\n",
        "ax6 = plt.subplot(2, 3, 6)\n",
        "ax6.axis('off')\n",
        "stats_text = f\"\"\"\n",
        "üìä NASNet Cross-Validation Results\n",
        "\n",
        "üéØ Model Performance:\n",
        "   ‚Ä¢ Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\n",
        "   ‚Ä¢ Best Fold: {best_fold_idx+1} ({max(all_val_accs):.2f}%)\n",
        "   ‚Ä¢ Worst Fold: {np.argmin(all_val_accs)+1} ({min(all_val_accs):.2f}%)\n",
        "\n",
        "‚öôÔ∏è Training Configuration:\n",
        "   ‚Ä¢ Architecture: NASNet Custom\n",
        "   ‚Ä¢ Epochs per fold: {NUM_EPOCHS}\n",
        "   ‚Ä¢ Batch size: {BATCH_SIZE}\n",
        "   ‚Ä¢ Learning rate: {LEARNING_RATE}\n",
        "   ‚Ä¢ Device: {device}\n",
        "\n",
        "‚è±Ô∏è Training Time:\n",
        "   ‚Ä¢ Total: {total_time/3600:.2f} hours\n",
        "   ‚Ä¢ Per fold: {total_time/3600/5:.2f} hours\n",
        "   ‚Ä¢ Per epoch: {total_time/3600/5/NUM_EPOCHS:.2f} hours\n",
        "\n",
        "üìà Data Information:\n",
        "   ‚Ä¢ Total samples: {len(full_dataset)}\n",
        "   ‚Ä¢ Classes: {len(full_dataset.classes)}\n",
        "   ‚Ä¢ Folds: 5 (stratified)\n",
        "\"\"\"\n",
        "\n",
        "ax6.text(0.1, 0.9, stats_text, transform=ax6.transAxes, fontsize=12,\n",
        "         verticalalignment='top', fontfamily='monospace',\n",
        "         bbox=dict(boxstyle=\"round,pad=0.5\", facecolor=\"lightblue\", alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.savefig('nasnet_cross_validation_results.png', dpi=300, bbox_inches='tight')\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Visualizations created and saved!\")\n",
        "\n",
        "# =============================================================================\n",
        "# 10. MODEL SAVING AND DOWNLOAD\n",
        "# =============================================================================\n",
        "print(\"\\nüíæ Saving best model...\")\n",
        "\n",
        "# Save best model\n",
        "best_model = fold_results[best_fold_idx]['model']\n",
        "model_filename = f'nasnet_best_fold_{best_fold_idx+1}_acc_{max(all_val_accs):.2f}.pth'\n",
        "\n",
        "# Save model state dict\n",
        "torch.save({\n",
        "    'model_state_dict': best_model.state_dict(),\n",
        "    'model_config': {\n",
        "        'num_classes': 4,\n",
        "        'architecture': 'NASNet Custom'\n",
        "    },\n",
        "    'training_info': {\n",
        "        'best_fold': best_fold_idx + 1,\n",
        "        'best_accuracy': max(all_val_accs),\n",
        "        'mean_accuracy': mean_acc,\n",
        "        'std_accuracy': std_acc,\n",
        "        'epochs': NUM_EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE\n",
        "    },\n",
        "    'class_names': ['angry', 'happy', 'relaxed', 'sad']\n",
        "}, model_filename)\n",
        "\n",
        "print(f\"‚úÖ Model saved as: {model_filename}\")\n",
        "\n",
        "# Save training results\n",
        "results_filename = 'nasnet_training_results.json'\n",
        "training_results = {\n",
        "    'cross_validation_results': {\n",
        "        'mean_accuracy': float(mean_acc),\n",
        "        'std_accuracy': float(std_acc),\n",
        "        'fold_accuracies': [float(acc) for acc in all_val_accs],\n",
        "        'best_fold': int(best_fold_idx + 1),\n",
        "        'best_accuracy': float(max(all_val_accs))\n",
        "    },\n",
        "    'training_config': {\n",
        "        'epochs': NUM_EPOCHS,\n",
        "        'batch_size': BATCH_SIZE,\n",
        "        'learning_rate': LEARNING_RATE,\n",
        "        'device': str(device),\n",
        "        'total_time_hours': total_time/3600\n",
        "    },\n",
        "    'dataset_info': {\n",
        "        'total_samples': len(full_dataset),\n",
        "        'num_classes': len(full_dataset.classes),\n",
        "        'class_names': full_dataset.classes\n",
        "    }\n",
        "}\n",
        "\n",
        "with open(results_filename, 'w') as f:\n",
        "    json.dump(training_results, f, indent=2)\n",
        "\n",
        "print(f\"‚úÖ Training results saved as: {results_filename}\")\n",
        "\n",
        "# Download files (for Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(\"\\nüì• Downloading files...\")\n",
        "    files.download(model_filename)\n",
        "    files.download(results_filename)\n",
        "    files.download('nasnet_cross_validation_results.png')\n",
        "    print(\"‚úÖ Files downloaded successfully!\")\n",
        "except ImportError:\n",
        "    print(\"üìÅ Files saved locally (not in Colab environment)\")\n",
        "\n",
        "# =============================================================================\n",
        "# 11. FINAL SUMMARY\n",
        "# =============================================================================\n",
        "print(f\"\\nüéâ NASNet CROSS-VALIDATION TRAINING COMPLETED!\")\n",
        "print(f\"{'='*80}\")\n",
        "print(f\"üìä FINAL RESULTS SUMMARY:\")\n",
        "print(f\"   üéØ Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"   üèÜ Best Fold: {best_fold_idx+1} with {max(all_val_accs):.2f}% accuracy\")\n",
        "print(f\"   üìà All Fold Accuracies: {[f'{acc:.2f}%' for acc in all_val_accs]}\")\n",
        "print(f\"   ‚è±Ô∏è Total Training Time: {total_time/3600:.2f} hours\")\n",
        "print(f\"   üíæ Model saved as: {model_filename}\")\n",
        "print(f\"   üìä Results saved as: {results_filename}\")\n",
        "print(f\"   üñºÔ∏è Visualization saved as: nasnet_cross_validation_results.png\")\n",
        "print(f\"{'='*80}\")\n",
        "\n",
        "# Usage instructions\n",
        "print(f\"\\nüìã HOW TO USE THE TRAINED MODEL:\")\n",
        "print(f\"1. Load the model:\")\n",
        "print(f\"   model = create_nasnet_model(num_classes=4)\")\n",
        "print(f\"   checkpoint = torch.load('{model_filename}')\")\n",
        "print(f\"   model.load_state_dict(checkpoint['model_state_dict'])\")\n",
        "print(f\"2. Use for inference on new dog images\")\n",
        "print(f\"3. Classes: {full_dataset.classes}\")\n",
        "\n",
        "print(f\"\\nüéØ Training completed successfully! NASNet is ready for dog emotion recognition.\")\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
