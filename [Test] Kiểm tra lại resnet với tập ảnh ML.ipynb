{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 116754,
     "status": "ok",
     "timestamp": 1751875431655,
     "user": {
      "displayName": "tran dat",
      "userId": "12905468336159583477"
     },
     "user_tz": -420
    },
    "id": "Atx7yieh122f",
    "outputId": "41ef215b-235a-4fb2-ffd6-8cefd4e98195"
   },
   "outputs": [],
   "source": [
    "!pip install roboflow ultralytics torchvision\n",
    "\n",
    "from roboflow import Roboflow\n",
    "\n",
    "print(\"üîó Connecting to Roboflow...\")\n",
    "rf = Roboflow(api_key=\"blm6FIqi33eLS0ewVlKV\")\n",
    "project = rf.workspace(\"2642025\").project(\"19-06\")\n",
    "version = project.version(7)\n",
    "\n",
    "print(\"üì• Downloading dataset...\")\n",
    "dataset = version.download(\"yolov12\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4228,
     "status": "ok",
     "timestamp": 1751875435886,
     "user": {
      "displayName": "tran dat",
      "userId": "12905468336159583477"
     },
     "user_tz": -420
    },
    "id": "dWaKSw672oLz",
    "outputId": "d298fc27-ca37-4af6-de05-df585777916e"
   },
   "outputs": [],
   "source": [
    "!gdown 1s5KprrhHWkbhjRWCb3OK48I-OriDLR_S"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1694,
     "status": "ok",
     "timestamp": 1751876705823,
     "user": {
      "displayName": "tran dat",
      "userId": "12905468336159583477"
     },
     "user_tz": -420
    },
    "id": "u0c16fCr22kc"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Load m√¥ h√¨nh ResNet ƒë√£ hu·∫•n luy·ªán (v√≠ d·ª•: ResNet18)\n",
    "model = models.resnet50(weights=None)\n",
    "num_classes = 4  # S·ª≠a l·∫°i theo s·ªë class c·ªßa b·∫°n\n",
    "model.fc = torch.nn.Linear(model.fc.in_features, num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "model.load_state_dict(torch.load(\"resnet50_dog_head_emotion_4cls_50e_best_v1.pth\", map_location=device))\n",
    "model.eval()\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2887,
     "status": "ok",
     "timestamp": 1751875448966,
     "user": {
      "displayName": "tran dat",
      "userId": "12905468336159583477"
     },
     "user_tz": -420
    },
    "id": "yPo6Hcvo2_vR"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from pathlib import Path\n",
    "dataset_path = Path(\"/content/19/06-7/test\")\n",
    "input_folder = Path(f\"{dataset_path}/images/\")  # Th∆∞ m·ª•c ·∫£nh g·ªëc\n",
    "labels_folder = Path(f\"{dataset_path}/labels/\")\n",
    "output_folder = dataset_path / \"cropped_images\"\n",
    "output_folder.mkdir(exist_ok=True)\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def crop_and_save(image_path, label_path):\n",
    "    img = cv2.imread(str(image_path))\n",
    "    h, w, _ = img.shape\n",
    "    with open(label_path, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "        for idx, line in enumerate(lines):\n",
    "            cls, x_center, y_center, bw, bh = map(float, line.strip().split())\n",
    "            # Chuy·ªÉn t·ª´ YOLO format sang pixel\n",
    "            x1 = int((x_center - bw / 2) * w)\n",
    "            y1 = int((y_center - bh / 2) * h)\n",
    "            x2 = int((x_center + bw / 2) * w)\n",
    "            y2 = int((y_center + bh / 2) * h)\n",
    "            crop = img[y1:y2, x1:x2]\n",
    "            crop_filename = output_folder / f\"{image_path.stem}_{idx}.jpg\"\n",
    "            cv2.imwrite(str(crop_filename), crop)\n",
    "\n",
    "for img_path in input_folder.glob(\"*.jpg\"):\n",
    "    label_path = labels_folder / (img_path.stem + \".txt\")\n",
    "    if label_path.exists():\n",
    "        crop_and_save(img_path, label_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 470026,
     "status": "ok",
     "timestamp": 1751877205900,
     "user": {
      "displayName": "tran dat",
      "userId": "12905468336159583477"
     },
     "user_tz": -420
    },
    "id": "lE88dkoe3GC9",
    "outputId": "2eb986fd-be8c-4e8c-c32e-7ffb20d3d6dc"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "\n",
    "results = []  # L∆∞u k·∫øt qu·∫£ ƒë·ªÉ d√πng ·ªü Cell 2\n",
    "\n",
    "for cropped_img in tqdm(sorted(output_folder.glob(\"*.jpg\"))):\n",
    "    img = Image.open(cropped_img).convert('RGB')\n",
    "    input_tensor = transform(img).unsqueeze(0)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        output = model(input_tensor)\n",
    "        probabilities = F.softmax(output, dim=1).squeeze().cpu().numpy()\n",
    "        predicted = int(output.argmax(1).item())\n",
    "\n",
    "    # L·∫•y ground-truth\n",
    "    original_name = cropped_img.stem.rsplit(\"_\", 1)[0]\n",
    "    box_index = int(cropped_img.stem.rsplit(\"_\", 1)[1])\n",
    "    gt_label_path = labels_folder / f\"{original_name}.txt\"\n",
    "    with open(gt_label_path, 'r') as f:\n",
    "        gt_line = f.readlines()[box_index]\n",
    "        gt_class = int(gt_line.strip().split()[0])\n",
    "\n",
    "    # L∆∞u k·∫øt qu·∫£ cho Cell 2\n",
    "    results.append({\n",
    "        \"image\": cropped_img.name,\n",
    "        \"gt\": gt_class,\n",
    "        \"pred\": predicted,\n",
    "        \"confidence\": float(probabilities[predicted]),\n",
    "        \"probabilities\": probabilities.tolist()\n",
    "    })\n",
    "\n",
    "    # ====== Visualization t·ª´ng ·∫£nh ======\n",
    "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "    # Hi·ªÉn th·ªã ·∫£nh\n",
    "    ax1.imshow(img)\n",
    "    ax1.axis(\"off\")\n",
    "    ax1.set_title(f\"{'‚úÖ' if predicted == gt_class else '‚ùå'} GT: {gt_class} | Pred: {predicted}\",\n",
    "                  color='green' if predicted == gt_class else 'red')\n",
    "\n",
    "    # Bi·ªÉu ƒë·ªì x√°c su·∫•t\n",
    "    ax2.bar(range(len(probabilities)), probabilities)\n",
    "    ax2.set_xticks(range(len(probabilities)))\n",
    "    ax2.set_title(\"Confidence per class\")\n",
    "    ax2.set_xlabel(\"Class ID\")\n",
    "    ax2.set_ylabel(\"Confidence\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# L∆∞u k·∫øt qu·∫£ d∆∞·ªõi d·∫°ng dataframe ƒë·ªÉ visualize sau\n",
    "df_results = pd.DataFrame(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 959
    },
    "executionInfo": {
     "elapsed": 392,
     "status": "ok",
     "timestamp": 1751876730935,
     "user": {
      "displayName": "tran dat",
      "userId": "12905468336159583477"
     },
     "user_tz": -420
    },
    "id": "aGvyKi5H8uRb",
    "outputId": "3f30f821-8771-47b9-e185-28cb0f2b0801"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score\n",
    "\n",
    "# T√≠nh t·ªïng accuracy\n",
    "acc = accuracy_score(df_results[\"gt\"], df_results[\"pred\"])\n",
    "print(f\"üîç Final Accuracy: {acc:.2%}\")\n",
    "\n",
    "# Bi·ªÉu ƒë·ªì confusion matrix\n",
    "cm = confusion_matrix(df_results[\"gt\"], df_results[\"pred\"])\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Bi·ªÉu ƒë·ªì ƒë√∫ng/sai theo confidence\n",
    "df_results[\"correct\"] = df_results[\"gt\"] == df_results[\"pred\"]\n",
    "\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.hist([df_results[df_results[\"correct\"]==True][\"confidence\"],\n",
    "          df_results[df_results[\"correct\"]==False][\"confidence\"]],\n",
    "         label=[\"Correct\", \"Incorrect\"], bins=10, alpha=0.7)\n",
    "plt.xlabel(\"Prediction Confidence\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.title(\"Confidence Distribution\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 27,
     "status": "ok",
     "timestamp": 1751876724150,
     "user": {
      "displayName": "tran dat",
      "userId": "12905468336159583477"
     },
     "user_tz": -420
    },
    "id": "-JtysrzR30Ak",
    "outputId": "e8f68618-c780-4a70-a530-790d6a83087b"
   },
   "outputs": [],
   "source": [
    "model.fc.out_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "e2jWFtCQ_VIg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
