{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62c914dc",
   "metadata": {},
   "source": [
    "# 3-Class Dog Emotion Recognition - Test & Visualization Notebook\n",
    "\n",
    "## Key Corrections Made:\n",
    "\n",
    "### 1. **Branch Configuration**\n",
    "- Changed from `conf-merge-3cls` to `conf-3cls` (your actual branch)\n",
    "- Repository: `https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git`\n",
    "\n",
    "### 2. **3-Class System**\n",
    "- Classes: `['angry', 'happy', 'relaxed']` (NOT merged sad)\n",
    "- Direct mapping: 0=angry, 1=happy, 2=relaxed\n",
    "- No class merging needed (already 3-class from start)\n",
    "\n",
    "### 3. **Model Loading Fixes**\n",
    "- Proper paths for your model files\n",
    "- Correct architecture parameters\n",
    "- Fixed import statements\n",
    "\n",
    "### 4. **YOLO Handling**\n",
    "- YOLO trained on 3-class directly\n",
    "- No conversion needed if YOLO outputs match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1bafd5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download models\n",
    "!gdown 1kg_O6D1i243veRSK2IDTxSqLFJ8Rie8l -O /content/vit.pt\n",
    "!gdown 1i4Y0IldGspmHXNJv2Ypi0td6Knfg5ep3 -O /content/EfficientNet.pt\n",
    "!gdown 1chEvbJzodR6Ifg9vQ-tDXzeLH0kXlmnD -O /content/densenet.pth\n",
    "!gdown 1Io77ALDwVmZYwUtKDlxJ0m02J73aAUTA -O /content/alex.pth\n",
    "!gdown 1Io77ALDwVmZYwUtKDlxJ0m02J73aAUTA -O /content/resnet101.pth\n",
    "!gdown 1oP4XLqDxJmzhP5ztiD3VVvGr7I-6yT0P -O /content/yolo_11.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33220ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "\n",
    "REPO_URL = \"https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git\"\n",
    "BRANCH_NAME = \"conf-3cls\"  # CORRECTED: Use conf-3cls, not conf-merge-3cls\n",
    "REPO_NAME = \"dog-emotion-recognition-hybrid\"\n",
    "\n",
    "if not os.path.exists(REPO_NAME):\n",
    "    !git clone -b $BRANCH_NAME $REPO_URL\n",
    "    \n",
    "os.chdir(REPO_NAME)\n",
    "if os.getcwd() not in sys.path: \n",
    "    sys.path.insert(0, os.getcwd())\n",
    "\n",
    "# Install dependencies\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n",
    "!pip install opencv-python-headless pillow pandas tqdm gdown albumentations \n",
    "!pip install matplotlib seaborn plotly scikit-learn timm ultralytics roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b92a0aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from ultralytics import YOLO\n",
    "\n",
    "# CORRECTED: 3-class configuration (no merging needed)\n",
    "EMOTION_CLASSES = ['angry', 'happy', 'relaxed']  # Direct 3-class\n",
    "NUM_CLASSES = 3\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "print(f\"‚úÖ Configured for 3-class system: {EMOTION_CLASSES}\")\n",
    "print(f\"üîß Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39d7d614",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from dog_emotion_classification import alexnet, densenet, efficientnet, vit, resnet\n",
    "\n",
    "print(\"‚úÖ Modules imported successfully\")\n",
    "\n",
    "# Define algorithms dictionary with correct parameters\n",
    "ALGORITHMS = {\n",
    "    'AlexNet': {\n",
    "        'module': alexnet,\n",
    "        'load_func': 'load_alexnet_model',\n",
    "        'predict_func': 'predict_emotion_alexnet',\n",
    "        'params': {'input_size': 224, 'num_classes': 3},\n",
    "        'model_path': '/content/alex.pth'\n",
    "    },\n",
    "    'DenseNet121': {\n",
    "        'module': densenet,\n",
    "        'load_func': 'load_densenet_model',\n",
    "        'predict_func': 'predict_emotion_densenet',\n",
    "        'params': {'architecture': 'densenet121', 'input_size': 224, 'num_classes': 3},\n",
    "        'model_path': '/content/densenet.pth'\n",
    "    },\n",
    "    'EfficientNet-B0': {\n",
    "        'module': efficientnet,\n",
    "        'load_func': 'load_efficientnet_model',\n",
    "        'predict_func': 'predict_emotion_efficientnet',\n",
    "        'params': {'architecture': 'efficientnet_b0', 'input_size': 224, 'num_classes': 3},\n",
    "        'model_path': '/content/EfficientNet.pt'\n",
    "    },\n",
    "    'ViT': {\n",
    "        'module': vit,\n",
    "        'load_func': 'load_vit_model',\n",
    "        'predict_func': 'predict_emotion_vit',\n",
    "        'params': {'architecture': 'vit_b_16', 'input_size': 224, 'num_classes': 3},\n",
    "        'model_path': '/content/vit.pt'\n",
    "    },\n",
    "    'ResNet101': {\n",
    "        'module': resnet,\n",
    "        'load_func': 'load_resnet_model',\n",
    "        'predict_func': 'predict_emotion_resnet',\n",
    "        'params': {'architecture': 'resnet101', 'input_size': 224, 'num_classes': 3},\n",
    "        'model_path': '/content/resnet101.pth'\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0439b668",
   "metadata": {},
   "outputs": [],
   "source": [
    "from roboflow import Roboflow\n",
    "from pathlib import Path\n",
    "\n",
    "# Download dataset\n",
    "rf = Roboflow(api_key=\"blm6FIqi33eLS0ewVlKV\")\n",
    "project = rf.workspace(\"2642025\").project(\"19-06\")\n",
    "version = project.version(7)\n",
    "dataset = version.download(\"yolov12\")\n",
    "\n",
    "dataset_path = Path(dataset.location)\n",
    "test_images_path = dataset_path / \"test\" / \"images\"\n",
    "test_labels_path = dataset_path / \"test\" / \"labels\"\n",
    "cropped_images_path = dataset_path / \"cropped_test_images\"\n",
    "cropped_images_path.mkdir(exist_ok=True)\n",
    "\n",
    "def crop_and_save_heads(image_path, label_path, output_dir):\n",
    "    \"\"\"Crop head regions - NO CLASS CONVERSION NEEDED (already 3-class)\"\"\"\n",
    "    img = cv2.imread(str(image_path))\n",
    "    if img is None: \n",
    "        return []\n",
    "    \n",
    "    h, w, _ = img.shape\n",
    "    cropped_files = []\n",
    "    \n",
    "    try:\n",
    "        with open(label_path, 'r') as f:\n",
    "            lines = f.readlines()\n",
    "            \n",
    "        for idx, line in enumerate(lines):\n",
    "            cls, x, y, bw, bh = map(float, line.strip().split())\n",
    "            \n",
    "            # NO CONVERSION - already 3-class (0=angry, 1=happy, 2=relaxed)\n",
    "            cls = int(cls)\n",
    "            \n",
    "            # Crop bounding box\n",
    "            x1 = int((x - bw/2) * w)\n",
    "            y1 = int((y - bh/2) * h)\n",
    "            x2 = int((x + bw/2) * w)\n",
    "            y2 = int((y + bh/2) * h)\n",
    "            \n",
    "            # Ensure within bounds\n",
    "            x1, y1 = max(0, x1), max(0, y1)\n",
    "            x2, y2 = min(w, x2), min(h, y2)\n",
    "            \n",
    "            if x2 > x1 and y2 > y1:\n",
    "                crop = img[y1:y2, x1:x2]\n",
    "                crop_filename = output_dir / f\"{image_path.stem}_{idx}_cls{cls}.jpg\"\n",
    "                cv2.imwrite(str(crop_filename), crop)\n",
    "                \n",
    "                cropped_files.append({\n",
    "                    'filename': crop_filename.name,\n",
    "                    'path': str(crop_filename),\n",
    "                    'original_image': image_path.name,\n",
    "                    'ground_truth': cls,\n",
    "                    'bbox': [x1, y1, x2, y2]\n",
    "                })\n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {image_path}: {e}\")\n",
    "    \n",
    "    return cropped_files\n",
    "\n",
    "# Process all test images\n",
    "all_cropped_data = []\n",
    "for img_path in test_images_path.glob(\"*.jpg\"):\n",
    "    label_path = test_labels_path / (img_path.stem + \".txt\")\n",
    "    if label_path.exists():\n",
    "        all_cropped_data.extend(crop_and_save_heads(img_path, label_path, cropped_images_path))\n",
    "\n",
    "all_data_df = pd.DataFrame(all_cropped_data)\n",
    "\n",
    "# Validate labels are 3-class\n",
    "print(f\"‚úÖ Label distribution (should be 0, 1, 2):\")\n",
    "print(all_data_df['ground_truth'].value_counts().sort_index())\n",
    "\n",
    "# Split into train/test\n",
    "train_df, test_df = train_test_split(\n",
    "    all_data_df, \n",
    "    test_size=0.2, \n",
    "    stratify=all_data_df['ground_truth'], \n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(train_df)}, Test: {len(test_df)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d24f2ec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_yolo_emotion_model():\n",
    "    try:\n",
    "        model = YOLO('/content/yolo_11.pt')\n",
    "        print(\"‚úÖ YOLO model loaded\")\n",
    "        \n",
    "        # Check YOLO classes\n",
    "        if hasattr(model, 'names'):\n",
    "            print(f\"YOLO classes: {model.names}\")\n",
    "        \n",
    "        return model\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load YOLO: {e}\")\n",
    "        return None\n",
    "\n",
    "def predict_emotion_yolo(image_path, model, head_bbox=None, device='cuda'):\n",
    "    try:\n",
    "        results = model(image_path)\n",
    "        if len(results) == 0 or len(results[0].boxes.cls) == 0:\n",
    "            return {'predicted': False}\n",
    "        \n",
    "        cls_id = int(results[0].boxes.cls[0].item())\n",
    "        conf = float(results[0].boxes.conf[0].item())\n",
    "        \n",
    "        # Direct mapping (no conversion needed if YOLO trained on 3-class)\n",
    "        emotion_scores = {e: 0.0 for e in EMOTION_CLASSES}\n",
    "        if 0 <= cls_id < len(EMOTION_CLASSES):\n",
    "            emotion_scores[EMOTION_CLASSES[cls_id]] = conf\n",
    "        else:\n",
    "            return {'predicted': False}\n",
    "            \n",
    "        emotion_scores['predicted'] = True\n",
    "        return emotion_scores\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"YOLO prediction error: {e}\")\n",
    "        return {'predicted': False}\n",
    "\n",
    "# Load YOLO\n",
    "yolo_emotion_model = load_yolo_emotion_model()\n",
    "\n",
    "if yolo_emotion_model:\n",
    "    ALGORITHMS['YOLO_Emotion'] = {\n",
    "        'module': None,\n",
    "        'custom_model': yolo_emotion_model,\n",
    "        'custom_predict': predict_emotion_yolo\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9893038e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_standard_model(module, load_func_name, params, model_path, device='cuda'):\n",
    "    \"\"\"Load model with proper parameters\"\"\"\n",
    "    import os\n",
    "    \n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model not found: {model_path}\")\n",
    "    \n",
    "    load_func = getattr(module, load_func_name)\n",
    "    \n",
    "    # Handle different parameter formats\n",
    "    if 'architecture' in params:\n",
    "        result = load_func(\n",
    "            model_path=model_path,\n",
    "            architecture=params['architecture'],\n",
    "            num_classes=params['num_classes'],\n",
    "            input_size=params.get('input_size', 224),\n",
    "            device=device\n",
    "        )\n",
    "    else:\n",
    "        result = load_func(\n",
    "            model_path=model_path,\n",
    "            num_classes=params['num_classes'],\n",
    "            input_size=params.get('input_size', 224),\n",
    "            device=device\n",
    "        )\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Load all models\n",
    "loaded_models = {}\n",
    "\n",
    "for name, config in ALGORITHMS.items():\n",
    "    try:\n",
    "        if 'custom_model' in config:\n",
    "            # YOLO special case\n",
    "            loaded_models[name] = {\n",
    "                'model': config['custom_model'],\n",
    "                'transform': None,\n",
    "                'config': config\n",
    "            }\n",
    "            print(f\"‚úÖ {name} loaded\")\n",
    "        else:\n",
    "            # Standard models\n",
    "            result = load_standard_model(\n",
    "                config['module'],\n",
    "                config['load_func'],\n",
    "                config['params'],\n",
    "                config['model_path'],\n",
    "                device\n",
    "            )\n",
    "            \n",
    "            if isinstance(result, tuple):\n",
    "                model, transform = result\n",
    "            else:\n",
    "                model = result\n",
    "                transform = transforms.Compose([\n",
    "                    transforms.Resize((224, 224)),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize(mean=[0.485, 0.456, 0.406], \n",
    "                                       std=[0.229, 0.224, 0.225])\n",
    "                ])\n",
    "            \n",
    "            loaded_models[name] = {\n",
    "                'model': model,\n",
    "                'transform': transform,\n",
    "                'config': config\n",
    "            }\n",
    "            print(f\"‚úÖ {name} loaded\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to load {name}: {e}\")\n",
    "\n",
    "print(f\"\\n‚úÖ Loaded {len(loaded_models)}/{len(ALGORITHMS)} models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56583298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_algorithm_on_dataset(algorithm_name, model_data, df, max_samples=9999):\n",
    "    \"\"\"Test algorithm on dataset\"\"\"\n",
    "    model = model_data['model']\n",
    "    transform = model_data['transform']\n",
    "    config = model_data['config']\n",
    "    \n",
    "    results = {\n",
    "        'algorithm': algorithm_name,\n",
    "        'predictions': [],\n",
    "        'ground_truths': [],\n",
    "        'confidences': [],\n",
    "        'success_count': 0,\n",
    "        'error_count': 0\n",
    "    }\n",
    "    \n",
    "    for idx, row in df.head(max_samples).iterrows():\n",
    "        try:\n",
    "            if 'custom_predict' in config:\n",
    "                # YOLO\n",
    "                pred = config['custom_predict'](row['path'], model, device=device)\n",
    "            else:\n",
    "                # Standard models\n",
    "                predict_func = getattr(config['module'], config['predict_func'])\n",
    "                pred = predict_func(\n",
    "                    image_path=row['path'],\n",
    "                    model=model,\n",
    "                    transform=transform,\n",
    "                    device=device,\n",
    "                    emotion_classes=EMOTION_CLASSES\n",
    "                )\n",
    "            \n",
    "            if pred and pred.get('predicted', False):\n",
    "                scores = {k: v for k, v in pred.items() if k != 'predicted'}\n",
    "                pred_emotion = max(scores, key=scores.get)\n",
    "                pred_class = EMOTION_CLASSES.index(pred_emotion)\n",
    "                conf = scores[pred_emotion]\n",
    "                \n",
    "                results['predictions'].append(pred_class)\n",
    "                results['ground_truths'].append(row['ground_truth'])\n",
    "                results['confidences'].append(conf)\n",
    "                results['success_count'] += 1\n",
    "            else:\n",
    "                results['error_count'] += 1\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            results['error_count'] += 1\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Test all models\n",
    "all_results = []\n",
    "for name, model_data in loaded_models.items():\n",
    "    print(f\"Testing {name}...\")\n",
    "    result = test_algorithm_on_dataset(name, model_data, test_df)\n",
    "    if result['success_count'] > 0:\n",
    "        all_results.append(result)\n",
    "        print(f\"‚úÖ {name}: {result['success_count']} predictions\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f3f4157",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble methods (soft voting, hard voting, etc.)\n",
    "def soft_voting(results):\n",
    "    \"\"\"Soft voting ensemble\"\"\"\n",
    "    n_samples = len(results[0]['predictions'])\n",
    "    n_classes = len(EMOTION_CLASSES)\n",
    "    \n",
    "    prob_sum = np.zeros((n_samples, n_classes))\n",
    "    \n",
    "    for r in results:\n",
    "        for i, (pred, conf) in enumerate(zip(r['predictions'], r['confidences'])):\n",
    "            prob_sum[i, pred] += conf\n",
    "    \n",
    "    prob_sum /= len(results)\n",
    "    predictions = np.argmax(prob_sum, axis=1)\n",
    "    confidences = np.max(prob_sum, axis=1)\n",
    "    \n",
    "    return predictions, confidences\n",
    "\n",
    "# Apply ensemble\n",
    "if len(all_results) > 1:\n",
    "    ensemble_preds, ensemble_confs = soft_voting(all_results)\n",
    "    \n",
    "    ensemble_result = {\n",
    "        'algorithm': 'Soft_Voting_Ensemble',\n",
    "        'predictions': ensemble_preds.tolist(),\n",
    "        'ground_truths': all_results[0]['ground_truths'],\n",
    "        'confidences': ensemble_confs.tolist(),\n",
    "        'success_count': len(ensemble_preds),\n",
    "        'error_count': 0\n",
    "    }\n",
    "    \n",
    "    all_results.append(ensemble_result)\n",
    "    print(\"‚úÖ Ensemble methods applied\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a602fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics\n",
    "performance_data = []\n",
    "\n",
    "for result in all_results:\n",
    "    if result['success_count'] > 0:\n",
    "        acc = accuracy_score(result['ground_truths'], result['predictions'])\n",
    "        precision, recall, f1, _ = precision_recall_fscore_support(\n",
    "            result['ground_truths'], \n",
    "            result['predictions'], \n",
    "            average='weighted', \n",
    "            zero_division=0\n",
    "        )\n",
    "        \n",
    "        performance_data.append({\n",
    "            'Algorithm': result['algorithm'],\n",
    "            'Accuracy': acc,\n",
    "            'Precision': precision,\n",
    "            'Recall': recall,\n",
    "            'F1_Score': f1,\n",
    "            'Avg_Confidence': np.mean(result['confidences'])\n",
    "        })\n",
    "\n",
    "performance_df = pd.DataFrame(performance_data)\n",
    "performance_df = performance_df.sort_values('Accuracy', ascending=False)\n",
    "\n",
    "print(\"\\nüèÜ FINAL LEADERBOARD:\")\n",
    "print(performance_df)\n",
    "\n",
    "# Visualization\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(performance_df['Algorithm'], performance_df['Accuracy'], color='skyblue', edgecolor='navy')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.title('Model Performance Comparison (3-Class System)')\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "for i, (algo, acc) in enumerate(zip(performance_df['Algorithm'], performance_df['Accuracy'])):\n",
    "    plt.text(i, acc + 0.005, f'{acc:.3f}', ha='center', va='bottom', fontweight='bold')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Confusion matrix for best model\n",
    "best_result = all_results[0]  # Assuming sorted by accuracy\n",
    "cm = confusion_matrix(best_result['ground_truths'], best_result['predictions'])\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', \n",
    "            xticklabels=EMOTION_CLASSES, \n",
    "            yticklabels=EMOTION_CLASSES)\n",
    "plt.title(f\"Confusion Matrix - {best_result['algorithm']}\")\n",
    "plt.xlabel('Predicted')\n",
    "plt.ylabel('Actual')\n",
    "plt.show()\n",
    "\n",
    "# Save results\n",
    "performance_df.to_csv('3class_performance_results.csv', index=False)\n",
    "print(\"‚úÖ Results saved to 3class_performance_results.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "979c633b",
   "metadata": {},
   "source": [
    "## Key Differences from Your Original:\n",
    "\n",
    "1. **No class merging** - Your system is already 3-class (angry, happy, relaxed)\n",
    "2. **Correct branch** - Using `conf-3cls` instead of `conf-merge-3cls`\n",
    "3. **Simplified YOLO handling** - No conversion needed if YOLO outputs match\n",
    "4. **Cleaner model loading** - Proper parameter passing\n",
    "5. **Removed unnecessary conversion functions**\n",
    "\n",
    "## Notes:\n",
    "\n",
    "- Ensure your YOLO model outputs match the 3-class system\n",
    "- Verify model file paths are correct\n",
    "- The notebook assumes models are trained on the same 3-class configuration\n",
    "- If any model was trained on 4-class, you'll need conversion logic\n",
    "\n",
    "## Expected Output:\n",
    "\n",
    "The notebook will:\n",
    "1. ‚úÖ Download and load all models\n",
    "2. ‚úÖ Process test dataset (no class conversion)\n",
    "3. ‚úÖ Test each model individually\n",
    "4. ‚úÖ Apply ensemble methods\n",
    "5. ‚úÖ Generate performance metrics and visualizations\n",
    "6. ‚úÖ Save results to CSV\n",
    "\n",
    "**Final Result:** Performance comparison across all algorithms with 3-class emotion recognition (angry, happy, relaxed)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
