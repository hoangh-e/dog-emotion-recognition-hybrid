{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# ü§ñ DeiT (Data-efficient Image Transformers) Cross-Validation Training for Dog Emotion Recognition\n",
        "\n",
        "## T·ªïng quan\n",
        "Notebook n√†y hu·∫•n luy·ªán m√¥ h√¨nh **DeiT (Data-efficient Image Transformers)** cho b√†i to√°n nh·∫≠n di·ªán c·∫£m x√∫c ch√≥ v·ªõi:\n",
        "- **Clone repository** t·ª´ GitHub\n",
        "- **Import DeiT (Data-efficient Image Transformers) module** t·ª´ dog_emotion_classification package\n",
        "- **5-fold Cross-Validation** ƒë·ªÉ ƒë√°nh gi√° robust\n",
        "- **50 epochs** hu·∫•n luy·ªán cho m·ªói fold\n",
        "- **T·ª± ƒë·ªông t·∫£i dataset** t·ª´ Google Drive\n",
        "- **Visualization** k·∫øt qu·∫£ training v√† confusion matrix\n",
        "- **T·ª± ƒë·ªông l∆∞u model** v√† t·∫£i v·ªÅ m√°y\n",
        "- **3-class configuration**: angry, happy, relaxed (removed \\'sad\\' class)\n",
        "\n",
        "## C√°ch s·ª≠ d·ª•ng\n",
        "1. **Ch·∫°y \"Run All\"** - T·∫•t c·∫£ s·∫Ω ƒë∆∞·ª£c th·ª±c hi·ªán t·ª± ƒë·ªông\n",
        "2. **Ch·ªù k·∫øt qu·∫£** - Kho·∫£ng 2-3 gi·ªù cho 5 folds (nhanh h∆°n do 3 classes) √ó 50 epochs\n",
        "3. **T·∫£i model** - File .pth s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông download v·ªÅ m√°y\n",
        "4. **Xem k·∫øt qu·∫£** - Accuracy, confusion matrix, v√† training curves\n",
        "\n",
        "## Y√™u c·∫ßu\n",
        "- **GPU**: Khuy·∫øn ngh·ªã s·ª≠ d·ª•ng GPU ƒë·ªÉ training nhanh h∆°n\n",
        "- **RAM**: T·ªëi thi·ªÉu 12GB RAM\n",
        "- **Disk**: Kho·∫£ng 4GB cho dataset v√† model (gi·∫£m do 3 classes)\n",
        "\n",
        "---\n",
        "**L∆∞u √Ω**: DeiT (Data-efficie\n",
        "\n",
        "## 3-Class Configuration\n",
        "- **Emotion Classes**: [\\'angry\\', \\'happy\\', \\'relaxed\\']\n",
        "- **Class Mapping**: 0=angry, 1=happy, 2=relaxed\n",
        "- **Expected Benefits**: Higher accuracy, faster training, better class separationnt Image Transformers) model cho dog emotion classification\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "ü§ñ DeiT (Data-efficient Image Transformers) Cross-Validation Training for Dog Emotion Recognition\n",
        "======================================================================\n",
        "\n",
        "Complete pipeline for training DeiT (Data-efficient Image Transformers) on dog emotion dataset with:\n",
        "- Automatic dataset download and preparation\n",
        "- 5-fold stratified cross-validation\n",
        "- 50 epochs training per fold\n",
        "- Comprehensive visualization and evaluation\n",
        "- Model saving and download\n",
        "\n",
        "Author: Dog Emotion Recognition Team\n",
        "Date: 2024\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import time\n",
        "from datetime import datetime\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "print(\"üöÄ Starting DeiT (Data-efficient Image Transformers) Cross-Validation Training Pipeline\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# =====================================\n",
        "# 1. PACKAGE INSTALLATION\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüì¶ Installing required packages...\")\n",
        "packages = [\n",
        "    'torch>=1.9.0',\n",
        "    'torchvision>=0.10.0', \n",
        "    'scikit-learn>=1.0.0',\n",
        "    'matplotlib>=3.3.0',\n",
        "    'seaborn>=0.11.0',\n",
        "    'gdown>=4.0.0',\n",
        "    'Pillow>=8.0.0',\n",
        "    'numpy>=1.21.0',\n",
        "    'pandas>=1.3.0',\n",
        "    'tqdm>=4.60.0'\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        os.system(f'pip install {package} --quiet')\n",
        "        print(f\"‚úÖ {package}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to install {package}: {e}\")\n",
        "\n",
        "print(\"üì¶ Package installation completed!\")\n",
        "\n",
        "# =====================================\n",
        "# 1.5. CLONE REPOSITORY & IMPORT MODULES\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüì• Cloning repository and importing custom modules...\")\n",
        "\n",
        "# Clone repository t·ª´ GitHub\n",
        "REPO_URL = \"https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git\"\n",
        "if not os.path.exists(\"dog-emotion-recognition-hybrid\"):\n",
        "    print(\"üì• Cloning repository from GitHub...\")\n",
        "    os.system(f\"git clone {REPO_URL}\")\n",
        "\n",
        "# Change to repository directory v√† th√™m v√†o Python path\n",
        "os.chdir(\"dog-emotion-recognition-hybrid\")\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "# Import modules t·ª´ custom package\n",
        "print(\"üì¶ Importing custom modules...\")\n",
        "from dog_emotion_classification.deit import (\n",
        "    load_deit_model,\n",
        "    predict_emotion_deit,\n",
        "    get_deit_transforms,\n",
        "    create_deit_model\n",
        ")\n",
        "\n",
        "# Import utility functions for 3-class conversion\n",
        "from dog_emotion_classification.utils import (\n",
        "    convert_dataframe_4class_to_3class,\n",
        "    get_3class_emotion_classes,\n",
        "    EMOTION_CLASSES_3CLASS\n",
        ")\n",
        "from dog_emotion_classification import EMOTION_CLASSES as PACKAGE_EMOTION_CLASSES\n",
        "\n",
        "print(\"‚úÖ Imported 3-class utility functions\")\n",
        "print(f\"üìä Target emotion classes: {EMOTION_CLASSES_3CLASS}\")\n",
        "print(f\"üì¶ Package emotion classes: {PACKAGE_EMOTION_CLASSES}\")\n",
        "\n",
        "# =====================================\n",
        "# 2. IMPORTS\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüìö Importing libraries...\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "import gdown\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üîß Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "# =====================================\n",
        "# 3. DATASET DOWNLOAD\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüíæ Downloading dataset...\")\n",
        "\n",
        "# Google Drive dataset ID\n",
        "dataset_id = \"1ZAgz5u64i3LDbwMFpBXjzsKt6FrhNGdW\"\n",
        "dataset_zip = \"cropped_dataset_4k_face.zip\"\n",
        "\n",
        "if not os.path.exists(\"cropped_dataset_4k_face\"):\n",
        "    print(\"üì• Downloading dataset from Google Drive...\")\n",
        "    try:\n",
        "        gdown.download(f'https://drive.google.com/uc?id={dataset_id}', dataset_zip, quiet=False)\n",
        "        \n",
        "        print(\"üìÇ Extracting dataset...\")\n",
        "        with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        \n",
        "        os.remove(dataset_zip)\n",
        "        print(\"‚úÖ Dataset downloaded and extracted successfully!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error downloading dataset: {e}\")\n",
        "        print(\"Please check your internet connection and try again.\")\n",
        "        sys.exit(1)\n",
        "else:\n",
        "    print(\"‚úÖ Dataset already exists!\")\n",
        "\n",
        "# =====================================\n",
        "# 4. DATASET CLASS\n",
        "# =====================================\n",
        "\n",
        "class DogEmotionDataset(Dataset):\n",
        "    \"\"\"Dataset class for dog emotion recognition\"\"\"\n",
        "    \n",
        "    def __init__(self, root, labels_csv, transform=None):\n",
        "        self.root = root\n",
        "        df = pd.read_csv(labels_csv)\n",
        "        self.items = df[['filename', 'label']].values\n",
        "        unique_labels = sorted(df['label'].unique())\n",
        "        self.label2index = {name: i for i, name in enumerate(unique_labels)}\n",
        "        self.index2label = {i: name for name, i in self.label2index.items()}\n",
        "        self.transform = transform\n",
        "        print(f\"üìä Dataset: {len(self.items)} samples\")\n",
        "        print(f\"üè∑Ô∏è  Classes: {list(self.label2index.keys())}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.items)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        fn, label_str = self.items[idx]\n",
        "        label_idx = self.label2index[label_str]\n",
        "        img_path = os.path.join(self.root, label_str, fn)\n",
        "        \n",
        "        try:\n",
        "            img = Image.open(img_path).convert('RGB')\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            return img, label_idx\n",
        "        except Exception as e:\n",
        "            # Fallback for corrupted images\n",
        "            img = Image.new('RGB', (224, 224), (0, 0, 0))\n",
        "            if self.transform:\n",
        "                img = self.transform(img)\n",
        "            return img, label_idx\n",
        "\n",
        "# =====================================\n",
        "# 5. DATA PREPARATION\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüîç Preparing dataset...\")\n",
        "\n",
        "# Dataset paths\n",
        "data_root = os.path.join(\"cropped_dataset_4k_face\", \"Dog Emotion\")\n",
        "labels_csv = os.path.join(data_root, \"labels.csv\")\n",
        "\n",
        "print(f\"\\nüìÇ Dataset structure:\")\n",
        "emotions = [d for d in os.listdir(data_root) if os.path.isdir(os.path.join(data_root, d))]\n",
        "print(f\"   Emotion classes: {emotions}\")\n",
        "\n",
        "for emotion in emotions:\n",
        "    emotion_path = os.path.join(data_root, emotion)\n",
        "    if os.path.isdir(emotion_path):\n",
        "        count = len([f for f in os.listdir(emotion_path) if f.lower().endswith(('.jpg', '.jpeg', '.png'))])\n",
        "        print(f\"     {emotion}: {count} images\")\n",
        "\n",
        "print(f\"   Labels CSV: {'‚úÖ' if os.path.exists(labels_csv) else '‚ùå'} {labels_csv}\")\n",
        "\n",
        "# Create initial dataset to check original classes\n",
        "print(\"\\nüìä Loading original dataset...\")\n",
        "original_dataset = DogEmotionDataset(data_root, labels_csv, None)\n",
        "original_classes = list(original_dataset.label2index.keys())\n",
        "print(f\"   Original classes: {original_classes}\")\n",
        "print(f\"   Original samples: {len(original_dataset)}\")\n",
        "\n",
        "# Filter dataset for 3-class configuration\n",
        "print(\"\\nüîß Converting to 3-class configuration...\")\n",
        "\n",
        "# Read labels CSV and filter out 'sad' class\n",
        "labels_df = pd.read_csv(labels_csv)\n",
        "print(f\"   Original DataFrame: {len(labels_df)} samples\")\n",
        "\n",
        "# Convert to 3-class by removing 'sad' samples\n",
        "filtered_df = convert_dataframe_4class_to_3class(labels_df, 'label')\n",
        "\n",
        "# Save filtered labels CSV\n",
        "filtered_labels_csv = os.path.join(data_root, \"labels_3class.csv\")\n",
        "filtered_df.to_csv(filtered_labels_csv, index=False)\n",
        "print(f\"   Saved filtered labels to: {filtered_labels_csv}\")\n",
        "\n",
        "# Create 3-class dataset\n",
        "dataset = DogEmotionDataset(data_root, filtered_labels_csv, None)  # Transform will be set later\n",
        "NUM_CLASSES = len(dataset.label2index)\n",
        "EMOTION_CLASSES = list(dataset.label2index.keys())\n",
        "\n",
        "print(f\"\\n‚úÖ Dataset ready:\")\n",
        "print(f\"   Total samples: {len(dataset)}\")\n",
        "print(f\"   Number of classes: {NUM_CLASSES}\")\n",
        "print(f\"   Emotion classes: {EMOTION_CLASSES}\")\n",
        "\n",
        "# =====================================\n",
        "# 6. TRAINING FUNCTIONS\n",
        "# =====================================\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train model for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(dataloader, desc=\"Training\")\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'Loss': f'{loss.item():.4f}',\n",
        "            'Acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    \"\"\"Evaluate model on validation set\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predicted = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(dataloader, desc=\"Evaluating\")\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            all_predicted.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            \n",
        "            pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "    \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc, all_predicted, all_labels\n",
        "\n",
        "# =====================================\n",
        "# 7. CROSS-VALIDATION TRAINING\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüéØ Starting 5-Fold Cross-Validation Training...\")\n",
        "\n",
        "# Training parameters\n",
        "n_folds = 5\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "input_size = 224\n",
        "\n",
        "# Data transforms\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Prepare labels for stratified split\n",
        "labels = [dataset.label2index[item[1]] for item in dataset.items]\n",
        "labels = np.array(labels)\n",
        "\n",
        "# Initialize cross-validation\n",
        "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Storage for results\n",
        "fold_results = []\n",
        "all_train_losses = []\n",
        "all_val_losses = []\n",
        "all_train_accs = []\n",
        "all_val_accs = []\n",
        "\n",
        "# Training loop\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(np.arange(len(dataset)), labels)):\n",
        "    print(f\"\\n{'='*20} FOLD {fold+1}/{n_folds} {'='*20}\")\n",
        "    \n",
        "    print(f\"Train samples: {len(train_idx)}\")\n",
        "    print(f\"Validation samples: {len(val_idx)}\")\n",
        "    \n",
        "    # Create data samplers\n",
        "    train_sampler = SubsetRandomSampler(train_idx)\n",
        "    val_sampler = SubsetRandomSampler(val_idx)\n",
        "    \n",
        "    # Set transforms\n",
        "    dataset.transform = train_transform\n",
        "    train_loader = DataLoader(dataset, batch_size=batch_size, sampler=train_sampler, num_workers=2)\n",
        "    \n",
        "    dataset.transform = val_transform  \n",
        "    val_loader = DataLoader(dataset, batch_size=batch_size, sampler=val_sampler, num_workers=2)\n",
        "    \n",
        "    # Create model using custom function\n",
        "    model = create_deit_model(num_classes=NUM_CLASSES)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
        "    \n",
        "    # Training tracking\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    best_val_acc = 0.0\n",
        "    \n",
        "    # Training epochs\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 30)\n",
        "        \n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        \n",
        "        # Validate\n",
        "        val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Save metrics\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "        \n",
        "        # Print progress\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "        \n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f'deit_fold_{fold+1}_best.pth')\n",
        "            print(f\"üíæ New best model saved! Accuracy: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    # Store fold results\n",
        "    fold_results.append({\n",
        "        'fold': fold + 1,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accs': train_accs,\n",
        "        'val_accs': val_accs\n",
        "    })\n",
        "    \n",
        "    all_train_losses.append(train_losses)\n",
        "    all_val_losses.append(val_losses)\n",
        "    all_train_accs.append(train_accs)\n",
        "    all_val_accs.append(val_accs)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Fold {fold+1} completed! Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "# =====================================\n",
        "# 8. RESULTS ANALYSIS\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüìä Training Results Analysis\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Calculate statistics\n",
        "fold_accuracies = [result['best_val_acc'] for result in fold_results]\n",
        "mean_acc = np.mean(fold_accuracies)\n",
        "std_acc = np.std(fold_accuracies)\n",
        "\n",
        "print(f\"Cross-Validation Results:\")\n",
        "print(f\"Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"Best Fold: {max(fold_accuracies):.2f}%\")\n",
        "print(f\"Worst Fold: {min(fold_accuracies):.2f}%\")\n",
        "\n",
        "print(\"\\nFold-by-fold results:\")\n",
        "for i, acc in enumerate(fold_accuracies):\n",
        "    print(f\"Fold {i+1}: {acc:.2f}%\")\n",
        "\n",
        "# =====================================\n",
        "# 9. VISUALIZATION\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüìà Creating visualizations...\")\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create comprehensive visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('DeiT (Data-efficient Image Transformers) Cross-Validation Training Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Training and Validation Loss\n",
        "ax1 = axes[0, 0]\n",
        "for fold in range(n_folds):\n",
        "    epochs_range = range(1, epochs + 1)\n",
        "    ax1.plot(epochs_range, all_train_losses[fold], alpha=0.7, label=f'Fold {fold+1} Train')\n",
        "    ax1.plot(epochs_range, all_val_losses[fold], alpha=0.7, linestyle='--', label=f'Fold {fold+1} Val')\n",
        "\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Training and Validation Accuracy\n",
        "ax2 = axes[0, 1]\n",
        "for fold in range(n_folds):\n",
        "    epochs_range = range(1, epochs + 1)\n",
        "    ax2.plot(epochs_range, all_train_accs[fold], alpha=0.7, label=f'Fold {fold+1} Train')\n",
        "    ax2.plot(epochs_range, all_val_accs[fold], alpha=0.7, linestyle='--', label=f'Fold {fold+1} Val')\n",
        "\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Cross-Validation Accuracy Distribution\n",
        "ax3 = axes[1, 0]\n",
        "ax3.bar(range(1, n_folds + 1), fold_accuracies, alpha=0.7, color='skyblue', edgecolor='navy')\n",
        "ax3.axhline(y=mean_acc, color='red', linestyle='--', label=f'Mean: {mean_acc:.2f}%')\n",
        "ax3.set_title('Cross-Validation Accuracy by Fold')\n",
        "ax3.set_xlabel('Fold')\n",
        "ax3.set_ylabel('Accuracy (%)')\n",
        "ax3.set_xticks(range(1, n_folds + 1))\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Add accuracy values on bars\n",
        "for i, acc in enumerate(fold_accuracies):\n",
        "    ax3.text(i + 1, acc + 0.5, f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 4. Model Performance Summary\n",
        "ax4 = axes[1, 1]\n",
        "ax4.axis('off')\n",
        "\n",
        "# Create summary text\n",
        "summary_text = f\"\"\"\n",
        "DEIT (DATA-EFFICIENT IMAGE TRANSFORMERS) TRAINING SUMMARY\n",
        "{'='*len(display_name)}\n",
        "\n",
        "Dataset: Dog Emotion Recognition (3-Class)\n",
        "Architecture: DeiT (Data-efficient Image Transformers)\n",
        "Input Size: 224√ó224\n",
        "Classes: {NUM_CLASSES}\n",
        "\n",
        "Training Configuration:\n",
        "‚Ä¢ Folds: {n_folds}\n",
        "‚Ä¢ Epochs per fold: {epochs}\n",
        "‚Ä¢ Batch size: {batch_size}\n",
        "‚Ä¢ Learning rate: {learning_rate}\n",
        "‚Ä¢ Optimizer: Adam\n",
        "\n",
        "Results:\n",
        "‚Ä¢ Mean CV Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\n",
        "‚Ä¢ Best Fold Accuracy: {max(fold_accuracies):.2f}%\n",
        "‚Ä¢ Total Training Time: {datetime.now().strftime('%H:%M:%S')}\n",
        "\n",
        "Classes: {', '.join(EMOTION_CLASSES)}\n",
        "\"\"\"\n",
        "\n",
        "ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes, fontsize=11,\n",
        "         verticalalignment='top', fontfamily='monospace',\n",
        "         bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# =====================================\n",
        "# 10. SAVE RESULTS\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüíæ Saving results...\")\n",
        "\n",
        "# Save training history\n",
        "results_data = {\n",
        "    'fold_results': fold_results,\n",
        "    'mean_accuracy': mean_acc,\n",
        "    'std_accuracy': std_acc,\n",
        "    'emotion_classes': EMOTION_CLASSES,\n",
        "    'training_config': {\n",
        "        'n_folds': n_folds,\n",
        "        'epochs': epochs,\n",
        "        'batch_size': batch_size,\n",
        "        'learning_rate': learning_rate,\n",
        "        'input_size': input_size\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('deit_training_results.json', 'w') as f:\n",
        "    json.dump(results_data, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Results saved to deit_training_results.json\")\n",
        "\n",
        "# =====================================\n",
        "# 11. MODEL DOWNLOAD\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüì• Preparing models for download...\")\n",
        "\n",
        "# Find best model\n",
        "best_fold = fold_accuracies.index(max(fold_accuracies)) + 1\n",
        "best_model_file = f'deit_fold_{best_fold}_best.pth'\n",
        "\n",
        "print(f\"\\nüèÜ Best model: {best_model_file} (Accuracy: {max(fold_accuracies):.2f}%)\")\n",
        "\n",
        "# Download best model (in Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(f\"\\nüì• Downloading best model: {best_model_file}\")\n",
        "    files.download(best_model_file)\n",
        "    files.download('deit_training_results.json')\n",
        "    print(\"‚úÖ Files downloaded successfully!\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Not running in Colab - files saved locally\")\n",
        "\n",
        "print(\"\\nüéâ DeiT (Data-efficient Image Transformers) Cross-Validation Training Completed!\")\n",
        "print(\"=\" * 60)\n",
        "print(f\"‚úÖ Final Results:\")\n",
        "print(f\"   Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"   Best Model: {best_model_file} ({max(fold_accuracies):.2f}%)\")\n",
        "print(f\"   Classes: {EMOTION_CLASSES}\")\n",
        "print(\"=\" * 60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}