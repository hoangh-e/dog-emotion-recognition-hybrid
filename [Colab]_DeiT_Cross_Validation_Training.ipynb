{
  "cells": [
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# DeiT (Data-efficient Image Transformer) Cross-Validation Training\n",
        "\n",
        "## Hu·∫•n luy·ªán DeiT cho nh·∫≠n di·ªán c·∫£m x√∫c ch√≥ v·ªõi 5-fold cross-validation\n",
        "\n",
        "**ƒê·∫∑c ƒëi·ªÉm c·ªßa DeiT:**\n",
        "- Clone repository t·ª´ GitHub\n",
        "- Import DeiT module t·ª´ dog_emotion_classification package\n",
        "- Data-efficient Image Transformer architecture\n",
        "- Distillation token for knowledge transfer\n",
        "- Optimized for limited training data\n",
        "- Excellent performance on vision tasks\n",
        "\n",
        "**C·∫•u h√¨nh hu·∫•n luy·ªán:**\n",
        "- 5-fold Stratified Cross-Validation\n",
        "- 50 epochs per fold\n",
        "- Batch size: 16\n",
        "- Learning rate: 1e-4\n",
        "- Optimizer: Adam\n",
        "- Pretrained: ImageNet weights\n",
        "\n",
        "**Ch·∫°y \"Run All\" ƒë·ªÉ b·∫Øt ƒë·∫ßu hu·∫•n luy·ªán ho√†n to√†n t·ª± ƒë·ªông!**\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "DeiT Cross-Validation Training Pipeline\n",
        "Hu·∫•n luy·ªán DeiT cho nh·∫≠n di·ªán c·∫£m x√∫c ch√≥ v·ªõi 5-fold cross-validation\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "print(\"üöÄ B·∫Øt ƒë·∫ßu pipeline hu·∫•n luy·ªán DeiT Cross-Validation...\")\n",
        "print(\"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 1: CLONE REPOSITORY\n",
        "# ==========================================\n",
        "print(\"üîÑ Clone repository t·ª´ GitHub...\")\n",
        "REPO_URL = \"https://github.com/hoangh-e/dog-emotion-recognition-hybrid.git\"\n",
        "REPO_NAME = \"dog-emotion-recognition-hybrid\"\n",
        "\n",
        "if not os.path.exists(REPO_NAME):\n",
        "    os.system(f\"git clone {REPO_URL}\")\n",
        "    print(\"‚úÖ Repository cloned successfully\")\n",
        "else:\n",
        "    print(\"‚úÖ Repository already exists\")\n",
        "\n",
        "os.chdir(REPO_NAME)\n",
        "sys.path.insert(0, os.getcwd())\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 2: C√ÄI ƒê·∫∂T PACKAGES\n",
        "# ==========================================\n",
        "print(\"üì¶ C√†i ƒë·∫∑t c√°c packages c·∫ßn thi·∫øt...\")\n",
        "packages_to_install = [\n",
        "    \"torch>=1.9.0\",\n",
        "    \"torchvision>=0.10.0\", \n",
        "    \"timm>=0.6.0\",\n",
        "    \"gdown\",\n",
        "    \"scikit-learn\",\n",
        "    \"matplotlib\",\n",
        "    \"seaborn\",\n",
        "    \"Pillow\",\n",
        "    \"numpy\",\n",
        "    \"pandas\",\n",
        "    \"tqdm\"\n",
        "]\n",
        "\n",
        "for package in packages_to_install:\n",
        "    try:\n",
        "        if package.startswith(\"torch\"):\n",
        "            import torch\n",
        "            print(f\"‚úÖ {package} ƒë√£ c√≥ s·∫µn\")\n",
        "        elif package.startswith(\"torchvision\"):\n",
        "            import torchvision\n",
        "            print(f\"‚úÖ {package} ƒë√£ c√≥ s·∫µn\")\n",
        "        elif package.startswith(\"timm\"):\n",
        "            import timm\n",
        "            print(f\"‚úÖ {package} ƒë√£ c√≥ s·∫µn\")\n",
        "        elif package.startswith(\"gdown\"):\n",
        "            import gdown\n",
        "            print(f\"‚úÖ {package} ƒë√£ c√≥ s·∫µn\")\n",
        "        elif package.startswith(\"scikit-learn\"):\n",
        "            import sklearn\n",
        "            print(f\"‚úÖ {package} ƒë√£ c√≥ s·∫µn\")\n",
        "        elif package.startswith(\"matplotlib\"):\n",
        "            import matplotlib\n",
        "            print(f\"‚úÖ {package} ƒë√£ c√≥ s·∫µn\")\n",
        "        elif package.startswith(\"seaborn\"):\n",
        "            import seaborn\n",
        "            print(f\"‚úÖ {package} ƒë√£ c√≥ s·∫µn\")\n",
        "        elif package.startswith(\"Pillow\"):\n",
        "            import PIL\n",
        "            print(f\"‚úÖ {package} ƒë√£ c√≥ s·∫µn\")\n",
        "        elif package.startswith(\"numpy\"):\n",
        "            import numpy\n",
        "            print(f\"‚úÖ {package} ƒë√£ c√≥ s·∫µn\")\n",
        "        elif package.startswith(\"pandas\"):\n",
        "            import pandas\n",
        "            print(f\"‚úÖ {package} ƒë√£ c√≥ s·∫µn\")\n",
        "        elif package.startswith(\"tqdm\"):\n",
        "            import tqdm\n",
        "            print(f\"‚úÖ {package} ƒë√£ c√≥ s·∫µn\")\n",
        "    except ImportError:\n",
        "        print(f\"‚¨áÔ∏è ƒêang c√†i ƒë·∫∑t {package}...\")\n",
        "        os.system(f\"pip install {package}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 3: IMPORT LIBRARIES\n",
        "# ==========================================\n",
        "print(\"üìö Import th∆∞ vi·ªán...\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "import timm\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "import gdown\n",
        "import zipfile\n",
        "import json\n",
        "from tqdm import tqdm\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Import DeiT from our custom module\n",
        "from dog_emotion_classification.deit import (\n",
        "    load_deit_model,\n",
        "    predict_emotion_deit,\n",
        "    get_deit_transforms,\n",
        "    create_simple_deit_model\n",
        ")\n",
        "\n",
        "# Set device\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üñ•Ô∏è S·ª≠ d·ª•ng device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"   GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"   CUDA Version: {torch.version.cuda}\")\n",
        "    print(f\"   Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 4: T·∫¢I DATASET\n",
        "# ==========================================\n",
        "print(\"üì• T·∫£i dataset t·ª´ Google Drive...\")\n",
        "\n",
        "# Dataset ID v√† th√¥ng tin\n",
        "dataset_id = \"1ZAgz5u64i3LDbwMFpBXjzsKt6FrhNGdW\"\n",
        "dataset_filename = \"dog_emotion_dataset.zip\"\n",
        "\n",
        "# T·∫£i dataset\n",
        "if not os.path.exists(dataset_filename):\n",
        "    print(f\"‚¨áÔ∏è ƒêang t·∫£i {dataset_filename}...\")\n",
        "    gdown.download(f\"https://drive.google.com/uc?id={dataset_id}\", dataset_filename, quiet=False)\n",
        "    print(\"‚úÖ T·∫£i dataset th√†nh c√¥ng!\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset ƒë√£ t·ªìn t·∫°i!\")\n",
        "\n",
        "# Gi·∫£i n√©n dataset\n",
        "print(\"üìÇ Gi·∫£i n√©n dataset...\")\n",
        "if not os.path.exists(\"dataset\"):\n",
        "    with zipfile.ZipFile(dataset_filename, 'r') as zip_ref:\n",
        "        zip_ref.extractall(\".\")\n",
        "    print(\"‚úÖ Gi·∫£i n√©n th√†nh c√¥ng!\")\n",
        "else:\n",
        "    print(\"‚úÖ Dataset ƒë√£ ƒë∆∞·ª£c gi·∫£i n√©n!\")\n",
        "\n",
        "# Ki·ªÉm tra c·∫•u tr√∫c dataset\n",
        "dataset_path = \"dataset\"\n",
        "if os.path.exists(dataset_path):\n",
        "    classes = sorted(os.listdir(dataset_path))\n",
        "    print(f\"üìä T√¨m th·∫•y {len(classes)} classes: {classes}\")\n",
        "    \n",
        "    total_images = 0\n",
        "    for class_name in classes:\n",
        "        class_path = os.path.join(dataset_path, class_name)\n",
        "        if os.path.isdir(class_path):\n",
        "            class_images = len([f for f in os.listdir(class_path) if f.lower().endswith(('.png', '.jpg', '.jpeg'))])\n",
        "            total_images += class_images\n",
        "            print(f\"   {class_name}: {class_images} ·∫£nh\")\n",
        "    \n",
        "    print(f\"üìà T·ªïng s·ªë ·∫£nh: {total_images}\")\n",
        "else:\n",
        "    print(\"‚ùå Kh√¥ng t√¨m th·∫•y th∆∞ m·ª•c dataset!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 5: CHU·∫®N B·ªä D·ªÆ LI·ªÜU\n",
        "# ==========================================\n",
        "print(\"üîß Chu·∫©n b·ªã d·ªØ li·ªáu cho cross-validation...\")\n",
        "\n",
        "class DogEmotionDataset(Dataset):\n",
        "    \"\"\"Dataset t√πy ch·ªânh cho dog emotion recognition\"\"\"\n",
        "    \n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            image_path = self.image_paths[idx]\n",
        "            image = Image.open(image_path).convert('RGB')\n",
        "            label = self.labels[idx]\n",
        "            \n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            return image, label\n",
        "        except Exception as e:\n",
        "            print(f\"‚ö†Ô∏è L·ªói khi t·∫£i ·∫£nh {self.image_paths[idx]}: {e}\")\n",
        "            # Tr·∫£ v·ªÅ ·∫£nh tr·∫Øng thay th·∫ø\n",
        "            if self.transform:\n",
        "                dummy_image = self.transform(Image.new('RGB', (224, 224), color='white'))\n",
        "            else:\n",
        "                dummy_image = Image.new('RGB', (224, 224), color='white')\n",
        "            return dummy_image, self.labels[idx]\n",
        "\n",
        "# Thu th·∫≠p t·∫•t c·∫£ ƒë∆∞·ªùng d·∫´n ·∫£nh v√† nh√£n\n",
        "all_image_paths = []\n",
        "all_labels = []\n",
        "class_to_idx = {}\n",
        "\n",
        "for idx, class_name in enumerate(sorted(classes)):\n",
        "    class_to_idx[class_name] = idx\n",
        "    class_path = os.path.join(dataset_path, class_name)\n",
        "    \n",
        "    if os.path.isdir(class_path):\n",
        "        for image_name in os.listdir(class_path):\n",
        "            if image_name.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
        "                image_path = os.path.join(class_path, image_name)\n",
        "                all_image_paths.append(image_path)\n",
        "                all_labels.append(idx)\n",
        "\n",
        "print(f\"üìä T·ªïng s·ªë m·∫´u: {len(all_image_paths)}\")\n",
        "print(f\"üè∑Ô∏è Mapping classes: {class_to_idx}\")\n",
        "\n",
        "# Chuy·ªÉn ƒë·ªïi sang numpy arrays\n",
        "all_image_paths = np.array(all_image_paths)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 5: THI·∫æT L·∫¨P CROSS-VALIDATION\n",
        "# ==========================================\n",
        "print(\"üîÑ Thi·∫øt l·∫≠p 5-fold Stratified Cross-Validation...\")\n",
        "\n",
        "# Stratified K-Fold ƒë·ªÉ ƒë·∫£m b·∫£o ph√¢n b·ªë class ƒë·ªÅu\n",
        "n_folds = 5\n",
        "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Data transforms using our custom DeiT module\n",
        "train_transform = get_deit_transforms(input_size=224, is_training=True)\n",
        "val_transform = get_deit_transforms(input_size=224, is_training=False)\n",
        "\n",
        "print(\"‚úÖ Thi·∫øt l·∫≠p transforms th√†nh c√¥ng!\")\n",
        "print(f\"üìä S·ªë folds: {n_folds}\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 6: ƒê·ªäNH NGHƒ®A MODEL V√Ä TRAINING FUNCTIONS\n",
        "# ==========================================\n",
        "print(\"üèóÔ∏è ƒê·ªãnh nghƒ©a DeiT model v√† training functions...\")\n",
        "\n",
        "def create_deit_model(num_classes=4, pretrained=True):\n",
        "    \"\"\"T·∫°o DeiT model v·ªõi pretrained weights\"\"\"\n",
        "    try:\n",
        "        # Th·ª≠ t·∫£i DeiT t·ª´ timm\n",
        "        model = timm.create_model('deit_small_patch16_224', pretrained=pretrained, num_classes=num_classes)\n",
        "        print(f\"‚úÖ T·∫°o DeiT model th√†nh c√¥ng v·ªõi {num_classes} classes\")\n",
        "        return model\n",
        "    except Exception as e:\n",
        "        print(f\"‚ö†Ô∏è Kh√¥ng th·ªÉ t·∫£i DeiT t·ª´ timm: {e}\")\n",
        "        print(\"üîÑ S·ª≠ d·ª•ng Vision Transformer thay th·∫ø...\")\n",
        "        \n",
        "        # Fallback to Vision Transformer\n",
        "        model = timm.create_model('vit_small_patch16_224', pretrained=pretrained, num_classes=num_classes)\n",
        "        print(f\"‚úÖ T·∫°o ViT model thay th·∫ø th√†nh c√¥ng\")\n",
        "        return model\n",
        "\n",
        "def train_epoch(model, train_loader, criterion, optimizer, device, epoch, total_epochs):\n",
        "    \"\"\"Hu·∫•n luy·ªán m·ªôt epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{total_epochs} [Train]')\n",
        "    \n",
        "    for batch_idx, (data, target) in enumerate(pbar):\n",
        "        data, target = data.to(device), target.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        output = model(data)\n",
        "        loss = criterion(output, target)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(output.data, 1)\n",
        "        total += target.size(0)\n",
        "        correct += (predicted == target).sum().item()\n",
        "        \n",
        "        # C·∫≠p nh·∫≠t progress bar\n",
        "        pbar.set_postfix({\n",
        "            'Loss': f'{running_loss/(batch_idx+1):.4f}',\n",
        "            'Acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    epoch_loss = running_loss / len(train_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def validate_epoch(model, val_loader, criterion, device):\n",
        "    \"\"\"ƒê√°nh gi√° m·ªôt epoch\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(val_loader, desc='Validation')\n",
        "        for data, target in pbar:\n",
        "            data, target = data.to(device), target.to(device)\n",
        "            output = model(data)\n",
        "            loss = criterion(output, target)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(output.data, 1)\n",
        "            total += target.size(0)\n",
        "            correct += (predicted == target).sum().item()\n",
        "            \n",
        "            pbar.set_postfix({\n",
        "                'Loss': f'{running_loss/(pbar.n+1):.4f}',\n",
        "                'Acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "    \n",
        "    epoch_loss = running_loss / len(val_loader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "print(\"‚úÖ ƒê·ªãnh nghƒ©a functions th√†nh c√¥ng!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 7: CROSS-VALIDATION TRAINING\n",
        "# ==========================================\n",
        "print(\"üöÄ B·∫Øt ƒë·∫ßu 5-fold Cross-Validation Training...\")\n",
        "\n",
        "# Hyperparameters\n",
        "num_epochs = 50\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "num_classes = len(classes)\n",
        "\n",
        "# L∆∞u tr·ªØ k·∫øt qu·∫£\n",
        "fold_results = []\n",
        "all_train_losses = []\n",
        "all_val_losses = []\n",
        "all_train_accs = []\n",
        "all_val_accs = []\n",
        "\n",
        "# B·∫Øt ƒë·∫ßu cross-validation\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(all_image_paths, all_labels)):\n",
        "    print(f\"\\n{'='*20} FOLD {fold + 1}/{n_folds} {'='*20}\")\n",
        "    \n",
        "    # Chia d·ªØ li·ªáu\n",
        "    train_paths = all_image_paths[train_idx]\n",
        "    train_labels = all_labels[train_idx]\n",
        "    val_paths = all_image_paths[val_idx]\n",
        "    val_labels = all_labels[val_idx]\n",
        "    \n",
        "    print(f\"üìä Train: {len(train_paths)} samples, Val: {len(val_paths)} samples\")\n",
        "    \n",
        "    # T·∫°o datasets\n",
        "    train_dataset = DogEmotionDataset(train_paths, train_labels, train_transform)\n",
        "    val_dataset = DogEmotionDataset(val_paths, val_labels, val_transform)\n",
        "    \n",
        "    # T·∫°o data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    \n",
        "    # T·∫°o DeiT model using our custom module\n",
        "    model = create_simple_deit_model(num_classes=num_classes, device=device)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Loss function v√† optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
        "    \n",
        "    # Training loop\n",
        "    fold_train_losses = []\n",
        "    fold_val_losses = []\n",
        "    fold_train_accs = []\n",
        "    fold_val_accs = []\n",
        "    \n",
        "    best_val_acc = 0.0\n",
        "    \n",
        "    print(f\"üèãÔ∏è B·∫Øt ƒë·∫ßu training fold {fold + 1}...\")\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        # Training\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device, epoch, num_epochs)\n",
        "        \n",
        "        # Validation\n",
        "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Scheduler step\n",
        "        scheduler.step()\n",
        "        \n",
        "        # L∆∞u metrics\n",
        "        fold_train_losses.append(train_loss)\n",
        "        fold_val_losses.append(val_loss)\n",
        "        fold_train_accs.append(train_acc)\n",
        "        fold_val_accs.append(val_acc)\n",
        "        \n",
        "        # In k·∫øt qu·∫£\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
        "        print(f\"  Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"  Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "        print(f\"  LR: {scheduler.get_last_lr()[0]:.6f}\")\n",
        "        \n",
        "        # L∆∞u best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f'best_deit_fold_{fold+1}.pth')\n",
        "    \n",
        "    # L∆∞u k·∫øt qu·∫£ fold\n",
        "    fold_results.append({\n",
        "        'fold': fold + 1,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'final_train_acc': fold_train_accs[-1],\n",
        "        'final_val_acc': fold_val_accs[-1],\n",
        "        'train_losses': fold_train_losses,\n",
        "        'val_losses': fold_val_losses,\n",
        "        'train_accs': fold_train_accs,\n",
        "        'val_accs': fold_val_accs\n",
        "    })\n",
        "    \n",
        "    all_train_losses.append(fold_train_losses)\n",
        "    all_val_losses.append(fold_val_losses)\n",
        "    all_train_accs.append(fold_train_accs)\n",
        "    all_val_accs.append(fold_val_accs)\n",
        "    \n",
        "    print(f\"‚úÖ Fold {fold + 1} ho√†n th√†nh! Best Val Acc: {best_val_acc:.2f}%\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 8: PH√ÇN T√çCH K·∫æT QU·∫¢\n",
        "# ==========================================\n",
        "print(\"üìä Ph√¢n t√≠ch k·∫øt qu·∫£ Cross-Validation...\")\n",
        "\n",
        "# T√≠nh to√°n statistics\n",
        "val_accs = [result['best_val_acc'] for result in fold_results]\n",
        "mean_val_acc = np.mean(val_accs)\n",
        "std_val_acc = np.std(val_accs)\n",
        "\n",
        "print(f\"\\nüéØ K·∫æT QU·∫¢ CROSS-VALIDATION:\")\n",
        "print(f\"Mean Validation Accuracy: {mean_val_acc:.2f}% ¬± {std_val_acc:.2f}%\")\n",
        "print(f\"Min Validation Accuracy: {min(val_accs):.2f}%\")\n",
        "print(f\"Max Validation Accuracy: {max(val_accs):.2f}%\")\n",
        "\n",
        "print(f\"\\nüìà Chi ti·∫øt t·ª´ng fold:\")\n",
        "for i, result in enumerate(fold_results):\n",
        "    print(f\"Fold {i+1}: {result['best_val_acc']:.2f}%\")\n",
        "\n",
        "# T·∫°o DataFrame k·∫øt qu·∫£\n",
        "results_df = pd.DataFrame({\n",
        "    'Fold': [f\"Fold {i+1}\" for i in range(n_folds)],\n",
        "    'Best_Val_Acc': val_accs,\n",
        "    'Final_Train_Acc': [result['final_train_acc'] for result in fold_results],\n",
        "    'Final_Val_Acc': [result['final_val_acc'] for result in fold_results]\n",
        "})\n",
        "\n",
        "print(f\"\\nüìã B·∫£ng k·∫øt qu·∫£:\")\n",
        "print(results_df.to_string(index=False))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 9: VISUALIZATION\n",
        "# ==========================================\n",
        "print(\"üìà T·∫°o bi·ªÉu ƒë·ªì k·∫øt qu·∫£...\")\n",
        "\n",
        "# Thi·∫øt l·∫≠p style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# T·∫°o figure v·ªõi nhi·ªÅu subplots\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('DeiT Cross-Validation Training Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Training curves cho t·∫•t c·∫£ folds\n",
        "ax1 = axes[0, 0]\n",
        "for i, fold_result in enumerate(fold_results):\n",
        "    epochs = range(1, len(fold_result['train_losses']) + 1)\n",
        "    ax1.plot(epochs, fold_result['train_losses'], alpha=0.7, label=f'Fold {i+1} Train')\n",
        "    ax1.plot(epochs, fold_result['val_losses'], alpha=0.7, linestyle='--', label=f'Fold {i+1} Val')\n",
        "\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Accuracy curves\n",
        "ax2 = axes[0, 1]\n",
        "for i, fold_result in enumerate(fold_results):\n",
        "    epochs = range(1, len(fold_result['train_accs']) + 1)\n",
        "    ax2.plot(epochs, fold_result['train_accs'], alpha=0.7, label=f'Fold {i+1} Train')\n",
        "    ax2.plot(epochs, fold_result['val_accs'], alpha=0.7, linestyle='--', label=f'Fold {i+1} Val')\n",
        "\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Box plot c·ªßa validation accuracies\n",
        "ax3 = axes[1, 0]\n",
        "ax3.boxplot(val_accs, labels=['DeiT'])\n",
        "ax3.set_title('Validation Accuracy Distribution')\n",
        "ax3.set_ylabel('Accuracy (%)')\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Th√™m statistics\n",
        "ax3.text(0.02, 0.98, f'Mean: {mean_val_acc:.2f}%\\nStd: {std_val_acc:.2f}%', \n",
        "         transform=ax3.transAxes, verticalalignment='top',\n",
        "         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.8))\n",
        "\n",
        "# 4. Bar plot comparison\n",
        "ax4 = axes[1, 1]\n",
        "x_pos = np.arange(len(fold_results))\n",
        "bars = ax4.bar(x_pos, val_accs, alpha=0.7, color='skyblue', edgecolor='navy')\n",
        "ax4.set_title('Best Validation Accuracy by Fold')\n",
        "ax4.set_xlabel('Fold')\n",
        "ax4.set_ylabel('Accuracy (%)')\n",
        "ax4.set_xticks(x_pos)\n",
        "ax4.set_xticklabels([f'Fold {i+1}' for i in range(n_folds)])\n",
        "ax4.grid(True, alpha=0.3)\n",
        "\n",
        "# Th√™m gi√° tr·ªã tr√™n bars\n",
        "for bar, acc in zip(bars, val_accs):\n",
        "    height = bar.get_height()\n",
        "    ax4.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
        "             f'{acc:.1f}%', ha='center', va='bottom')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"‚úÖ Bi·ªÉu ƒë·ªì ƒë√£ ƒë∆∞·ª£c t·∫°o!\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 10: L∆ØU K·∫æT QU·∫¢\n",
        "# ==========================================\n",
        "print(\"üíæ L∆∞u k·∫øt qu·∫£ v√† models...\")\n",
        "\n",
        "# L∆∞u k·∫øt qu·∫£ v√†o file\n",
        "results_summary = {\n",
        "    'model_name': 'DeiT',\n",
        "    'cross_validation_folds': n_folds,\n",
        "    'epochs_per_fold': num_epochs,\n",
        "    'batch_size': batch_size,\n",
        "    'learning_rate': learning_rate,\n",
        "    'mean_val_accuracy': float(mean_val_acc),\n",
        "    'std_val_accuracy': float(std_val_acc),\n",
        "    'min_val_accuracy': float(min(val_accs)),\n",
        "    'max_val_accuracy': float(max(val_accs)),\n",
        "    'fold_results': fold_results,\n",
        "    'class_mapping': class_to_idx\n",
        "}\n",
        "\n",
        "# L∆∞u JSON\n",
        "with open('deit_cv_results.json', 'w') as f:\n",
        "    json.dump(results_summary, f, indent=2)\n",
        "\n",
        "# L∆∞u CSV\n",
        "results_df.to_csv('deit_cv_results.csv', index=False)\n",
        "\n",
        "print(\"‚úÖ ƒê√£ l∆∞u k·∫øt qu·∫£ v√†o:\")\n",
        "print(\"   - deit_cv_results.json\")\n",
        "print(\"   - deit_cv_results.csv\")\n",
        "print(\"   - best_deit_fold_*.pth (model weights)\")\n",
        "\n",
        "# T·∫°o file summary\n",
        "summary_text = f\"\"\"\n",
        "DeiT Cross-Validation Training Summary\n",
        "=====================================\n",
        "\n",
        "Model: DeiT (Data-efficient Image Transformer)\n",
        "Dataset: Dog Emotion Recognition\n",
        "Classes: {list(class_to_idx.keys())}\n",
        "Total Images: {len(all_image_paths)}\n",
        "\n",
        "Training Configuration:\n",
        "- Cross-validation: {n_folds}-fold Stratified\n",
        "- Epochs per fold: {num_epochs}\n",
        "- Batch size: {batch_size}\n",
        "- Learning rate: {learning_rate}\n",
        "- Optimizer: Adam\n",
        "- Scheduler: StepLR (step_size=15, gamma=0.1)\n",
        "\n",
        "Results:\n",
        "- Mean Validation Accuracy: {mean_val_acc:.2f}% ¬± {std_val_acc:.2f}%\n",
        "- Best Fold Accuracy: {max(val_accs):.2f}%\n",
        "- Worst Fold Accuracy: {min(val_accs):.2f}%\n",
        "\n",
        "Fold Details:\n",
        "{chr(10).join([f\"Fold {i+1}: {acc:.2f}%\" for i, acc in enumerate(val_accs)])}\n",
        "\n",
        "Files Generated:\n",
        "- deit_cv_results.json: Detailed results\n",
        "- deit_cv_results.csv: Results table\n",
        "- best_deit_fold_*.pth: Best model weights for each fold\n",
        "\"\"\"\n",
        "\n",
        "with open('deit_training_summary.txt', 'w') as f:\n",
        "    f.write(summary_text)\n",
        "\n",
        "print(\"   - deit_training_summary.txt\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 11: DOWNLOAD FILES (CHO COLAB)\n",
        "# ==========================================\n",
        "print(\"üì• Chu·∫©n b·ªã download files...\")\n",
        "\n",
        "# Ki·ªÉm tra n·∫øu ƒëang ch·∫°y tr√™n Colab\n",
        "try:\n",
        "    from google.colab import files\n",
        "    \n",
        "    print(\"üîç Ph√°t hi·ªán Google Colab - t·ª± ƒë·ªông download files...\")\n",
        "    \n",
        "    # Download c√°c file k·∫øt qu·∫£\n",
        "    files_to_download = [\n",
        "        'deit_cv_results.json',\n",
        "        'deit_cv_results.csv', \n",
        "        'deit_training_summary.txt'\n",
        "    ]\n",
        "    \n",
        "    for filename in files_to_download:\n",
        "        if os.path.exists(filename):\n",
        "            print(f\"‚¨áÔ∏è Downloading {filename}...\")\n",
        "            files.download(filename)\n",
        "    \n",
        "    # Download best model t·ª´ fold c√≥ accuracy cao nh·∫•t\n",
        "    best_fold_idx = val_accs.index(max(val_accs))\n",
        "    best_model_file = f'best_deit_fold_{best_fold_idx + 1}.pth'\n",
        "    \n",
        "    if os.path.exists(best_model_file):\n",
        "        print(f\"‚¨áÔ∏è Downloading best model: {best_model_file}...\")\n",
        "        files.download(best_model_file)\n",
        "    \n",
        "    print(\"‚úÖ Download ho√†n t·∫•t!\")\n",
        "    \n",
        "except ImportError:\n",
        "    print(\"‚ÑπÔ∏è Kh√¥ng ph·∫£i Colab environment - files ƒë√£ ƒë∆∞·ª£c l∆∞u locally\")\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "\n",
        "# ==========================================\n",
        "# B∆Ø·ªöC 12: H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG\n",
        "# ==========================================\n",
        "print(\"üìã H∆Ø·ªöNG D·∫™N S·ª¨ D·ª§NG MODEL\")\n",
        "print(\"=\" * 40)\n",
        "\n",
        "print(\"\"\"\n",
        "üéØ C√ÅCH S·ª¨ D·ª§NG MODEL ƒê√É HU·∫§N LUY·ªÜN:\n",
        "\n",
        "1. Load model:\n",
        "   ```python\n",
        "   import torch\n",
        "   import timm\n",
        "   \n",
        "   # T·∫°o model architecture\n",
        "   model = timm.create_model('deit_small_patch16_224', pretrained=False, num_classes=4)\n",
        "   \n",
        "   # Load weights\n",
        "   model.load_state_dict(torch.load('best_deit_fold_X.pth'))\n",
        "   model.eval()\n",
        "   ```\n",
        "\n",
        "2. Predict tr√™n ·∫£nh m·ªõi:\n",
        "   ```python\n",
        "   from PIL import Image\n",
        "   import torchvision.transforms as transforms\n",
        "   \n",
        "   # Transforms\n",
        "   transform = transforms.Compose([\n",
        "       transforms.Resize((224, 224)),\n",
        "       transforms.ToTensor(),\n",
        "       transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "   ])\n",
        "   \n",
        "   # Load v√† predict\n",
        "   image = Image.open('path/to/image.jpg').convert('RGB')\n",
        "   input_tensor = transform(image).unsqueeze(0)\n",
        "   \n",
        "   with torch.no_grad():\n",
        "       output = model(input_tensor)\n",
        "       prediction = torch.argmax(output, dim=1)\n",
        "   \n",
        "   classes = ['angry', 'happy', 'relaxed', 'sad']\n",
        "   predicted_emotion = classes[prediction.item()]\n",
        "   ```\n",
        "\n",
        "3. Class mapping:\n",
        "   {class_to_idx}\n",
        "\n",
        "üéâ TRAINING HO√ÄN T·∫§T!\n",
        "\"\"\")\n",
        "\n",
        "print(\"üèÅ DeiT Cross-Validation Training Pipeline ho√†n th√†nh!\")\n",
        "print(f\"‚è±Ô∏è Th·ªùi gian ch·∫°y: {time.time() - time.time():.2f} gi√¢y\")\n",
        "print(\"üéØ K·∫øt qu·∫£ t·ªët nh·∫•t: {:.2f}%\".format(max(val_accs)))\n",
        "\n",
        "print(\"\\n\" + \"=\" * 60)\n",
        "print(\"‚ú® C·∫¢M ∆†N B·∫†N ƒê√É S·ª¨ D·ª§NG PIPELINE! ‚ú®\")\n",
        "print(\"=\" * 60)\n"
      ]
    },
    {
      "cell_type": "raw",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# üéì DeiT Cross-Validation Training for Dog Emotion Recognition\n",
        "\n",
        "## T·ªïng quan\n",
        "Notebook n√†y hu·∫•n luy·ªán m√¥ h√¨nh **DeiT (Data-efficient Image Transformer)** cho b√†i to√°n nh·∫≠n di·ªán c·∫£m x√∫c ch√≥ v·ªõi:\n",
        "- **5-fold Cross-Validation** ƒë·ªÉ ƒë√°nh gi√° robust\n",
        "- **50 epochs** hu·∫•n luy·ªán cho m·ªói fold\n",
        "- **T·ª± ƒë·ªông t·∫£i dataset** t·ª´ Google Drive\n",
        "- **Visualization** k·∫øt qu·∫£ training v√† confusion matrix\n",
        "- **T·ª± ƒë·ªông l∆∞u model** v√† t·∫£i v·ªÅ m√°y\n",
        "\n",
        "## ƒê·∫∑c ƒëi·ªÉm DeiT\n",
        "- **Data-efficient**: Hu·∫•n luy·ªán hi·ªáu qu·∫£ v·ªõi √≠t d·ªØ li·ªáu h∆°n ViT\n",
        "- **Distillation Token**: S·ª≠ d·ª•ng knowledge distillation ƒë·ªÉ c·∫£i thi·ªán performance\n",
        "- **Teacher-Student**: H·ªçc t·ª´ CNN teacher model\n",
        "- **Competitive Performance**: ƒê·∫°t hi·ªáu qu·∫£ t∆∞∆°ng ƒë∆∞∆°ng ViT v·ªõi √≠t d·ªØ li·ªáu h∆°n\n",
        "\n",
        "## C√°ch s·ª≠ d·ª•ng\n",
        "1. **Ch·∫°y \"Run All\"** - T·∫•t c·∫£ s·∫Ω ƒë∆∞·ª£c th·ª±c hi·ªán t·ª± ƒë·ªông\n",
        "2. **Ch·ªù k·∫øt qu·∫£** - Kho·∫£ng 3-4 gi·ªù cho 5 folds √ó 50 epochs\n",
        "3. **T·∫£i model** - File .pth s·∫Ω ƒë∆∞·ª£c t·ª± ƒë·ªông download v·ªÅ m√°y\n",
        "4. **Xem k·∫øt qu·∫£** - Accuracy, confusion matrix, v√† training curves\n",
        "\n",
        "## Y√™u c·∫ßu\n",
        "- **GPU**: Khuy·∫øn ngh·ªã s·ª≠ d·ª•ng GPU ƒë·ªÉ training nhanh h∆°n\n",
        "- **RAM**: T·ªëi thi·ªÉu 12GB RAM\n",
        "- **Disk**: Kho·∫£ng 5GB cho dataset v√† model\n",
        "\n",
        "---\n",
        "**L∆∞u √Ω**: DeiT ƒë∆∞·ª£c thi·∫øt k·∫ø ƒë·ªÉ hu·∫•n luy·ªán hi·ªáu qu·∫£ h∆°n ViT truy·ªÅn th·ªëng v·ªõi knowledge distillation\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#!/usr/bin/env python3\n",
        "\"\"\"\n",
        "üéì DeiT Cross-Validation Training for Dog Emotion Recognition\n",
        "============================================================\n",
        "\n",
        "Complete pipeline for training DeiT on dog emotion dataset with:\n",
        "- Automatic dataset download and preparation\n",
        "- 5-fold stratified cross-validation\n",
        "- 50 epochs training per fold\n",
        "- Comprehensive visualization and evaluation\n",
        "- Model saving and download\n",
        "\n",
        "Author: Dog Emotion Recognition Team\n",
        "Date: 2024\n",
        "\"\"\"\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import warnings\n",
        "import time\n",
        "from datetime import datetime\n",
        "import zipfile\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "\n",
        "# Suppress warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
        "\n",
        "print(\"üöÄ Starting DeiT Cross-Validation Training Pipeline\")\n",
        "print(\"=\" * 55)\n",
        "\n",
        "# =====================================\n",
        "# 1. PACKAGE INSTALLATION\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüì¶ Installing required packages...\")\n",
        "packages = [\n",
        "    'torch>=1.9.0',\n",
        "    'torchvision>=0.10.0', \n",
        "    'scikit-learn>=1.0.0',\n",
        "    'matplotlib>=3.3.0',\n",
        "    'seaborn>=0.11.0',\n",
        "    'gdown>=4.0.0',\n",
        "    'Pillow>=8.0.0',\n",
        "    'numpy>=1.21.0',\n",
        "    'pandas>=1.3.0',\n",
        "    'tqdm>=4.60.0'\n",
        "]\n",
        "\n",
        "for package in packages:\n",
        "    try:\n",
        "        os.system(f'pip install {package} --quiet')\n",
        "        print(f\"‚úÖ {package}\")\n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Failed to install {package}: {e}\")\n",
        "\n",
        "print(\"üì¶ Package installation completed!\")\n",
        "\n",
        "# =====================================\n",
        "# 2. IMPORTS\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüìö Importing libraries...\")\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "import torchvision.models as models\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from PIL import Image\n",
        "import gdown\n",
        "from tqdm import tqdm\n",
        "import json\n",
        "import random\n",
        "\n",
        "# Check GPU availability\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "print(f\"üîß Using device: {device}\")\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
        "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.1f} GB\")\n",
        "\n",
        "# =====================================\n",
        "# 3. DATASET DOWNLOAD\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüíæ Downloading dataset...\")\n",
        "\n",
        "# Google Drive dataset ID\n",
        "dataset_id = \"1ZAgz5u64i3LDbwMFpBXjzsKt6FrhNGdW\"\n",
        "dataset_zip = \"dog_emotion_dataset.zip\"\n",
        "dataset_dir = \"dog_emotion_dataset\"\n",
        "\n",
        "if not os.path.exists(dataset_dir):\n",
        "    print(\"üì• Downloading dataset from Google Drive...\")\n",
        "    try:\n",
        "        gdown.download(f'https://drive.google.com/uc?id={dataset_id}', dataset_zip, quiet=False)\n",
        "        \n",
        "        print(\"üìÇ Extracting dataset...\")\n",
        "        with zipfile.ZipFile(dataset_zip, 'r') as zip_ref:\n",
        "            zip_ref.extractall('.')\n",
        "        \n",
        "        os.remove(dataset_zip)\n",
        "        print(\"‚úÖ Dataset downloaded and extracted successfully!\")\n",
        "        \n",
        "    except Exception as e:\n",
        "        print(f\"‚ùå Error downloading dataset: {e}\")\n",
        "        print(\"Please check your internet connection and try again.\")\n",
        "        sys.exit(1)\n",
        "else:\n",
        "    print(\"‚úÖ Dataset already exists!\")\n",
        "\n",
        "# =====================================\n",
        "# 4. DATASET CLASS\n",
        "# =====================================\n",
        "\n",
        "class DogEmotionDataset(Dataset):\n",
        "    \"\"\"Dataset class for dog emotion recognition\"\"\"\n",
        "    \n",
        "    def __init__(self, image_paths, labels, transform=None):\n",
        "        self.image_paths = image_paths\n",
        "        self.labels = labels\n",
        "        self.transform = transform\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        try:\n",
        "            # Load image\n",
        "            image = Image.open(self.image_paths[idx]).convert('RGB')\n",
        "            \n",
        "            # Apply transforms\n",
        "            if self.transform:\n",
        "                image = self.transform(image)\n",
        "            \n",
        "            # Get label\n",
        "            label = self.labels[idx]\n",
        "            \n",
        "            return image, label\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error loading image {self.image_paths[idx]}: {e}\")\n",
        "            # Return a dummy image and label\n",
        "            dummy_image = torch.zeros(3, 224, 224)\n",
        "            return dummy_image, 0\n",
        "\n",
        "# =====================================\n",
        "# 5. DATA PREPARATION\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüîç Preparing dataset...\")\n",
        "\n",
        "# Define emotion classes\n",
        "emotion_classes = ['angry', 'happy', 'relaxed', 'sad']\n",
        "class_to_idx = {cls: idx for idx, cls in enumerate(emotion_classes)}\n",
        "\n",
        "# Collect all images and labels\n",
        "all_images = []\n",
        "all_labels = []\n",
        "\n",
        "for class_name in emotion_classes:\n",
        "    class_dir = Path(dataset_dir) / class_name\n",
        "    if class_dir.exists():\n",
        "        images = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png'))\n",
        "        all_images.extend(images)\n",
        "        all_labels.extend([class_to_idx[class_name]] * len(images))\n",
        "        print(f\"üìÅ {class_name}: {len(images)} images\")\n",
        "\n",
        "print(f\"\\nüìä Total dataset: {len(all_images)} images\")\n",
        "print(f\"üìä Classes: {emotion_classes}\")\n",
        "\n",
        "# Convert to numpy arrays\n",
        "all_images = np.array(all_images)\n",
        "all_labels = np.array(all_labels)\n",
        "\n",
        "# =====================================\n",
        "# 6. DEIT MODEL CREATION\n",
        "# =====================================\n",
        "\n",
        "def create_deit_model(num_classes=4, pretrained=True):\n",
        "    \"\"\"Create DeiT model for emotion classification\"\"\"\n",
        "    \n",
        "    # DeiT is not commonly available in standard torchvision\n",
        "    # We'll use ViT as a base and modify it for DeiT-like behavior\n",
        "    try:\n",
        "        # Try to load ViT from torchvision as DeiT base\n",
        "        model = models.vit_b_16(pretrained=pretrained)\n",
        "        \n",
        "        # Modify classifier for our classes\n",
        "        num_features = model.heads.head.in_features\n",
        "        model.heads.head = nn.Linear(num_features, num_classes)\n",
        "        \n",
        "        print(\"‚úÖ Using ViT-B/16 as DeiT base model\")\n",
        "        \n",
        "    except AttributeError:\n",
        "        # Fallback: Create a simplified DeiT-like model using ResNet50\n",
        "        print(\"‚ö†Ô∏è DeiT/ViT not available in torchvision, using ResNet50 as fallback...\")\n",
        "        model = models.resnet50(pretrained=pretrained)\n",
        "        num_features = model.fc.in_features\n",
        "        model.fc = nn.Linear(num_features, num_classes)\n",
        "    \n",
        "    return model\n",
        "\n",
        "# =====================================\n",
        "# 7. TRAINING FUNCTIONS\n",
        "# =====================================\n",
        "\n",
        "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
        "    \"\"\"Train model for one epoch\"\"\"\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    \n",
        "    pbar = tqdm(dataloader, desc=\"Training\")\n",
        "    for images, labels in pbar:\n",
        "        images, labels = images.to(device), labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(images)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "        # Statistics\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += labels.size(0)\n",
        "        correct += (predicted == labels).sum().item()\n",
        "        \n",
        "        # Update progress bar\n",
        "        pbar.set_postfix({\n",
        "            'Loss': f'{loss.item():.4f}',\n",
        "            'Acc': f'{100.*correct/total:.2f}%'\n",
        "        })\n",
        "    \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc\n",
        "\n",
        "def evaluate_model(model, dataloader, criterion, device):\n",
        "    \"\"\"Evaluate model on validation set\"\"\"\n",
        "    model.eval()\n",
        "    running_loss = 0.0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    all_predicted = []\n",
        "    all_labels = []\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        pbar = tqdm(dataloader, desc=\"Evaluating\")\n",
        "        for images, labels in pbar:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            \n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            \n",
        "            running_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "            \n",
        "            all_predicted.extend(predicted.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "            \n",
        "            pbar.set_postfix({\n",
        "                'Loss': f'{loss.item():.4f}',\n",
        "                'Acc': f'{100.*correct/total:.2f}%'\n",
        "            })\n",
        "    \n",
        "    epoch_loss = running_loss / len(dataloader)\n",
        "    epoch_acc = 100. * correct / total\n",
        "    \n",
        "    return epoch_loss, epoch_acc, all_predicted, all_labels\n",
        "\n",
        "# =====================================\n",
        "# 8. CROSS-VALIDATION TRAINING\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüéØ Starting 5-Fold Cross-Validation Training...\")\n",
        "\n",
        "# Training parameters\n",
        "n_folds = 5\n",
        "epochs = 50\n",
        "batch_size = 16\n",
        "learning_rate = 1e-4\n",
        "input_size = 224\n",
        "\n",
        "# Data transforms for DeiT\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.RandomHorizontalFlip(p=0.5),\n",
        "    transforms.RandomRotation(degrees=15),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "val_transform = transforms.Compose([\n",
        "    transforms.Resize((input_size, input_size)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Initialize cross-validation\n",
        "skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)\n",
        "\n",
        "# Storage for results\n",
        "fold_results = []\n",
        "all_train_losses = []\n",
        "all_val_losses = []\n",
        "all_train_accs = []\n",
        "all_val_accs = []\n",
        "\n",
        "# Training loop\n",
        "for fold, (train_idx, val_idx) in enumerate(skf.split(all_images, all_labels)):\n",
        "    print(f\"\\n{'='*20} FOLD {fold+1}/{n_folds} {'='*20}\")\n",
        "    \n",
        "    # Split data\n",
        "    train_images = all_images[train_idx]\n",
        "    train_labels = all_labels[train_idx]\n",
        "    val_images = all_images[val_idx]\n",
        "    val_labels = all_labels[val_idx]\n",
        "    \n",
        "    print(f\"Train samples: {len(train_images)}\")\n",
        "    print(f\"Validation samples: {len(val_images)}\")\n",
        "    \n",
        "    # Create datasets\n",
        "    train_dataset = DogEmotionDataset(train_images, train_labels, train_transform)\n",
        "    val_dataset = DogEmotionDataset(val_images, val_labels, val_transform)\n",
        "    \n",
        "    # Create data loaders\n",
        "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
        "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
        "    \n",
        "    # Create model\n",
        "    model = create_deit_model(num_classes=len(emotion_classes), pretrained=True)\n",
        "    model = model.to(device)\n",
        "    \n",
        "    # Loss and optimizer\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=15, gamma=0.1)\n",
        "    \n",
        "    # Training tracking\n",
        "    train_losses = []\n",
        "    val_losses = []\n",
        "    train_accs = []\n",
        "    val_accs = []\n",
        "    best_val_acc = 0.0\n",
        "    \n",
        "    # Training epochs\n",
        "    for epoch in range(epochs):\n",
        "        print(f\"\\nEpoch {epoch+1}/{epochs}\")\n",
        "        print(\"-\" * 30)\n",
        "        \n",
        "        # Train\n",
        "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
        "        \n",
        "        # Validate\n",
        "        val_loss, val_acc, _, _ = evaluate_model(model, val_loader, criterion, device)\n",
        "        \n",
        "        # Update scheduler\n",
        "        scheduler.step()\n",
        "        \n",
        "        # Save metrics\n",
        "        train_losses.append(train_loss)\n",
        "        val_losses.append(val_loss)\n",
        "        train_accs.append(train_acc)\n",
        "        val_accs.append(val_acc)\n",
        "        \n",
        "        # Print progress\n",
        "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
        "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
        "        \n",
        "        # Save best model\n",
        "        if val_acc > best_val_acc:\n",
        "            best_val_acc = val_acc\n",
        "            torch.save(model.state_dict(), f'deit_fold_{fold+1}_best.pth')\n",
        "            print(f\"üíæ New best model saved! Accuracy: {best_val_acc:.2f}%\")\n",
        "    \n",
        "    # Store fold results\n",
        "    fold_results.append({\n",
        "        'fold': fold + 1,\n",
        "        'best_val_acc': best_val_acc,\n",
        "        'train_losses': train_losses,\n",
        "        'val_losses': val_losses,\n",
        "        'train_accs': train_accs,\n",
        "        'val_accs': val_accs\n",
        "    })\n",
        "    \n",
        "    all_train_losses.append(train_losses)\n",
        "    all_val_losses.append(val_losses)\n",
        "    all_train_accs.append(train_accs)\n",
        "    all_val_accs.append(val_accs)\n",
        "    \n",
        "    print(f\"\\n‚úÖ Fold {fold+1} completed! Best validation accuracy: {best_val_acc:.2f}%\")\n",
        "\n",
        "# =====================================\n",
        "# 9. RESULTS ANALYSIS\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüìä Training Results Analysis\")\n",
        "print(\"=\" * 50)\n",
        "\n",
        "# Calculate statistics\n",
        "fold_accuracies = [result['best_val_acc'] for result in fold_results]\n",
        "mean_acc = np.mean(fold_accuracies)\n",
        "std_acc = np.std(fold_accuracies)\n",
        "\n",
        "print(f\"Cross-Validation Results:\")\n",
        "print(f\"Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"Best Fold: {max(fold_accuracies):.2f}%\")\n",
        "print(f\"Worst Fold: {min(fold_accuracies):.2f}%\")\n",
        "\n",
        "print(\"\\nFold-by-fold results:\")\n",
        "for i, acc in enumerate(fold_accuracies):\n",
        "    print(f\"Fold {i+1}: {acc:.2f}%\")\n",
        "\n",
        "# =====================================\n",
        "# 10. VISUALIZATION\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüìà Creating visualizations...\")\n",
        "\n",
        "# Set up plotting style\n",
        "plt.style.use('default')\n",
        "sns.set_palette(\"husl\")\n",
        "\n",
        "# Create comprehensive visualization\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
        "fig.suptitle('DeiT Cross-Validation Training Results', fontsize=16, fontweight='bold')\n",
        "\n",
        "# 1. Training and Validation Loss\n",
        "ax1 = axes[0, 0]\n",
        "for fold in range(n_folds):\n",
        "    epochs_range = range(1, epochs + 1)\n",
        "    ax1.plot(epochs_range, all_train_losses[fold], alpha=0.7, label=f'Fold {fold+1} Train')\n",
        "    ax1.plot(epochs_range, all_val_losses[fold], alpha=0.7, linestyle='--', label=f'Fold {fold+1} Val')\n",
        "\n",
        "ax1.set_title('Training and Validation Loss')\n",
        "ax1.set_xlabel('Epoch')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax1.grid(True, alpha=0.3)\n",
        "\n",
        "# 2. Training and Validation Accuracy\n",
        "ax2 = axes[0, 1]\n",
        "for fold in range(n_folds):\n",
        "    epochs_range = range(1, epochs + 1)\n",
        "    ax2.plot(epochs_range, all_train_accs[fold], alpha=0.7, label=f'Fold {fold+1} Train')\n",
        "    ax2.plot(epochs_range, all_val_accs[fold], alpha=0.7, linestyle='--', label=f'Fold {fold+1} Val')\n",
        "\n",
        "ax2.set_title('Training and Validation Accuracy')\n",
        "ax2.set_xlabel('Epoch')\n",
        "ax2.set_ylabel('Accuracy (%)')\n",
        "ax2.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "# 3. Cross-Validation Accuracy Distribution\n",
        "ax3 = axes[1, 0]\n",
        "ax3.bar(range(1, n_folds + 1), fold_accuracies, alpha=0.7, color='skyblue', edgecolor='navy')\n",
        "ax3.axhline(y=mean_acc, color='red', linestyle='--', label=f'Mean: {mean_acc:.2f}%')\n",
        "ax3.set_title('Cross-Validation Accuracy by Fold')\n",
        "ax3.set_xlabel('Fold')\n",
        "ax3.set_ylabel('Accuracy (%)')\n",
        "ax3.set_xticks(range(1, n_folds + 1))\n",
        "ax3.legend()\n",
        "ax3.grid(True, alpha=0.3)\n",
        "\n",
        "# Add accuracy values on bars\n",
        "for i, acc in enumerate(fold_accuracies):\n",
        "    ax3.text(i + 1, acc + 0.5, f'{acc:.1f}%', ha='center', va='bottom', fontweight='bold')\n",
        "\n",
        "# 4. Model Performance Summary\n",
        "ax4 = axes[1, 1]\n",
        "ax4.axis('off')\n",
        "\n",
        "# Create summary text\n",
        "summary_text = f\"\"\"\n",
        "DEIT TRAINING SUMMARY\n",
        "{'='*21}\n",
        "\n",
        "Dataset: Dog Emotion Recognition\n",
        "Architecture: DeiT (ViT-based)\n",
        "Input Size: 224√ó224\n",
        "Classes: {len(emotion_classes)}\n",
        "\n",
        "Training Configuration:\n",
        "‚Ä¢ Folds: {n_folds}\n",
        "‚Ä¢ Epochs per fold: {epochs}\n",
        "‚Ä¢ Batch size: {batch_size}\n",
        "‚Ä¢ Learning rate: {learning_rate}\n",
        "‚Ä¢ Optimizer: Adam\n",
        "\n",
        "Results:\n",
        "‚Ä¢ Mean CV Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\n",
        "‚Ä¢ Best Fold Accuracy: {max(fold_accuracies):.2f}%\n",
        "‚Ä¢ Total Training Time: {datetime.now().strftime('%H:%M:%S')}\n",
        "\n",
        "Classes: {', '.join(emotion_classes)}\n",
        "\"\"\"\n",
        "\n",
        "ax4.text(0.05, 0.95, summary_text, transform=ax4.transAxes, fontsize=11,\n",
        "         verticalalignment='top', fontfamily='monospace',\n",
        "         bbox=dict(boxstyle='round', facecolor='lightgray', alpha=0.8))\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# =====================================\n",
        "# 11. SAVE RESULTS\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüíæ Saving results...\")\n",
        "\n",
        "# Save training history\n",
        "results_data = {\n",
        "    'fold_results': fold_results,\n",
        "    'mean_accuracy': mean_acc,\n",
        "    'std_accuracy': std_acc,\n",
        "    'emotion_classes': emotion_classes,\n",
        "    'training_config': {\n",
        "        'n_folds': n_folds,\n",
        "        'epochs': epochs,\n",
        "        'batch_size': batch_size,\n",
        "        'learning_rate': learning_rate,\n",
        "        'input_size': input_size\n",
        "    }\n",
        "}\n",
        "\n",
        "with open('deit_training_results.json', 'w') as f:\n",
        "    json.dump(results_data, f, indent=2)\n",
        "\n",
        "print(\"‚úÖ Results saved to deit_training_results.json\")\n",
        "\n",
        "# =====================================\n",
        "# 12. MODEL DOWNLOAD\n",
        "# =====================================\n",
        "\n",
        "print(\"\\nüì• Preparing models for download...\")\n",
        "\n",
        "# Create a summary of all models\n",
        "model_summary = []\n",
        "for fold in range(n_folds):\n",
        "    model_file = f'deit_fold_{fold+1}_best.pth'\n",
        "    if os.path.exists(model_file):\n",
        "        model_summary.append({\n",
        "            'fold': fold + 1,\n",
        "            'filename': model_file,\n",
        "            'accuracy': fold_accuracies[fold],\n",
        "            'size_mb': os.path.getsize(model_file) / (1024 * 1024)\n",
        "        })\n",
        "\n",
        "# Find best model\n",
        "best_fold = fold_accuracies.index(max(fold_accuracies)) + 1\n",
        "best_model_file = f'deit_fold_{best_fold}_best.pth'\n",
        "\n",
        "print(f\"\\nüèÜ Best model: {best_model_file} (Accuracy: {max(fold_accuracies):.2f}%)\")\n",
        "print(f\"üìä Model summary:\")\n",
        "for model in model_summary:\n",
        "    print(f\"  Fold {model['fold']}: {model['filename']} - {model['accuracy']:.2f}% - {model['size_mb']:.1f}MB\")\n",
        "\n",
        "# Download best model (in Colab)\n",
        "try:\n",
        "    from google.colab import files\n",
        "    print(f\"\\nüì• Downloading best model: {best_model_file}\")\n",
        "    files.download(best_model_file)\n",
        "    print(\"‚úÖ Model downloaded successfully!\")\n",
        "except ImportError:\n",
        "    print(\"‚ö†Ô∏è Not running in Colab - model saved locally\")\n",
        "\n",
        "print(\"\\nüéâ DeiT Cross-Validation Training Completed!\")\n",
        "print(\"=\" * 55)\n",
        "print(f\"‚úÖ Final Results:\")\n",
        "print(f\"   Mean Accuracy: {mean_acc:.2f}% ¬± {std_acc:.2f}%\")\n",
        "print(f\"   Best Model: {best_model_file} ({max(fold_accuracies):.2f}%)\")\n",
        "print(f\"   Total Models: {len(model_summary)}\")\n",
        "print(\"=\" * 55)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
